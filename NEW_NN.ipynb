{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b69cff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.ml import Pipeline,Transformer\n",
    "from pyspark.ml.feature import Imputer,StandardScaler,StringIndexer,OneHotEncoder, VectorAssembler\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb917af8",
   "metadata": {},
   "source": [
    "## Create a pipeline for data engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "580aca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"protocol\",\"flow_duration\",\n",
    "\"flow_byts_s\",\"flow_pkts_s\",\n",
    "\"fwd_pkts_s\",\"bwd_pkts_s\",\n",
    "\"tot_fwd_pkts\",\"tot_bwd_pkts\",\n",
    "\"totlen_fwd_pkts\",\"totlen_bwd_pkts\",\n",
    "\"fwd_pkt_len_max\",\"fwd_pkt_len_min\",\n",
    "\"fwd_pkt_len_mean\",\"fwd_pkt_len_std\",\n",
    "\"bwd_pkt_len_max\",\"bwd_pkt_len_min\",\n",
    "\"bwd_pkt_len_mean\",\"bwd_pkt_len_std\",\n",
    "\"pkt_len_max\",\"pkt_len_min\",\n",
    "\"pkt_len_mean\",\"pkt_len_std\",\n",
    "\"pkt_len_var\",\"fwd_header_len\",\n",
    "\"bwd_header_len\",\"fwd_seg_size_min\",\n",
    "\"fwd_act_data_pkts\",\"flow_iat_mean\",\n",
    "\"flow_iat_max\",\"flow_iat_min\",\n",
    "\"flow_iat_std\",\"fwd_iat_tot\",\n",
    "\"fwd_iat_max\",\"fwd_iat_min\",\n",
    "\"fwd_iat_mean\",\"fwd_iat_std\",\n",
    "\"bwd_iat_tot\",\"bwd_iat_max\",\n",
    "\"bwd_iat_min\",\"bwd_iat_mean\",\n",
    "\"bwd_iat_std\",\"fwd_psh_flags\",\n",
    "\"bwd_psh_flags\",\"fwd_urg_flags\",\n",
    "\"bwd_urg_flags\",\"fin_flag_cnt\",\n",
    "\"syn_flag_cnt\",\"rst_flag_cnt\",\n",
    "\"psh_flag_cnt\",\"ack_flag_cnt\",\n",
    "\"urg_flag_cnt\",\"ece_flag_cnt\",\n",
    "\"down_up_ratio\",\"pkt_size_avg\",\n",
    "\"init_fwd_win_byts\",\"init_bwd_win_byts\",\n",
    "\"active_max\",\"active_min\",\n",
    "\"active_mean\",\"active_std\",\n",
    "\"idle_max\",\"idle_min\",\n",
    "\"idle_mean\",\"idle_std\",\n",
    "\"fwd_byts_b_avg\",\"fwd_pkts_b_avg\",\n",
    "\"bwd_byts_b_avg\",\"bwd_pkts_b_avg\",\n",
    "\"fwd_blk_rate_avg\",\"bwd_blk_rate_avg\",\n",
    "\"fwd_seg_size_avg\",\"bwd_seg_size_avg\",\n",
    "\"cwr_flag_count\",\"subflow_fwd_pkts\",\n",
    "\"subflow_bwd_pkts\",\"subflow_fwd_byts\",\n",
    "\"subflow_bwd_byts\", \"label\"]\n",
    "\n",
    "feature_cols = [\"protocol\",\"flow_duration\",\n",
    "\"flow_byts_s\",\"flow_pkts_s\",\n",
    "\"fwd_pkts_s\",\"bwd_pkts_s\",\n",
    "\"tot_fwd_pkts\",\"tot_bwd_pkts\",\n",
    "\"totlen_fwd_pkts\",\"totlen_bwd_pkts\",\n",
    "\"fwd_pkt_len_max\",\"fwd_pkt_len_min\",\n",
    "\"fwd_pkt_len_mean\",\"fwd_pkt_len_std\",\n",
    "\"bwd_pkt_len_max\",\"bwd_pkt_len_min\",\n",
    "\"bwd_pkt_len_mean\",\"bwd_pkt_len_std\",\n",
    "\"pkt_len_max\",\"pkt_len_min\",\n",
    "\"pkt_len_mean\",\"pkt_len_std\",\n",
    "\"pkt_len_var\",\"fwd_header_len\",\n",
    "\"bwd_header_len\",\"fwd_seg_size_min\",\n",
    "\"fwd_act_data_pkts\",\"flow_iat_mean\",\n",
    "\"flow_iat_max\",\"flow_iat_min\",\n",
    "\"flow_iat_std\",\"fwd_iat_tot\",\n",
    "\"fwd_iat_max\",\"fwd_iat_min\",\n",
    "\"fwd_iat_mean\",\"fwd_iat_std\",\n",
    "\"bwd_iat_tot\",\"bwd_iat_max\",\n",
    "\"bwd_iat_min\",\"bwd_iat_mean\",\n",
    "\"bwd_iat_std\",\"fwd_psh_flags\",\n",
    "\"bwd_psh_flags\",\"fwd_urg_flags\",\n",
    "\"bwd_urg_flags\",\"fin_flag_cnt\",\n",
    "\"syn_flag_cnt\",\"rst_flag_cnt\",\n",
    "\"psh_flag_cnt\",\"ack_flag_cnt\",\n",
    "\"urg_flag_cnt\",\"ece_flag_cnt\",\n",
    "\"down_up_ratio\",\"pkt_size_avg\",\n",
    "\"init_fwd_win_byts\",\"init_bwd_win_byts\",\n",
    "\"active_max\",\"active_min\",\n",
    "\"active_mean\",\"active_std\",\n",
    "\"idle_max\",\"idle_min\",\n",
    "\"idle_mean\",\"idle_std\",\n",
    "\"fwd_byts_b_avg\",\"fwd_pkts_b_avg\",\n",
    "\"bwd_byts_b_avg\",\"bwd_pkts_b_avg\",\n",
    "\"fwd_blk_rate_avg\",\"bwd_blk_rate_avg\",\n",
    "\"fwd_seg_size_avg\",\"bwd_seg_size_avg\",\n",
    "\"cwr_flag_count\",\"subflow_fwd_pkts\",\n",
    "\"subflow_bwd_pkts\",\"subflow_fwd_byts\",\n",
    "\"subflow_bwd_byts\"]\n",
    "\n",
    "\n",
    "class OutcomeCreater(Transformer): # this defines a transformer that creates the outcome column\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "\n",
    "        indexer = StringIndexer(inputCol= 'label', outputCol= 'outcome_index')\n",
    "        output_df = indexer.fit(dataset).transform(dataset)\n",
    "\n",
    "        encoder = OneHotEncoder(inputCol= 'outcome_index', outputCol= 'outcome_encoded', dropLast=False)\n",
    "        output_df = encoder.fit(output_df).transform(output_df)\n",
    "        \n",
    "        output_df = output_df.drop('difficulty')\n",
    "\n",
    "        return output_df\n",
    "\n",
    "class FeatureTypeCaster(Transformer): # this transformer will cast the columns as appropriate types  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        output_df = dataset\n",
    "        for col_name in feature_cols:\n",
    "            output_df = output_df.withColumn(col_name,col(col_name).cast(DoubleType()))\n",
    "\n",
    "        return output_df\n",
    "\n",
    "class ColumnDropper(Transformer): # this transformer drops unnecessary columns\n",
    "    def __init__(self, columns_to_drop = None):\n",
    "        super().__init__()\n",
    "        self.columns_to_drop=columns_to_drop\n",
    "    def _transform(self, dataset):\n",
    "        output_df = dataset\n",
    "        for col_name in self.columns_to_drop:\n",
    "            output_df = output_df.drop(col_name)\n",
    "        return output_df\n",
    "\n",
    "def get_preprocess_pipeline():\n",
    "    # Stage where columns are casted as appropriate types\n",
    "    stage_typecaster = FeatureTypeCaster()\n",
    "\n",
    "    # Stage where all relevant features are assembled into a vector (and dropping a few)\n",
    "    stage_vector_assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"vectorized_features\")\n",
    "\n",
    "    # Stage where we scale the columns\n",
    "    stage_scaler = StandardScaler(inputCol= 'vectorized_features', outputCol= 'features')\n",
    "    \n",
    "    # Stage for creating the outcome column representing whether there is attack \n",
    "    stage_outcome = OutcomeCreater()\n",
    "\n",
    "    # Removing all unnecessary columbs, only keeping the 'features' and 'outcome' columns\n",
    "    stage_column_dropper = ColumnDropper(columns_to_drop = feature_cols + ['vectorized_features', 'outcome_index', 'label'])\n",
    "\n",
    "    # Connect the columns into a pipeline\n",
    "    pipeline = Pipeline(stages=[stage_typecaster, stage_vector_assembler,stage_scaler,stage_outcome,stage_column_dropper])\n",
    "    return pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb46588",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "74c83a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "# os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "# os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"SystemsToolChains\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "c2_data_raw = spark.read.csv('dataflow_final.csv',header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9f2a6e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- protocol: string (nullable = true)\n",
      " |-- flow_duration: string (nullable = true)\n",
      " |-- flow_byts_s: string (nullable = true)\n",
      " |-- flow_pkts_s: string (nullable = true)\n",
      " |-- fwd_pkts_s: string (nullable = true)\n",
      " |-- bwd_pkts_s: string (nullable = true)\n",
      " |-- tot_fwd_pkts: string (nullable = true)\n",
      " |-- tot_bwd_pkts: string (nullable = true)\n",
      " |-- totlen_fwd_pkts: string (nullable = true)\n",
      " |-- totlen_bwd_pkts: string (nullable = true)\n",
      " |-- fwd_pkt_len_max: string (nullable = true)\n",
      " |-- fwd_pkt_len_min: string (nullable = true)\n",
      " |-- fwd_pkt_len_mean: string (nullable = true)\n",
      " |-- fwd_pkt_len_std: string (nullable = true)\n",
      " |-- bwd_pkt_len_max: string (nullable = true)\n",
      " |-- bwd_pkt_len_min: string (nullable = true)\n",
      " |-- bwd_pkt_len_mean: string (nullable = true)\n",
      " |-- bwd_pkt_len_std: string (nullable = true)\n",
      " |-- pkt_len_max: string (nullable = true)\n",
      " |-- pkt_len_min: string (nullable = true)\n",
      " |-- pkt_len_mean: string (nullable = true)\n",
      " |-- pkt_len_std: string (nullable = true)\n",
      " |-- pkt_len_var: string (nullable = true)\n",
      " |-- fwd_header_len: string (nullable = true)\n",
      " |-- bwd_header_len: string (nullable = true)\n",
      " |-- fwd_seg_size_min: string (nullable = true)\n",
      " |-- fwd_act_data_pkts: string (nullable = true)\n",
      " |-- flow_iat_mean: string (nullable = true)\n",
      " |-- flow_iat_max: string (nullable = true)\n",
      " |-- flow_iat_min: string (nullable = true)\n",
      " |-- flow_iat_std: string (nullable = true)\n",
      " |-- fwd_iat_tot: string (nullable = true)\n",
      " |-- fwd_iat_max: string (nullable = true)\n",
      " |-- fwd_iat_min: string (nullable = true)\n",
      " |-- fwd_iat_mean: string (nullable = true)\n",
      " |-- fwd_iat_std: string (nullable = true)\n",
      " |-- bwd_iat_tot: string (nullable = true)\n",
      " |-- bwd_iat_max: string (nullable = true)\n",
      " |-- bwd_iat_min: string (nullable = true)\n",
      " |-- bwd_iat_mean: string (nullable = true)\n",
      " |-- bwd_iat_std: string (nullable = true)\n",
      " |-- fwd_psh_flags: string (nullable = true)\n",
      " |-- bwd_psh_flags: string (nullable = true)\n",
      " |-- fwd_urg_flags: string (nullable = true)\n",
      " |-- bwd_urg_flags: string (nullable = true)\n",
      " |-- fin_flag_cnt: string (nullable = true)\n",
      " |-- syn_flag_cnt: string (nullable = true)\n",
      " |-- rst_flag_cnt: string (nullable = true)\n",
      " |-- psh_flag_cnt: string (nullable = true)\n",
      " |-- ack_flag_cnt: string (nullable = true)\n",
      " |-- urg_flag_cnt: string (nullable = true)\n",
      " |-- ece_flag_cnt: string (nullable = true)\n",
      " |-- down_up_ratio: string (nullable = true)\n",
      " |-- pkt_size_avg: string (nullable = true)\n",
      " |-- init_fwd_win_byts: string (nullable = true)\n",
      " |-- init_bwd_win_byts: string (nullable = true)\n",
      " |-- active_max: string (nullable = true)\n",
      " |-- active_min: string (nullable = true)\n",
      " |-- active_mean: string (nullable = true)\n",
      " |-- active_std: string (nullable = true)\n",
      " |-- idle_max: string (nullable = true)\n",
      " |-- idle_min: string (nullable = true)\n",
      " |-- idle_mean: string (nullable = true)\n",
      " |-- idle_std: string (nullable = true)\n",
      " |-- fwd_byts_b_avg: string (nullable = true)\n",
      " |-- fwd_pkts_b_avg: string (nullable = true)\n",
      " |-- bwd_byts_b_avg: string (nullable = true)\n",
      " |-- bwd_pkts_b_avg: string (nullable = true)\n",
      " |-- fwd_blk_rate_avg: string (nullable = true)\n",
      " |-- bwd_blk_rate_avg: string (nullable = true)\n",
      " |-- fwd_seg_size_avg: string (nullable = true)\n",
      " |-- bwd_seg_size_avg: string (nullable = true)\n",
      " |-- cwr_flag_count: string (nullable = true)\n",
      " |-- subflow_fwd_pkts: string (nullable = true)\n",
      " |-- subflow_bwd_pkts: string (nullable = true)\n",
      " |-- subflow_fwd_byts: string (nullable = true)\n",
      " |-- subflow_bwd_byts: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c2_data_raw.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b604d5f",
   "metadata": {},
   "source": [
    "## Drop some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e6d703cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_pipeline = get_preprocess_pipeline()\n",
    "preprocess_pipeline_model = preprocess_pipeline.fit(c2_data_raw)\n",
    "c2_data = preprocess_pipeline_model.transform(c2_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bc4a9e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|            features|outcome_encoded|\n",
      "+--------------------+---------------+\n",
      "|[1.60573311739580...|  (4,[0],[1.0])|\n",
      "|[1.60573311739580...|  (4,[0],[1.0])|\n",
      "|(77,[0,1,2,3,4,6,...|  (4,[0],[1.0])|\n",
      "|(77,[0,1,2,3,4,6,...|  (4,[0],[1.0])|\n",
      "|(77,[0,1,2,3,4,6,...|  (4,[0],[1.0])|\n",
      "|(77,[0,1,2,3,4,6,...|  (4,[0],[1.0])|\n",
      "|[1.60573311739580...|  (4,[0],[1.0])|\n",
      "|(77,[0,1,2,3,4,6,...|  (4,[0],[1.0])|\n",
      "|(77,[0,1,2,3,4,6,...|  (4,[0],[1.0])|\n",
      "|(77,[0,1,2,3,4,6,...|  (4,[0],[1.0])|\n",
      "|(77,[0,1,2,3,4,5,...|  (4,[0],[1.0])|\n",
      "|(77,[0,1,2,3,4,5,...|  (4,[0],[1.0])|\n",
      "|(77,[0,1,2,3,4,5,...|  (4,[1],[1.0])|\n",
      "|(77,[0,1,2,3,4,5,...|  (4,[1],[1.0])|\n",
      "|(77,[0,1,2,3,4,5,...|  (4,[1],[1.0])|\n",
      "|(77,[0,1,2,3,4,5,...|  (4,[1],[1.0])|\n",
      "|(77,[0,1,2,3,4,5,...|  (4,[1],[1.0])|\n",
      "|(77,[0,1,2,3,4,5,...|  (4,[1],[1.0])|\n",
      "|[1.60573311739580...|  (4,[0],[1.0])|\n",
      "|(77,[0,1,2,3,4,5,...|  (4,[1],[1.0])|\n",
      "|[1.60573311739580...|  (4,[0],[1.0])|\n",
      "|[1.60573311739580...|  (4,[0],[1.0])|\n",
      "|[4.54957716595477...|  (4,[2],[1.0])|\n",
      "|(77,[0,1,2,3,4,5,...|  (4,[0],[1.0])|\n",
      "|(77,[0,1,2,3,4,5,...|  (4,[0],[1.0])|\n",
      "|[1.60573311739580...|  (4,[0],[1.0])|\n",
      "|(77,[0,1,2,3,4,6,...|  (4,[0],[1.0])|\n",
      "|(77,[0,1,2,3,4,5,...|  (4,[0],[1.0])|\n",
      "|[1.60573311739580...|  (4,[0],[1.0])|\n",
      "|[1.60573311739580...|  (4,[0],[1.0])|\n",
      "+--------------------+---------------+\n",
      "only showing top 30 rows\n",
      "\n",
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- outcome_encoded: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c2_data.show(30)\n",
    "c2_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "56fa3c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|outcome_encoded|count|\n",
      "+---------------+-----+\n",
      "|  (4,[2],[1.0])|    5|\n",
      "|  (4,[0],[1.0])| 1358|\n",
      "|  (4,[3],[1.0])|    3|\n",
      "|  (4,[1],[1.0])|   10|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## calculate the percentage of each class\n",
    "c2_data.groupBy('outcome_encoded').count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4b33dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data into training, validation, and test sets\n",
    "train, test = c2_data.randomSplit([0.8, 0.2], seed=12345)\n",
    "train, validation = train.randomSplit([0.8, 0.2], seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_train_pandas = train.toPandas()\n",
    "c2_test_pandas = test.toPandas()\n",
    "c2f_validate_pandas = validation.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class MyDataset(Dataset): \n",
    "    def __init__(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.x[idx],self.y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(np.array(c2_train_pandas['features'].values.tolist(), np.float32))\n",
    "y_train = torch.from_numpy(np.array(c2_train_pandas['outcome_encoded'].values.tolist(), np.float32))\n",
    "\n",
    "x_validate = torch.from_numpy(np.array(c2f_validate_pandas['features'].values.tolist(), np.float32))\n",
    "y_validate = torch.from_numpy(np.array(c2f_validate_pandas['outcome_encoded'].values.tolist(), np.float32))\n",
    "\n",
    "x_test = torch.from_numpy(np.array(c2_test_pandas['features'].values.tolist(), np.float32))\n",
    "y_test = torch.from_numpy(np.array(c2_test_pandas['outcome_encoded'].values.tolist(), np.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([924, 4])\n",
      "torch.Size([199, 4])\n",
      "torch.Size([253, 4])\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_validate.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([924, 77])\n",
      "torch.Size([199, 77])\n",
      "torch.Size([253, 77])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_validate.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MyDataset(x_train,y_train)\n",
    "validate_set = MyDataset(x_validate,y_validate)\n",
    "test_set = MyDataset(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myMultiLayerPerceptron(\n",
      "  (sequential): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=77, out_features=50, bias=True)\n",
      "    (2): Tanh()\n",
      "    (3): Linear(in_features=50, out_features=20, bias=True)\n",
      "    (4): Tanh()\n",
      "    (5): Linear(in_features=20, out_features=4, bias=True)\n",
      "    (6): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Example: using Sequential in Pytorch\n",
    "\n",
    "class myMultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super().__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(input_dim,50),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50,20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20,output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        y = self.sequential(x)\n",
    "        return y\n",
    "    \n",
    "model1 = myMultiLayerPerceptron(77,4)\n",
    "print(model1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Training Accuracy:  0.19480519480519481\n",
      "Validation Accuracy:  0.23618090452261306\n",
      "Training Loss:  1.5258237\n",
      "Validation Loss:  1.4071624\n",
      "Epoch:  1\n",
      "Training Accuracy:  0.237012987012987\n",
      "Validation Accuracy:  0.2914572864321608\n",
      "Training Loss:  1.5236795\n",
      "Validation Loss:  1.400592\n",
      "Epoch:  2\n",
      "Training Accuracy:  0.30627705627705626\n",
      "Validation Accuracy:  0.39195979899497485\n",
      "Training Loss:  1.5179807\n",
      "Validation Loss:  1.3949502\n",
      "Epoch:  3\n",
      "Training Accuracy:  0.4101731601731602\n",
      "Validation Accuracy:  0.46733668341708545\n",
      "Training Loss:  1.5071737\n",
      "Validation Loss:  1.4813212\n",
      "Epoch:  4\n",
      "Training Accuracy:  0.4880952380952381\n",
      "Validation Accuracy:  0.5025125628140703\n",
      "Training Loss:  1.500562\n",
      "Validation Loss:  1.3805715\n",
      "Epoch:  5\n",
      "Training Accuracy:  0.577922077922078\n",
      "Validation Accuracy:  0.6683417085427136\n",
      "Training Loss:  1.4951514\n",
      "Validation Loss:  1.3765987\n",
      "Epoch:  6\n",
      "Training Accuracy:  0.6645021645021645\n",
      "Validation Accuracy:  0.7236180904522613\n",
      "Training Loss:  1.4937125\n",
      "Validation Loss:  1.3678309\n",
      "Epoch:  7\n",
      "Training Accuracy:  0.7391774891774892\n",
      "Validation Accuracy:  0.8090452261306532\n",
      "Training Loss:  1.4828395\n",
      "Validation Loss:  1.3616744\n",
      "Epoch:  8\n",
      "Training Accuracy:  0.7997835497835498\n",
      "Validation Accuracy:  0.8341708542713567\n",
      "Training Loss:  1.4786347\n",
      "Validation Loss:  1.3543332\n",
      "Epoch:  9\n",
      "Training Accuracy:  0.8484848484848485\n",
      "Validation Accuracy:  0.8894472361809045\n",
      "Training Loss:  1.4763643\n",
      "Validation Loss:  1.3479569\n",
      "Epoch:  10\n",
      "Training Accuracy:  0.8874458874458875\n",
      "Validation Accuracy:  0.914572864321608\n",
      "Training Loss:  1.4700117\n",
      "Validation Loss:  1.3414552\n",
      "Epoch:  11\n",
      "Training Accuracy:  0.9069264069264069\n",
      "Validation Accuracy:  0.8994974874371859\n",
      "Training Loss:  1.4614356\n",
      "Validation Loss:  1.3369087\n",
      "Epoch:  12\n",
      "Training Accuracy:  0.9361471861471862\n",
      "Validation Accuracy:  0.9346733668341709\n",
      "Training Loss:  1.4524455\n",
      "Validation Loss:  1.328325\n",
      "Epoch:  13\n",
      "Training Accuracy:  0.9491341991341992\n",
      "Validation Accuracy:  0.964824120603015\n",
      "Training Loss:  1.4494274\n",
      "Validation Loss:  1.3246479\n",
      "Epoch:  14\n",
      "Training Accuracy:  0.9556277056277056\n",
      "Validation Accuracy:  0.9547738693467337\n",
      "Training Loss:  1.444412\n",
      "Validation Loss:  1.3164855\n",
      "Epoch:  15\n",
      "Training Accuracy:  0.9729437229437229\n",
      "Validation Accuracy:  0.964824120603015\n",
      "Training Loss:  1.4363765\n",
      "Validation Loss:  1.3150288\n",
      "Epoch:  16\n",
      "Training Accuracy:  0.9707792207792207\n",
      "Validation Accuracy:  0.9748743718592965\n",
      "Training Loss:  1.4338031\n",
      "Validation Loss:  1.3091906\n",
      "Epoch:  17\n",
      "Training Accuracy:  0.9696969696969697\n",
      "Validation Accuracy:  0.9698492462311558\n",
      "Training Loss:  1.4233979\n",
      "Validation Loss:  1.2997068\n",
      "Epoch:  18\n",
      "Training Accuracy:  0.9816017316017316\n",
      "Validation Accuracy:  0.9798994974874372\n",
      "Training Loss:  1.419247\n",
      "Validation Loss:  1.2920595\n",
      "Epoch:  19\n",
      "Training Accuracy:  0.9794372294372294\n",
      "Validation Accuracy:  0.9849246231155779\n",
      "Training Loss:  1.4131685\n",
      "Validation Loss:  1.284317\n",
      "Epoch:  20\n",
      "Training Accuracy:  0.9826839826839827\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.4072134\n",
      "Validation Loss:  1.2830021\n",
      "Epoch:  21\n",
      "Training Accuracy:  0.9816017316017316\n",
      "Validation Accuracy:  0.9849246231155779\n",
      "Training Loss:  1.4009391\n",
      "Validation Loss:  1.2767875\n",
      "Epoch:  22\n",
      "Training Accuracy:  0.9859307359307359\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  1.3940041\n",
      "Validation Loss:  1.2662977\n",
      "Epoch:  23\n",
      "Training Accuracy:  0.9859307359307359\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  1.3884078\n",
      "Validation Loss:  1.2646106\n",
      "Epoch:  24\n",
      "Training Accuracy:  0.987012987012987\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  1.3844414\n",
      "Validation Loss:  1.2578677\n",
      "Epoch:  25\n",
      "Training Accuracy:  0.9859307359307359\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.3778486\n",
      "Validation Loss:  1.2491885\n",
      "Epoch:  26\n",
      "Training Accuracy:  0.9848484848484849\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.3760697\n",
      "Validation Loss:  1.2442274\n",
      "Epoch:  27\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  1.3694221\n",
      "Validation Loss:  1.2410635\n",
      "Epoch:  28\n",
      "Training Accuracy:  0.987012987012987\n",
      "Validation Accuracy:  0.9849246231155779\n",
      "Training Loss:  1.3602347\n",
      "Validation Loss:  1.2336569\n",
      "Epoch:  29\n",
      "Training Accuracy:  0.987012987012987\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  1.3583895\n",
      "Validation Loss:  1.2284087\n",
      "Epoch:  30\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.3526381\n",
      "Validation Loss:  1.2259272\n",
      "Epoch:  31\n",
      "Training Accuracy:  0.987012987012987\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  1.3475924\n",
      "Validation Loss:  1.2195225\n",
      "Epoch:  32\n",
      "Training Accuracy:  0.987012987012987\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  1.3427733\n",
      "Validation Loss:  1.2155675\n",
      "Epoch:  33\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.3387601\n",
      "Validation Loss:  1.209931\n",
      "Epoch:  34\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.3379033\n",
      "Validation Loss:  1.2073096\n",
      "Epoch:  35\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  1.3263949\n",
      "Validation Loss:  1.1983967\n",
      "Epoch:  36\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.3204442\n",
      "Validation Loss:  1.2892554\n",
      "Epoch:  37\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.319866\n",
      "Validation Loss:  1.1871876\n",
      "Epoch:  38\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.316663\n",
      "Validation Loss:  1.1853855\n",
      "Epoch:  39\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.3114445\n",
      "Validation Loss:  1.175819\n",
      "Epoch:  40\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  1.3079729\n",
      "Validation Loss:  1.1787957\n",
      "Epoch:  41\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.3025724\n",
      "Validation Loss:  1.1708313\n",
      "Epoch:  42\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.301526\n",
      "Validation Loss:  1.1692177\n",
      "Epoch:  43\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2981999\n",
      "Validation Loss:  1.1616021\n",
      "Epoch:  44\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2936013\n",
      "Validation Loss:  1.15926\n",
      "Epoch:  45\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2869731\n",
      "Validation Loss:  1.1583854\n",
      "Epoch:  46\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2817632\n",
      "Validation Loss:  1.15292\n",
      "Epoch:  47\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2790859\n",
      "Validation Loss:  1.1450883\n",
      "Epoch:  48\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2748654\n",
      "Validation Loss:  1.1398302\n",
      "Epoch:  49\n",
      "Training Accuracy:  0.987012987012987\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2739033\n",
      "Validation Loss:  1.1393956\n",
      "Epoch:  50\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.272783\n",
      "Validation Loss:  1.1337332\n",
      "Epoch:  51\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2673247\n",
      "Validation Loss:  1.1345072\n",
      "Epoch:  52\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2605304\n",
      "Validation Loss:  1.1290988\n",
      "Epoch:  53\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2589272\n",
      "Validation Loss:  1.1262949\n",
      "Epoch:  54\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.25701\n",
      "Validation Loss:  1.1202554\n",
      "Epoch:  55\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2528785\n",
      "Validation Loss:  1.2212752\n",
      "Epoch:  56\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2462224\n",
      "Validation Loss:  1.1217813\n",
      "Epoch:  57\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2477587\n",
      "Validation Loss:  1.1162988\n",
      "Epoch:  58\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2461485\n",
      "Validation Loss:  1.1120027\n",
      "Epoch:  59\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2399776\n",
      "Validation Loss:  1.2056557\n",
      "Epoch:  60\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2427323\n",
      "Validation Loss:  1.1071056\n",
      "Epoch:  61\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2340736\n",
      "Validation Loss:  1.0999315\n",
      "Epoch:  62\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2308658\n",
      "Validation Loss:  1.0965195\n",
      "Epoch:  63\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2300833\n",
      "Validation Loss:  1.0950183\n",
      "Epoch:  64\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2279843\n",
      "Validation Loss:  1.0916637\n",
      "Epoch:  65\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2242337\n",
      "Validation Loss:  1.0879673\n",
      "Epoch:  66\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2220578\n",
      "Validation Loss:  1.0846361\n",
      "Epoch:  67\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2171495\n",
      "Validation Loss:  1.0868235\n",
      "Epoch:  68\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2159553\n",
      "Validation Loss:  1.0811402\n",
      "Epoch:  69\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2128984\n",
      "Validation Loss:  1.0795404\n",
      "Epoch:  70\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2102377\n",
      "Validation Loss:  1.0769134\n",
      "Epoch:  71\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2102246\n",
      "Validation Loss:  1.0783798\n",
      "Epoch:  72\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.208224\n",
      "Validation Loss:  1.071556\n",
      "Epoch:  73\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2066413\n",
      "Validation Loss:  1.0677131\n",
      "Epoch:  74\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1997137\n",
      "Validation Loss:  1.0732286\n",
      "Epoch:  75\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.2002121\n",
      "Validation Loss:  1.0689313\n",
      "Epoch:  76\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1948886\n",
      "Validation Loss:  1.0624253\n",
      "Epoch:  77\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1944234\n",
      "Validation Loss:  1.0588808\n",
      "Epoch:  78\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1946088\n",
      "Validation Loss:  1.0602409\n",
      "Epoch:  79\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.189458\n",
      "Validation Loss:  1.053868\n",
      "Epoch:  80\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1907372\n",
      "Validation Loss:  1.0520877\n",
      "Epoch:  81\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.191387\n",
      "Validation Loss:  1.0511458\n",
      "Epoch:  82\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1826705\n",
      "Validation Loss:  1.0490386\n",
      "Epoch:  83\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1841797\n",
      "Validation Loss:  1.0440391\n",
      "Epoch:  84\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1797112\n",
      "Validation Loss:  1.0492584\n",
      "Epoch:  85\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1791672\n",
      "Validation Loss:  1.0415065\n",
      "Epoch:  86\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1780015\n",
      "Validation Loss:  1.0391262\n",
      "Epoch:  87\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1751002\n",
      "Validation Loss:  1.043861\n",
      "Epoch:  88\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1746249\n",
      "Validation Loss:  1.0358821\n",
      "Epoch:  89\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1690315\n",
      "Validation Loss:  1.1374446\n",
      "Epoch:  90\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.17027\n",
      "Validation Loss:  1.0358021\n",
      "Epoch:  91\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1701497\n",
      "Validation Loss:  1.1360587\n",
      "Epoch:  92\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1652662\n",
      "Validation Loss:  1.030094\n",
      "Epoch:  93\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1691018\n",
      "Validation Loss:  1.0257485\n",
      "Epoch:  94\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1656557\n",
      "Validation Loss:  1.0262953\n",
      "Epoch:  95\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1632087\n",
      "Validation Loss:  1.0222858\n",
      "Epoch:  96\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1614785\n",
      "Validation Loss:  1.01958\n",
      "Epoch:  97\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1583165\n",
      "Validation Loss:  1.0196677\n",
      "Epoch:  98\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1568017\n",
      "Validation Loss:  1.019026\n",
      "Epoch:  99\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1527228\n",
      "Validation Loss:  1.0154603\n",
      "Epoch:  100\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1545339\n",
      "Validation Loss:  1.012546\n",
      "Epoch:  101\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1523681\n",
      "Validation Loss:  1.0151402\n",
      "Epoch:  102\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1498194\n",
      "Validation Loss:  1.0125145\n",
      "Epoch:  103\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.146941\n",
      "Validation Loss:  1.0082266\n",
      "Epoch:  104\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1446555\n",
      "Validation Loss:  1.0076725\n",
      "Epoch:  105\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1465033\n",
      "Validation Loss:  1.0098772\n",
      "Epoch:  106\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1432474\n",
      "Validation Loss:  1.003151\n",
      "Epoch:  107\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1454203\n",
      "Validation Loss:  1.0043796\n",
      "Epoch:  108\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1389831\n",
      "Validation Loss:  1.0013602\n",
      "Epoch:  109\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.137582\n",
      "Validation Loss:  0.9982747\n",
      "Epoch:  110\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1362939\n",
      "Validation Loss:  0.997887\n",
      "Epoch:  111\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1356356\n",
      "Validation Loss:  0.99648094\n",
      "Epoch:  112\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1347095\n",
      "Validation Loss:  0.99458045\n",
      "Epoch:  113\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1330206\n",
      "Validation Loss:  0.99239856\n",
      "Epoch:  114\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1339338\n",
      "Validation Loss:  0.9905105\n",
      "Epoch:  115\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1309277\n",
      "Validation Loss:  0.991819\n",
      "Epoch:  116\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1311444\n",
      "Validation Loss:  0.9912852\n",
      "Epoch:  117\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1313944\n",
      "Validation Loss:  0.98828363\n",
      "Epoch:  118\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1262776\n",
      "Validation Loss:  0.98488826\n",
      "Epoch:  119\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1255609\n",
      "Validation Loss:  0.9858292\n",
      "Epoch:  120\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1245143\n",
      "Validation Loss:  0.9842898\n",
      "Epoch:  121\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1224355\n",
      "Validation Loss:  0.9829222\n",
      "Epoch:  122\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1203307\n",
      "Validation Loss:  0.98070484\n",
      "Epoch:  123\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.120403\n",
      "Validation Loss:  0.9791827\n",
      "Epoch:  124\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1194466\n",
      "Validation Loss:  0.9798536\n",
      "Epoch:  125\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1161268\n",
      "Validation Loss:  0.97873735\n",
      "Epoch:  126\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.116416\n",
      "Validation Loss:  0.9752944\n",
      "Epoch:  127\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1177454\n",
      "Validation Loss:  0.975138\n",
      "Epoch:  128\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1146125\n",
      "Validation Loss:  0.97352636\n",
      "Epoch:  129\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1124504\n",
      "Validation Loss:  0.9713086\n",
      "Epoch:  130\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1119536\n",
      "Validation Loss:  0.97102815\n",
      "Epoch:  131\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1111448\n",
      "Validation Loss:  0.9687162\n",
      "Epoch:  132\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1075408\n",
      "Validation Loss:  0.9686008\n",
      "Epoch:  133\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1099495\n",
      "Validation Loss:  0.96599615\n",
      "Epoch:  134\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1057385\n",
      "Validation Loss:  0.96432596\n",
      "Epoch:  135\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.106608\n",
      "Validation Loss:  0.9621593\n",
      "Epoch:  136\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1038047\n",
      "Validation Loss:  0.96485275\n",
      "Epoch:  137\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1032985\n",
      "Validation Loss:  0.963027\n",
      "Epoch:  138\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1051253\n",
      "Validation Loss:  0.9621964\n",
      "Epoch:  139\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1005996\n",
      "Validation Loss:  0.95943946\n",
      "Epoch:  140\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1025561\n",
      "Validation Loss:  0.9600002\n",
      "Epoch:  141\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0983573\n",
      "Validation Loss:  0.95593876\n",
      "Epoch:  142\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0982403\n",
      "Validation Loss:  0.95756006\n",
      "Epoch:  143\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1010952\n",
      "Validation Loss:  0.9548408\n",
      "Epoch:  144\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.1000103\n",
      "Validation Loss:  0.9539596\n",
      "Epoch:  145\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0945965\n",
      "Validation Loss:  0.9512814\n",
      "Epoch:  146\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0981627\n",
      "Validation Loss:  0.9509769\n",
      "Epoch:  147\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0924505\n",
      "Validation Loss:  0.9508397\n",
      "Epoch:  148\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0916541\n",
      "Validation Loss:  0.9499555\n",
      "Epoch:  149\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0908663\n",
      "Validation Loss:  0.94861156\n",
      "Epoch:  150\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0895573\n",
      "Validation Loss:  0.946345\n",
      "Epoch:  151\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0889565\n",
      "Validation Loss:  0.94556034\n",
      "Epoch:  152\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0874447\n",
      "Validation Loss:  0.9462119\n",
      "Epoch:  153\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0866169\n",
      "Validation Loss:  0.9445483\n",
      "Epoch:  154\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0869437\n",
      "Validation Loss:  0.94209784\n",
      "Epoch:  155\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0845553\n",
      "Validation Loss:  0.9432468\n",
      "Epoch:  156\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0832834\n",
      "Validation Loss:  0.94317764\n",
      "Epoch:  157\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0828077\n",
      "Validation Loss:  0.9408709\n",
      "Epoch:  158\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0826946\n",
      "Validation Loss:  0.93918353\n",
      "Epoch:  159\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0798652\n",
      "Validation Loss:  0.9387998\n",
      "Epoch:  160\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0809766\n",
      "Validation Loss:  0.93897194\n",
      "Epoch:  161\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0814226\n",
      "Validation Loss:  0.93652314\n",
      "Epoch:  162\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0778041\n",
      "Validation Loss:  0.93627083\n",
      "Epoch:  163\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0781665\n",
      "Validation Loss:  0.93543977\n",
      "Epoch:  164\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0750631\n",
      "Validation Loss:  0.935803\n",
      "Epoch:  165\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0779405\n",
      "Validation Loss:  0.93190706\n",
      "Epoch:  166\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0757151\n",
      "Validation Loss:  0.93078905\n",
      "Epoch:  167\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0730584\n",
      "Validation Loss:  0.9300419\n",
      "Epoch:  168\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0725715\n",
      "Validation Loss:  0.93033546\n",
      "Epoch:  169\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0712559\n",
      "Validation Loss:  0.9312275\n",
      "Epoch:  170\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0698689\n",
      "Validation Loss:  0.92736256\n",
      "Epoch:  171\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0727952\n",
      "Validation Loss:  0.9276134\n",
      "Epoch:  172\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.070348\n",
      "Validation Loss:  1.0364302\n",
      "Epoch:  173\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0727848\n",
      "Validation Loss:  0.92710555\n",
      "Epoch:  174\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0674323\n",
      "Validation Loss:  0.92450255\n",
      "Epoch:  175\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0705545\n",
      "Validation Loss:  0.9238228\n",
      "Epoch:  176\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.066314\n",
      "Validation Loss:  0.9217404\n",
      "Epoch:  177\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.06402\n",
      "Validation Loss:  0.92064816\n",
      "Epoch:  178\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.064404\n",
      "Validation Loss:  0.92228734\n",
      "Epoch:  179\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0644376\n",
      "Validation Loss:  0.9200269\n",
      "Epoch:  180\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.062069\n",
      "Validation Loss:  0.91996485\n",
      "Epoch:  181\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0614892\n",
      "Validation Loss:  0.9206697\n",
      "Epoch:  182\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0652924\n",
      "Validation Loss:  0.91779816\n",
      "Epoch:  183\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0621495\n",
      "Validation Loss:  0.91744506\n",
      "Epoch:  184\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0601989\n",
      "Validation Loss:  0.9165654\n",
      "Epoch:  185\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0596583\n",
      "Validation Loss:  0.91632193\n",
      "Epoch:  186\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0616338\n",
      "Validation Loss:  0.91371\n",
      "Epoch:  187\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0569738\n",
      "Validation Loss:  0.91375554\n",
      "Epoch:  188\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0588224\n",
      "Validation Loss:  0.91410875\n",
      "Epoch:  189\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0577354\n",
      "Validation Loss:  0.9135728\n",
      "Epoch:  190\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.057526\n",
      "Validation Loss:  0.91224957\n",
      "Epoch:  191\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0524668\n",
      "Validation Loss:  0.91106033\n",
      "Epoch:  192\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0546494\n",
      "Validation Loss:  0.91200155\n",
      "Epoch:  193\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0541925\n",
      "Validation Loss:  1.0221978\n",
      "Epoch:  194\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.052968\n",
      "Validation Loss:  0.90868413\n",
      "Epoch:  195\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0533338\n",
      "Validation Loss:  0.9110188\n",
      "Epoch:  196\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0519435\n",
      "Validation Loss:  0.9081109\n",
      "Epoch:  197\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0519794\n",
      "Validation Loss:  0.90728074\n",
      "Epoch:  198\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0510229\n",
      "Validation Loss:  0.90787536\n",
      "Epoch:  199\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0546622\n",
      "Validation Loss:  0.9048992\n",
      "Epoch:  200\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.049253\n",
      "Validation Loss:  0.90538985\n",
      "Epoch:  201\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0489738\n",
      "Validation Loss:  0.9038874\n",
      "Epoch:  202\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0457315\n",
      "Validation Loss:  0.90373164\n",
      "Epoch:  203\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0477337\n",
      "Validation Loss:  0.90384465\n",
      "Epoch:  204\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.045169\n",
      "Validation Loss:  0.901221\n",
      "Epoch:  205\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0445606\n",
      "Validation Loss:  0.9013532\n",
      "Epoch:  206\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0453305\n",
      "Validation Loss:  0.89910215\n",
      "Epoch:  207\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0430552\n",
      "Validation Loss:  0.8983716\n",
      "Epoch:  208\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0507712\n",
      "Validation Loss:  0.8988401\n",
      "Epoch:  209\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0444684\n",
      "Validation Loss:  0.8998288\n",
      "Epoch:  210\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0430226\n",
      "Validation Loss:  0.897343\n",
      "Epoch:  211\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0420018\n",
      "Validation Loss:  0.8986677\n",
      "Epoch:  212\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0412173\n",
      "Validation Loss:  0.8957127\n",
      "Epoch:  213\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0401642\n",
      "Validation Loss:  0.8961034\n",
      "Epoch:  214\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0402522\n",
      "Validation Loss:  1.0088073\n",
      "Epoch:  215\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0434445\n",
      "Validation Loss:  0.8988188\n",
      "Epoch:  216\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0426883\n",
      "Validation Loss:  0.89391434\n",
      "Epoch:  217\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0396636\n",
      "Validation Loss:  0.89371735\n",
      "Epoch:  218\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0385683\n",
      "Validation Loss:  0.89299196\n",
      "Epoch:  219\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.037555\n",
      "Validation Loss:  0.8917786\n",
      "Epoch:  220\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0412644\n",
      "Validation Loss:  0.892447\n",
      "Epoch:  221\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.034043\n",
      "Validation Loss:  0.8906149\n",
      "Epoch:  222\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0343661\n",
      "Validation Loss:  0.8920575\n",
      "Epoch:  223\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0357176\n",
      "Validation Loss:  0.89032114\n",
      "Epoch:  224\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0338326\n",
      "Validation Loss:  0.89009464\n",
      "Epoch:  225\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0351162\n",
      "Validation Loss:  0.88977605\n",
      "Epoch:  226\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0337574\n",
      "Validation Loss:  0.8880462\n",
      "Epoch:  227\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.036185\n",
      "Validation Loss:  0.8868825\n",
      "Epoch:  228\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0327748\n",
      "Validation Loss:  0.8868697\n",
      "Epoch:  229\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0343041\n",
      "Validation Loss:  0.8864771\n",
      "Epoch:  230\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0351402\n",
      "Validation Loss:  0.88524777\n",
      "Epoch:  231\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0320196\n",
      "Validation Loss:  0.8850482\n",
      "Epoch:  232\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0305241\n",
      "Validation Loss:  0.88467544\n",
      "Epoch:  233\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0302082\n",
      "Validation Loss:  0.8846453\n",
      "Epoch:  234\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0297569\n",
      "Validation Loss:  0.8834454\n",
      "Epoch:  235\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0286791\n",
      "Validation Loss:  0.88317287\n",
      "Epoch:  236\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0286794\n",
      "Validation Loss:  0.9973682\n",
      "Epoch:  237\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0302495\n",
      "Validation Loss:  0.88190496\n",
      "Epoch:  238\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0283895\n",
      "Validation Loss:  0.8816515\n",
      "Epoch:  239\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0272505\n",
      "Validation Loss:  0.88054127\n",
      "Epoch:  240\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0299505\n",
      "Validation Loss:  0.88021547\n",
      "Epoch:  241\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0259914\n",
      "Validation Loss:  0.8804654\n",
      "Epoch:  242\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0250949\n",
      "Validation Loss:  0.87986195\n",
      "Epoch:  243\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.024902\n",
      "Validation Loss:  0.8786787\n",
      "Epoch:  244\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.024915\n",
      "Validation Loss:  0.87758696\n",
      "Epoch:  245\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0244552\n",
      "Validation Loss:  0.87799484\n",
      "Epoch:  246\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0240079\n",
      "Validation Loss:  0.8770202\n",
      "Epoch:  247\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0222123\n",
      "Validation Loss:  0.8765253\n",
      "Epoch:  248\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0224874\n",
      "Validation Loss:  0.8756851\n",
      "Epoch:  249\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0218612\n",
      "Validation Loss:  0.87684107\n",
      "Epoch:  250\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0201266\n",
      "Validation Loss:  0.875278\n",
      "Epoch:  251\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0211405\n",
      "Validation Loss:  0.8752163\n",
      "Epoch:  252\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0210836\n",
      "Validation Loss:  0.8738874\n",
      "Epoch:  253\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0193708\n",
      "Validation Loss:  0.8743692\n",
      "Epoch:  254\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0240977\n",
      "Validation Loss:  0.8732428\n",
      "Epoch:  255\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0227292\n",
      "Validation Loss:  0.87339556\n",
      "Epoch:  256\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0169283\n",
      "Validation Loss:  0.87167895\n",
      "Epoch:  257\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0167243\n",
      "Validation Loss:  0.8721904\n",
      "Epoch:  258\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0177848\n",
      "Validation Loss:  0.87176085\n",
      "Epoch:  259\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0181243\n",
      "Validation Loss:  0.870973\n",
      "Epoch:  260\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0168474\n",
      "Validation Loss:  0.87008715\n",
      "Epoch:  261\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.017387\n",
      "Validation Loss:  0.87084574\n",
      "Epoch:  262\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0206624\n",
      "Validation Loss:  0.8692866\n",
      "Epoch:  263\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0203782\n",
      "Validation Loss:  0.86980826\n",
      "Epoch:  264\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0166689\n",
      "Validation Loss:  0.86887324\n",
      "Epoch:  265\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.015197\n",
      "Validation Loss:  0.9847798\n",
      "Epoch:  266\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0146927\n",
      "Validation Loss:  0.8679509\n",
      "Epoch:  267\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0158488\n",
      "Validation Loss:  0.8675171\n",
      "Epoch:  268\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.017807\n",
      "Validation Loss:  0.8679939\n",
      "Epoch:  269\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0135487\n",
      "Validation Loss:  0.86706173\n",
      "Epoch:  270\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0124975\n",
      "Validation Loss:  0.8664419\n",
      "Epoch:  271\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0122021\n",
      "Validation Loss:  0.86570895\n",
      "Epoch:  272\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.012899\n",
      "Validation Loss:  0.86584705\n",
      "Epoch:  273\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0115454\n",
      "Validation Loss:  0.8652057\n",
      "Epoch:  274\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0096585\n",
      "Validation Loss:  0.8654928\n",
      "Epoch:  275\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0109572\n",
      "Validation Loss:  0.86465377\n",
      "Epoch:  276\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0103165\n",
      "Validation Loss:  0.8637576\n",
      "Epoch:  277\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0100839\n",
      "Validation Loss:  0.86344814\n",
      "Epoch:  278\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.008004\n",
      "Validation Loss:  0.86257166\n",
      "Epoch:  279\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0135622\n",
      "Validation Loss:  0.8633648\n",
      "Epoch:  280\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0140278\n",
      "Validation Loss:  0.8626414\n",
      "Epoch:  281\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0084991\n",
      "Validation Loss:  0.8623037\n",
      "Epoch:  282\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0081015\n",
      "Validation Loss:  0.86133736\n",
      "Epoch:  283\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0061759\n",
      "Validation Loss:  0.86214584\n",
      "Epoch:  284\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0076165\n",
      "Validation Loss:  0.860194\n",
      "Epoch:  285\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.010795\n",
      "Validation Loss:  0.8602301\n",
      "Epoch:  286\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.006878\n",
      "Validation Loss:  0.86017615\n",
      "Epoch:  287\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0078269\n",
      "Validation Loss:  0.8599202\n",
      "Epoch:  288\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0057029\n",
      "Validation Loss:  0.85852164\n",
      "Epoch:  289\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0044271\n",
      "Validation Loss:  0.85857064\n",
      "Epoch:  290\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0061324\n",
      "Validation Loss:  0.8586946\n",
      "Epoch:  291\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.004855\n",
      "Validation Loss:  0.8579151\n",
      "Epoch:  292\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0050405\n",
      "Validation Loss:  0.858566\n",
      "Epoch:  293\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0030736\n",
      "Validation Loss:  0.8572391\n",
      "Epoch:  294\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0037062\n",
      "Validation Loss:  0.856459\n",
      "Epoch:  295\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0045823\n",
      "Validation Loss:  0.8572628\n",
      "Epoch:  296\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0023799\n",
      "Validation Loss:  0.8568037\n",
      "Epoch:  297\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0025523\n",
      "Validation Loss:  0.85605377\n",
      "Epoch:  298\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0077243\n",
      "Validation Loss:  0.8558404\n",
      "Epoch:  299\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0030571\n",
      "Validation Loss:  0.85502595\n",
      "Epoch:  300\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0056355\n",
      "Validation Loss:  0.8546816\n",
      "Epoch:  301\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0014974\n",
      "Validation Loss:  0.8546997\n",
      "Epoch:  302\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0017917\n",
      "Validation Loss:  0.8545583\n",
      "Epoch:  303\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.99986535\n",
      "Validation Loss:  0.85346663\n",
      "Epoch:  304\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.99992514\n",
      "Validation Loss:  0.853038\n",
      "Epoch:  305\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  1.0008442\n",
      "Validation Loss:  0.8530237\n",
      "Epoch:  306\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9997112\n",
      "Validation Loss:  0.85234356\n",
      "Epoch:  307\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9995151\n",
      "Validation Loss:  0.85282165\n",
      "Epoch:  308\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.99985456\n",
      "Validation Loss:  0.85188377\n",
      "Epoch:  309\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9987832\n",
      "Validation Loss:  0.85126793\n",
      "Epoch:  310\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.99815524\n",
      "Validation Loss:  0.85103804\n",
      "Epoch:  311\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.99969405\n",
      "Validation Loss:  0.9701237\n",
      "Epoch:  312\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.99778235\n",
      "Validation Loss:  0.8517105\n",
      "Epoch:  313\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9964229\n",
      "Validation Loss:  0.85007876\n",
      "Epoch:  314\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.99832517\n",
      "Validation Loss:  0.85012627\n",
      "Epoch:  315\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.996982\n",
      "Validation Loss:  0.8497477\n",
      "Epoch:  316\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.997041\n",
      "Validation Loss:  0.84888\n",
      "Epoch:  317\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9961976\n",
      "Validation Loss:  0.8491798\n",
      "Epoch:  318\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9971483\n",
      "Validation Loss:  0.84859407\n",
      "Epoch:  319\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9997896\n",
      "Validation Loss:  0.8481141\n",
      "Epoch:  320\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.99567896\n",
      "Validation Loss:  0.84819466\n",
      "Epoch:  321\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9963571\n",
      "Validation Loss:  0.84760565\n",
      "Epoch:  322\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.99546856\n",
      "Validation Loss:  0.8474801\n",
      "Epoch:  323\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9959589\n",
      "Validation Loss:  0.8471851\n",
      "Epoch:  324\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.99521655\n",
      "Validation Loss:  0.8471088\n",
      "Epoch:  325\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9977144\n",
      "Validation Loss:  0.8463413\n",
      "Epoch:  326\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.99424285\n",
      "Validation Loss:  0.8461004\n",
      "Epoch:  327\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9931216\n",
      "Validation Loss:  0.84652334\n",
      "Epoch:  328\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9933144\n",
      "Validation Loss:  0.84587663\n",
      "Epoch:  329\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9932409\n",
      "Validation Loss:  0.84527063\n",
      "Epoch:  330\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9921864\n",
      "Validation Loss:  0.84451467\n",
      "Epoch:  331\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.99164444\n",
      "Validation Loss:  0.8445587\n",
      "Epoch:  332\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9913412\n",
      "Validation Loss:  0.84525055\n",
      "Epoch:  333\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.99513394\n",
      "Validation Loss:  0.8445621\n",
      "Epoch:  334\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9928421\n",
      "Validation Loss:  0.84356225\n",
      "Epoch:  335\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9917512\n",
      "Validation Loss:  0.84373474\n",
      "Epoch:  336\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9895991\n",
      "Validation Loss:  0.84373415\n",
      "Epoch:  337\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.99151945\n",
      "Validation Loss:  0.84449434\n",
      "Epoch:  338\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9913813\n",
      "Validation Loss:  0.8422941\n",
      "Epoch:  339\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9902389\n",
      "Validation Loss:  0.84207207\n",
      "Epoch:  340\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9900653\n",
      "Validation Loss:  0.84224826\n",
      "Epoch:  341\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.990378\n",
      "Validation Loss:  0.8415263\n",
      "Epoch:  342\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.98769385\n",
      "Validation Loss:  0.84173965\n",
      "Epoch:  343\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9893253\n",
      "Validation Loss:  0.84106475\n",
      "Epoch:  344\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9918365\n",
      "Validation Loss:  0.84060717\n",
      "Epoch:  345\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9884813\n",
      "Validation Loss:  0.84064424\n",
      "Epoch:  346\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9885424\n",
      "Validation Loss:  0.8408722\n",
      "Epoch:  347\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9870606\n",
      "Validation Loss:  0.84003526\n",
      "Epoch:  348\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9858778\n",
      "Validation Loss:  0.83965766\n",
      "Epoch:  349\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.99162203\n",
      "Validation Loss:  0.8400531\n",
      "Epoch:  350\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.98664564\n",
      "Validation Loss:  0.8389596\n",
      "Epoch:  351\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.98773324\n",
      "Validation Loss:  0.8390579\n",
      "Epoch:  352\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9865341\n",
      "Validation Loss:  0.83900726\n",
      "Epoch:  353\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9864341\n",
      "Validation Loss:  0.83845484\n",
      "Epoch:  354\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.99046624\n",
      "Validation Loss:  0.83789384\n",
      "Epoch:  355\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9857917\n",
      "Validation Loss:  0.83767813\n",
      "Epoch:  356\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.98336965\n",
      "Validation Loss:  0.83782625\n",
      "Epoch:  357\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.98757154\n",
      "Validation Loss:  0.8372248\n",
      "Epoch:  358\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9855064\n",
      "Validation Loss:  0.8369842\n",
      "Epoch:  359\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.98519003\n",
      "Validation Loss:  0.8368252\n",
      "Epoch:  360\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9841658\n",
      "Validation Loss:  0.8366911\n",
      "Epoch:  361\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9839853\n",
      "Validation Loss:  0.83617055\n",
      "Epoch:  362\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9843358\n",
      "Validation Loss:  0.8362421\n",
      "Epoch:  363\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9856549\n",
      "Validation Loss:  0.83574706\n",
      "Epoch:  364\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9846623\n",
      "Validation Loss:  0.8356228\n",
      "Epoch:  365\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9827433\n",
      "Validation Loss:  0.8352961\n",
      "Epoch:  366\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.98192835\n",
      "Validation Loss:  0.8361009\n",
      "Epoch:  367\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9850746\n",
      "Validation Loss:  0.8352686\n",
      "Epoch:  368\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.98258954\n",
      "Validation Loss:  0.83462816\n",
      "Epoch:  369\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.98181605\n",
      "Validation Loss:  0.8345046\n",
      "Epoch:  370\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9820265\n",
      "Validation Loss:  0.83397436\n",
      "Epoch:  371\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.98150086\n",
      "Validation Loss:  0.833743\n",
      "Epoch:  372\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.98083293\n",
      "Validation Loss:  0.8337261\n",
      "Epoch:  373\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9801132\n",
      "Validation Loss:  0.83330864\n",
      "Epoch:  374\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.98214453\n",
      "Validation Loss:  0.8330902\n",
      "Epoch:  375\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.98451513\n",
      "Validation Loss:  0.8334451\n",
      "Epoch:  376\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.98067474\n",
      "Validation Loss:  0.8333054\n",
      "Epoch:  377\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9820501\n",
      "Validation Loss:  0.8332515\n",
      "Epoch:  378\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9856013\n",
      "Validation Loss:  0.832234\n",
      "Epoch:  379\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.98000205\n",
      "Validation Loss:  0.831931\n",
      "Epoch:  380\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9811294\n",
      "Validation Loss:  0.8315423\n",
      "Epoch:  381\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9787415\n",
      "Validation Loss:  0.8316345\n",
      "Epoch:  382\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9798455\n",
      "Validation Loss:  0.831257\n",
      "Epoch:  383\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9800018\n",
      "Validation Loss:  0.8337999\n",
      "Epoch:  384\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.97966206\n",
      "Validation Loss:  0.83061945\n",
      "Epoch:  385\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9833725\n",
      "Validation Loss:  0.95092106\n",
      "Epoch:  386\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.97760206\n",
      "Validation Loss:  0.8302476\n",
      "Epoch:  387\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9795908\n",
      "Validation Loss:  0.8298892\n",
      "Epoch:  388\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.97814506\n",
      "Validation Loss:  0.8304535\n",
      "Epoch:  389\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9786021\n",
      "Validation Loss:  0.8294465\n",
      "Epoch:  390\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9807606\n",
      "Validation Loss:  0.82959384\n",
      "Epoch:  391\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.98241377\n",
      "Validation Loss:  0.8294867\n",
      "Epoch:  392\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.97898656\n",
      "Validation Loss:  0.8293528\n",
      "Epoch:  393\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.98028827\n",
      "Validation Loss:  0.82866704\n",
      "Epoch:  394\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.980674\n",
      "Validation Loss:  0.8285724\n",
      "Epoch:  395\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9754817\n",
      "Validation Loss:  0.8283042\n",
      "Epoch:  396\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.97723156\n",
      "Validation Loss:  0.8282301\n",
      "Epoch:  397\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9772856\n",
      "Validation Loss:  0.82803595\n",
      "Epoch:  398\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9761373\n",
      "Validation Loss:  0.8276621\n",
      "Epoch:  399\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9759338\n",
      "Validation Loss:  0.8273702\n",
      "Epoch:  400\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9746926\n",
      "Validation Loss:  0.8276863\n",
      "Epoch:  401\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.97488713\n",
      "Validation Loss:  0.8272894\n",
      "Epoch:  402\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9746934\n",
      "Validation Loss:  0.8266111\n",
      "Epoch:  403\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9741656\n",
      "Validation Loss:  0.8275784\n",
      "Epoch:  404\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9745666\n",
      "Validation Loss:  0.8268327\n",
      "Epoch:  405\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.97607094\n",
      "Validation Loss:  0.8261551\n",
      "Epoch:  406\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9747036\n",
      "Validation Loss:  0.82629734\n",
      "Epoch:  407\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9736286\n",
      "Validation Loss:  0.8263449\n",
      "Epoch:  408\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.97343963\n",
      "Validation Loss:  0.8259779\n",
      "Epoch:  409\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.97422945\n",
      "Validation Loss:  0.8252216\n",
      "Epoch:  410\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.973755\n",
      "Validation Loss:  0.8256274\n",
      "Epoch:  411\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9746785\n",
      "Validation Loss:  0.8254288\n",
      "Epoch:  412\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9736014\n",
      "Validation Loss:  0.82509273\n",
      "Epoch:  413\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9708911\n",
      "Validation Loss:  0.824957\n",
      "Epoch:  414\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.974222\n",
      "Validation Loss:  0.8244472\n",
      "Epoch:  415\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9721502\n",
      "Validation Loss:  0.8244814\n",
      "Epoch:  416\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9722311\n",
      "Validation Loss:  0.8242293\n",
      "Epoch:  417\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.974396\n",
      "Validation Loss:  0.8242055\n",
      "Epoch:  418\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9735515\n",
      "Validation Loss:  0.82403654\n",
      "Epoch:  419\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9739656\n",
      "Validation Loss:  0.8238724\n",
      "Epoch:  420\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9729797\n",
      "Validation Loss:  0.8236942\n",
      "Epoch:  421\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9715111\n",
      "Validation Loss:  0.82321316\n",
      "Epoch:  422\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.97207314\n",
      "Validation Loss:  0.8229712\n",
      "Epoch:  423\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9711327\n",
      "Validation Loss:  0.82297283\n",
      "Epoch:  424\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9709815\n",
      "Validation Loss:  0.8227448\n",
      "Epoch:  425\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.97069806\n",
      "Validation Loss:  0.8223149\n",
      "Epoch:  426\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.969614\n",
      "Validation Loss:  0.8223113\n",
      "Epoch:  427\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9705124\n",
      "Validation Loss:  0.82193696\n",
      "Epoch:  428\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9710774\n",
      "Validation Loss:  0.82188123\n",
      "Epoch:  429\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.97385275\n",
      "Validation Loss:  0.8218511\n",
      "Epoch:  430\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.97087264\n",
      "Validation Loss:  0.82210195\n",
      "Epoch:  431\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96874434\n",
      "Validation Loss:  0.8214574\n",
      "Epoch:  432\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9714846\n",
      "Validation Loss:  0.8211221\n",
      "Epoch:  433\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.97051275\n",
      "Validation Loss:  0.8213965\n",
      "Epoch:  434\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.97107816\n",
      "Validation Loss:  0.8208599\n",
      "Epoch:  435\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96891826\n",
      "Validation Loss:  0.82047874\n",
      "Epoch:  436\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.97110486\n",
      "Validation Loss:  0.82057947\n",
      "Epoch:  437\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9688043\n",
      "Validation Loss:  0.82033646\n",
      "Epoch:  438\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9695973\n",
      "Validation Loss:  0.82032454\n",
      "Epoch:  439\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9698528\n",
      "Validation Loss:  0.8196007\n",
      "Epoch:  440\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9679951\n",
      "Validation Loss:  0.8196803\n",
      "Epoch:  441\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9666604\n",
      "Validation Loss:  0.8196859\n",
      "Epoch:  442\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9691282\n",
      "Validation Loss:  0.8194209\n",
      "Epoch:  443\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9661598\n",
      "Validation Loss:  0.819657\n",
      "Epoch:  444\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9691663\n",
      "Validation Loss:  0.8190722\n",
      "Epoch:  445\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9671874\n",
      "Validation Loss:  0.8189274\n",
      "Epoch:  446\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96786475\n",
      "Validation Loss:  0.8185521\n",
      "Epoch:  447\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96686023\n",
      "Validation Loss:  0.81853056\n",
      "Epoch:  448\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96866906\n",
      "Validation Loss:  0.8183735\n",
      "Epoch:  449\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96663594\n",
      "Validation Loss:  0.81883514\n",
      "Epoch:  450\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9697783\n",
      "Validation Loss:  0.818556\n",
      "Epoch:  451\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9665425\n",
      "Validation Loss:  0.81814826\n",
      "Epoch:  452\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.97245866\n",
      "Validation Loss:  0.8183637\n",
      "Epoch:  453\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.97099286\n",
      "Validation Loss:  0.8175686\n",
      "Epoch:  454\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96456915\n",
      "Validation Loss:  0.8173891\n",
      "Epoch:  455\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.97060907\n",
      "Validation Loss:  0.8173812\n",
      "Epoch:  456\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96726555\n",
      "Validation Loss:  0.8172494\n",
      "Epoch:  457\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96535885\n",
      "Validation Loss:  0.81692415\n",
      "Epoch:  458\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9646516\n",
      "Validation Loss:  0.816943\n",
      "Epoch:  459\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9667054\n",
      "Validation Loss:  0.81669533\n",
      "Epoch:  460\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96510035\n",
      "Validation Loss:  0.8168236\n",
      "Epoch:  461\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9677174\n",
      "Validation Loss:  0.9390989\n",
      "Epoch:  462\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96430624\n",
      "Validation Loss:  0.8165199\n",
      "Epoch:  463\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9645554\n",
      "Validation Loss:  0.8170031\n",
      "Epoch:  464\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9641063\n",
      "Validation Loss:  0.8160216\n",
      "Epoch:  465\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9641712\n",
      "Validation Loss:  0.815854\n",
      "Epoch:  466\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9628115\n",
      "Validation Loss:  0.8156002\n",
      "Epoch:  467\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9665148\n",
      "Validation Loss:  0.81588036\n",
      "Epoch:  468\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96417725\n",
      "Validation Loss:  0.81537867\n",
      "Epoch:  469\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9632359\n",
      "Validation Loss:  0.8154236\n",
      "Epoch:  470\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9638251\n",
      "Validation Loss:  0.81510967\n",
      "Epoch:  471\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9637894\n",
      "Validation Loss:  0.9380171\n",
      "Epoch:  472\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9633071\n",
      "Validation Loss:  0.8152\n",
      "Epoch:  473\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9641033\n",
      "Validation Loss:  0.93746597\n",
      "Epoch:  474\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9631659\n",
      "Validation Loss:  0.8149256\n",
      "Epoch:  475\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9681478\n",
      "Validation Loss:  0.8144621\n",
      "Epoch:  476\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96280783\n",
      "Validation Loss:  0.9372515\n",
      "Epoch:  477\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9645598\n",
      "Validation Loss:  0.81469005\n",
      "Epoch:  478\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9609787\n",
      "Validation Loss:  0.8137843\n",
      "Epoch:  479\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.961741\n",
      "Validation Loss:  0.9366201\n",
      "Epoch:  480\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95903075\n",
      "Validation Loss:  0.8137541\n",
      "Epoch:  481\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96317494\n",
      "Validation Loss:  0.81354207\n",
      "Epoch:  482\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9637367\n",
      "Validation Loss:  0.8133599\n",
      "Epoch:  483\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9582161\n",
      "Validation Loss:  0.8133997\n",
      "Epoch:  484\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9619471\n",
      "Validation Loss:  0.81322384\n",
      "Epoch:  485\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96090144\n",
      "Validation Loss:  0.8129142\n",
      "Epoch:  486\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9703125\n",
      "Validation Loss:  0.81328434\n",
      "Epoch:  487\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96037185\n",
      "Validation Loss:  0.81273764\n",
      "Epoch:  488\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96131134\n",
      "Validation Loss:  0.8128096\n",
      "Epoch:  489\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96162164\n",
      "Validation Loss:  0.8126788\n",
      "Epoch:  490\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9654204\n",
      "Validation Loss:  0.8125265\n",
      "Epoch:  491\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.963581\n",
      "Validation Loss:  0.8122473\n",
      "Epoch:  492\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9602703\n",
      "Validation Loss:  0.8123483\n",
      "Epoch:  493\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95841384\n",
      "Validation Loss:  0.8118302\n",
      "Epoch:  494\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9603608\n",
      "Validation Loss:  0.81188637\n",
      "Epoch:  495\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96259356\n",
      "Validation Loss:  0.81169397\n",
      "Epoch:  496\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95940006\n",
      "Validation Loss:  0.81164366\n",
      "Epoch:  497\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9592655\n",
      "Validation Loss:  0.81129843\n",
      "Epoch:  498\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96023875\n",
      "Validation Loss:  0.8115964\n",
      "Epoch:  499\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9598008\n",
      "Validation Loss:  0.8115374\n",
      "Epoch:  500\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9633447\n",
      "Validation Loss:  0.81128645\n",
      "Epoch:  501\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95998424\n",
      "Validation Loss:  0.8108509\n",
      "Epoch:  502\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95943135\n",
      "Validation Loss:  0.8108067\n",
      "Epoch:  503\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9601509\n",
      "Validation Loss:  0.8105652\n",
      "Epoch:  504\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9630795\n",
      "Validation Loss:  0.81087697\n",
      "Epoch:  505\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9591755\n",
      "Validation Loss:  0.8104202\n",
      "Epoch:  506\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9585218\n",
      "Validation Loss:  0.93382025\n",
      "Epoch:  507\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9589848\n",
      "Validation Loss:  0.81023836\n",
      "Epoch:  508\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95808524\n",
      "Validation Loss:  0.8100072\n",
      "Epoch:  509\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96432877\n",
      "Validation Loss:  0.8099662\n",
      "Epoch:  510\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96199673\n",
      "Validation Loss:  0.80988634\n",
      "Epoch:  511\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95886254\n",
      "Validation Loss:  0.80967295\n",
      "Epoch:  512\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95825887\n",
      "Validation Loss:  0.8098775\n",
      "Epoch:  513\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95741266\n",
      "Validation Loss:  0.80931604\n",
      "Epoch:  514\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95706123\n",
      "Validation Loss:  0.8093243\n",
      "Epoch:  515\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9571178\n",
      "Validation Loss:  0.8091758\n",
      "Epoch:  516\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95604336\n",
      "Validation Loss:  0.80909455\n",
      "Epoch:  517\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9581735\n",
      "Validation Loss:  0.8088748\n",
      "Epoch:  518\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9575755\n",
      "Validation Loss:  0.8088942\n",
      "Epoch:  519\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9577978\n",
      "Validation Loss:  0.8088005\n",
      "Epoch:  520\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95774657\n",
      "Validation Loss:  0.80864125\n",
      "Epoch:  521\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95869493\n",
      "Validation Loss:  0.8084589\n",
      "Epoch:  522\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9561267\n",
      "Validation Loss:  0.8092955\n",
      "Epoch:  523\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.957916\n",
      "Validation Loss:  0.8082075\n",
      "Epoch:  524\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95612186\n",
      "Validation Loss:  0.80817693\n",
      "Epoch:  525\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9573211\n",
      "Validation Loss:  0.8079351\n",
      "Epoch:  526\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9554474\n",
      "Validation Loss:  0.80839777\n",
      "Epoch:  527\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95578676\n",
      "Validation Loss:  0.8078374\n",
      "Epoch:  528\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95416987\n",
      "Validation Loss:  0.80775493\n",
      "Epoch:  529\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.958989\n",
      "Validation Loss:  0.8076037\n",
      "Epoch:  530\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9562898\n",
      "Validation Loss:  0.80758685\n",
      "Epoch:  531\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.96075\n",
      "Validation Loss:  0.8073675\n",
      "Epoch:  532\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.959261\n",
      "Validation Loss:  0.80718696\n",
      "Epoch:  533\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95548683\n",
      "Validation Loss:  0.80719936\n",
      "Epoch:  534\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95579195\n",
      "Validation Loss:  0.80710095\n",
      "Epoch:  535\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95622355\n",
      "Validation Loss:  0.8070248\n",
      "Epoch:  536\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9554541\n",
      "Validation Loss:  0.80702955\n",
      "Epoch:  537\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95424044\n",
      "Validation Loss:  0.80693096\n",
      "Epoch:  538\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95560545\n",
      "Validation Loss:  0.8067134\n",
      "Epoch:  539\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9544517\n",
      "Validation Loss:  0.80668694\n",
      "Epoch:  540\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9519187\n",
      "Validation Loss:  0.80647576\n",
      "Epoch:  541\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9543477\n",
      "Validation Loss:  0.80642265\n",
      "Epoch:  542\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95745575\n",
      "Validation Loss:  0.80622244\n",
      "Epoch:  543\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9580143\n",
      "Validation Loss:  0.80612695\n",
      "Epoch:  544\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95667326\n",
      "Validation Loss:  0.80630237\n",
      "Epoch:  545\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9572597\n",
      "Validation Loss:  0.8060673\n",
      "Epoch:  546\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9577046\n",
      "Validation Loss:  0.8058817\n",
      "Epoch:  547\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9527847\n",
      "Validation Loss:  0.8059474\n",
      "Epoch:  548\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9508501\n",
      "Validation Loss:  0.805591\n",
      "Epoch:  549\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95764667\n",
      "Validation Loss:  0.805729\n",
      "Epoch:  550\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95417416\n",
      "Validation Loss:  0.8054023\n",
      "Epoch:  551\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9526225\n",
      "Validation Loss:  0.8053791\n",
      "Epoch:  552\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9535518\n",
      "Validation Loss:  0.80554444\n",
      "Epoch:  553\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9530329\n",
      "Validation Loss:  0.92967176\n",
      "Epoch:  554\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9527663\n",
      "Validation Loss:  0.80506843\n",
      "Epoch:  555\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9531227\n",
      "Validation Loss:  0.805097\n",
      "Epoch:  556\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9589649\n",
      "Validation Loss:  0.80499923\n",
      "Epoch:  557\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95493746\n",
      "Validation Loss:  0.80479896\n",
      "Epoch:  558\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95220274\n",
      "Validation Loss:  0.80482644\n",
      "Epoch:  559\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95337766\n",
      "Validation Loss:  0.8050706\n",
      "Epoch:  560\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9506236\n",
      "Validation Loss:  0.80447775\n",
      "Epoch:  561\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95256555\n",
      "Validation Loss:  0.8048312\n",
      "Epoch:  562\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9526479\n",
      "Validation Loss:  0.80471164\n",
      "Epoch:  563\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95421076\n",
      "Validation Loss:  0.8047052\n",
      "Epoch:  564\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9523864\n",
      "Validation Loss:  0.8044505\n",
      "Epoch:  565\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9555252\n",
      "Validation Loss:  0.8041116\n",
      "Epoch:  566\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95257187\n",
      "Validation Loss:  0.80413955\n",
      "Epoch:  567\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95885456\n",
      "Validation Loss:  0.8038508\n",
      "Epoch:  568\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95233285\n",
      "Validation Loss:  0.8040677\n",
      "Epoch:  569\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9553733\n",
      "Validation Loss:  0.8037883\n",
      "Epoch:  570\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9515786\n",
      "Validation Loss:  0.8038025\n",
      "Epoch:  571\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9543404\n",
      "Validation Loss:  0.928342\n",
      "Epoch:  572\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9519958\n",
      "Validation Loss:  0.80354035\n",
      "Epoch:  573\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9558186\n",
      "Validation Loss:  0.8034111\n",
      "Epoch:  574\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95169216\n",
      "Validation Loss:  0.80345786\n",
      "Epoch:  575\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95170355\n",
      "Validation Loss:  0.803239\n",
      "Epoch:  576\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95182383\n",
      "Validation Loss:  0.803298\n",
      "Epoch:  577\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9492199\n",
      "Validation Loss:  0.92765903\n",
      "Epoch:  578\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9515716\n",
      "Validation Loss:  0.8029679\n",
      "Epoch:  579\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95070875\n",
      "Validation Loss:  0.8034827\n",
      "Epoch:  580\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9501781\n",
      "Validation Loss:  0.80360496\n",
      "Epoch:  581\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95480394\n",
      "Validation Loss:  0.80269045\n",
      "Epoch:  582\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95197904\n",
      "Validation Loss:  0.8027178\n",
      "Epoch:  583\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9491016\n",
      "Validation Loss:  0.80325955\n",
      "Epoch:  584\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9490513\n",
      "Validation Loss:  0.8026763\n",
      "Epoch:  585\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94900966\n",
      "Validation Loss:  0.80284154\n",
      "Epoch:  586\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9508104\n",
      "Validation Loss:  0.80276066\n",
      "Epoch:  587\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9541111\n",
      "Validation Loss:  0.80223\n",
      "Epoch:  588\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9473781\n",
      "Validation Loss:  0.9268562\n",
      "Epoch:  589\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9489625\n",
      "Validation Loss:  0.80206907\n",
      "Epoch:  590\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9493132\n",
      "Validation Loss:  0.8018894\n",
      "Epoch:  591\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9439734\n",
      "Validation Loss:  0.8020951\n",
      "Epoch:  592\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9577068\n",
      "Validation Loss:  0.8020514\n",
      "Epoch:  593\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9521531\n",
      "Validation Loss:  0.80179644\n",
      "Epoch:  594\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9516403\n",
      "Validation Loss:  0.80177015\n",
      "Epoch:  595\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9476821\n",
      "Validation Loss:  0.8015619\n",
      "Epoch:  596\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9523483\n",
      "Validation Loss:  0.80196035\n",
      "Epoch:  597\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.946247\n",
      "Validation Loss:  0.8014603\n",
      "Epoch:  598\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9497599\n",
      "Validation Loss:  0.80144846\n",
      "Epoch:  599\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94921076\n",
      "Validation Loss:  0.8015421\n",
      "Epoch:  600\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9509388\n",
      "Validation Loss:  0.80121934\n",
      "Epoch:  601\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94621456\n",
      "Validation Loss:  0.8011532\n",
      "Epoch:  602\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9487629\n",
      "Validation Loss:  0.8012886\n",
      "Epoch:  603\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9480449\n",
      "Validation Loss:  0.801072\n",
      "Epoch:  604\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95001274\n",
      "Validation Loss:  0.92587906\n",
      "Epoch:  605\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9466291\n",
      "Validation Loss:  0.80116946\n",
      "Epoch:  606\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94800305\n",
      "Validation Loss:  0.80099875\n",
      "Epoch:  607\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9450176\n",
      "Validation Loss:  0.80077296\n",
      "Epoch:  608\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9504238\n",
      "Validation Loss:  0.8005667\n",
      "Epoch:  609\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94733\n",
      "Validation Loss:  0.80070204\n",
      "Epoch:  610\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9504391\n",
      "Validation Loss:  0.80066115\n",
      "Epoch:  611\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9513061\n",
      "Validation Loss:  0.8005431\n",
      "Epoch:  612\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9487533\n",
      "Validation Loss:  0.8003808\n",
      "Epoch:  613\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9490701\n",
      "Validation Loss:  0.80080986\n",
      "Epoch:  614\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9442715\n",
      "Validation Loss:  0.80031306\n",
      "Epoch:  615\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9449961\n",
      "Validation Loss:  0.9252771\n",
      "Epoch:  616\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94066924\n",
      "Validation Loss:  0.8001111\n",
      "Epoch:  617\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9495684\n",
      "Validation Loss:  0.8001941\n",
      "Epoch:  618\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94762784\n",
      "Validation Loss:  0.80028194\n",
      "Epoch:  619\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9438748\n",
      "Validation Loss:  0.8013169\n",
      "Epoch:  620\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94467205\n",
      "Validation Loss:  0.79989207\n",
      "Epoch:  621\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9438284\n",
      "Validation Loss:  0.7999721\n",
      "Epoch:  622\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9504319\n",
      "Validation Loss:  0.7999063\n",
      "Epoch:  623\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94441855\n",
      "Validation Loss:  0.7998594\n",
      "Epoch:  624\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94652164\n",
      "Validation Loss:  0.80008394\n",
      "Epoch:  625\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9439767\n",
      "Validation Loss:  0.8009421\n",
      "Epoch:  626\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9397848\n",
      "Validation Loss:  0.8000826\n",
      "Epoch:  627\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9440913\n",
      "Validation Loss:  0.7994429\n",
      "Epoch:  628\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9399732\n",
      "Validation Loss:  0.7996298\n",
      "Epoch:  629\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94850767\n",
      "Validation Loss:  0.7994585\n",
      "Epoch:  630\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9438929\n",
      "Validation Loss:  0.8000487\n",
      "Epoch:  631\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.95390266\n",
      "Validation Loss:  0.7996578\n",
      "Epoch:  632\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9479442\n",
      "Validation Loss:  0.79938316\n",
      "Epoch:  633\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9403423\n",
      "Validation Loss:  0.79929\n",
      "Epoch:  634\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9440533\n",
      "Validation Loss:  0.7996888\n",
      "Epoch:  635\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9436017\n",
      "Validation Loss:  0.7996556\n",
      "Epoch:  636\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9439736\n",
      "Validation Loss:  0.7992741\n",
      "Epoch:  637\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94431776\n",
      "Validation Loss:  0.7989575\n",
      "Epoch:  638\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.943609\n",
      "Validation Loss:  0.79909474\n",
      "Epoch:  639\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9446698\n",
      "Validation Loss:  0.79998887\n",
      "Epoch:  640\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94676065\n",
      "Validation Loss:  0.7988919\n",
      "Epoch:  641\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9422823\n",
      "Validation Loss:  0.7989231\n",
      "Epoch:  642\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94456816\n",
      "Validation Loss:  0.7988381\n",
      "Epoch:  643\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.943581\n",
      "Validation Loss:  0.79862255\n",
      "Epoch:  644\n",
      "Training Accuracy:  0.987012987012987\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.93984246\n",
      "Validation Loss:  0.7984958\n",
      "Epoch:  645\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94220006\n",
      "Validation Loss:  0.7985573\n",
      "Epoch:  646\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94061023\n",
      "Validation Loss:  0.7997921\n",
      "Epoch:  647\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.93810743\n",
      "Validation Loss:  0.80006206\n",
      "Epoch:  648\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94578356\n",
      "Validation Loss:  0.798752\n",
      "Epoch:  649\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94263446\n",
      "Validation Loss:  0.7985297\n",
      "Epoch:  650\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94213146\n",
      "Validation Loss:  0.79813766\n",
      "Epoch:  651\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94294494\n",
      "Validation Loss:  0.7980711\n",
      "Epoch:  652\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.93819827\n",
      "Validation Loss:  0.79939604\n",
      "Epoch:  653\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9432597\n",
      "Validation Loss:  0.79798925\n",
      "Epoch:  654\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94578063\n",
      "Validation Loss:  0.7981309\n",
      "Epoch:  655\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9369961\n",
      "Validation Loss:  0.798134\n",
      "Epoch:  656\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9452362\n",
      "Validation Loss:  0.79785955\n",
      "Epoch:  657\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9350547\n",
      "Validation Loss:  0.7979303\n",
      "Epoch:  658\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.93741745\n",
      "Validation Loss:  0.79812706\n",
      "Epoch:  659\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9383041\n",
      "Validation Loss:  0.7984366\n",
      "Epoch:  660\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.93652654\n",
      "Validation Loss:  0.7978867\n",
      "Epoch:  661\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9445503\n",
      "Validation Loss:  0.7980239\n",
      "Epoch:  662\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9406124\n",
      "Validation Loss:  0.7976341\n",
      "Epoch:  663\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.93536323\n",
      "Validation Loss:  0.7976974\n",
      "Epoch:  664\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9359782\n",
      "Validation Loss:  0.7981056\n",
      "Epoch:  665\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9386847\n",
      "Validation Loss:  0.7978479\n",
      "Epoch:  666\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94208413\n",
      "Validation Loss:  0.7978355\n",
      "Epoch:  667\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9354369\n",
      "Validation Loss:  0.7979752\n",
      "Epoch:  668\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9433715\n",
      "Validation Loss:  0.79747105\n",
      "Epoch:  669\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.93688476\n",
      "Validation Loss:  0.79741186\n",
      "Epoch:  670\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.93399745\n",
      "Validation Loss:  0.7973749\n",
      "Epoch:  671\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94168776\n",
      "Validation Loss:  0.7973049\n",
      "Epoch:  672\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.93623215\n",
      "Validation Loss:  0.79756385\n",
      "Epoch:  673\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9389618\n",
      "Validation Loss:  0.7972933\n",
      "Epoch:  674\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9360559\n",
      "Validation Loss:  0.79732925\n",
      "Epoch:  675\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94273955\n",
      "Validation Loss:  0.7979365\n",
      "Epoch:  676\n",
      "Training Accuracy:  0.987012987012987\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.93766934\n",
      "Validation Loss:  0.79720956\n",
      "Epoch:  677\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9350878\n",
      "Validation Loss:  0.7975112\n",
      "Epoch:  678\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.93678683\n",
      "Validation Loss:  0.7971607\n",
      "Epoch:  679\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9377715\n",
      "Validation Loss:  0.7972899\n",
      "Epoch:  680\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9344658\n",
      "Validation Loss:  0.79685897\n",
      "Epoch:  681\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.936136\n",
      "Validation Loss:  0.79895765\n",
      "Epoch:  682\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.93462706\n",
      "Validation Loss:  0.9227085\n",
      "Epoch:  683\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9428927\n",
      "Validation Loss:  0.9224251\n",
      "Epoch:  684\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.93907547\n",
      "Validation Loss:  0.7966239\n",
      "Epoch:  685\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9414219\n",
      "Validation Loss:  0.7974803\n",
      "Epoch:  686\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9316076\n",
      "Validation Loss:  0.79740465\n",
      "Epoch:  687\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9377424\n",
      "Validation Loss:  0.7976219\n",
      "Epoch:  688\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94166034\n",
      "Validation Loss:  0.79667056\n",
      "Epoch:  689\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.93038106\n",
      "Validation Loss:  0.79654247\n",
      "Epoch:  690\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.93515974\n",
      "Validation Loss:  0.79680634\n",
      "Epoch:  691\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.92658716\n",
      "Validation Loss:  0.7972245\n",
      "Epoch:  692\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.931965\n",
      "Validation Loss:  0.7967512\n",
      "Epoch:  693\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.94051665\n",
      "Validation Loss:  0.7964191\n",
      "Epoch:  694\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9376048\n",
      "Validation Loss:  0.7969457\n",
      "Epoch:  695\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.92783016\n",
      "Validation Loss:  0.7967563\n",
      "Epoch:  696\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.92718333\n",
      "Validation Loss:  0.7968221\n",
      "Epoch:  697\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.937736\n",
      "Validation Loss:  0.7962861\n",
      "Epoch:  698\n",
      "Training Accuracy:  0.987012987012987\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9252298\n",
      "Validation Loss:  0.79639286\n",
      "Epoch:  699\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9352812\n",
      "Validation Loss:  0.79690015\n",
      "Epoch:  700\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.93321353\n",
      "Validation Loss:  0.7962042\n",
      "Epoch:  701\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.93117076\n",
      "Validation Loss:  0.79644984\n",
      "Epoch:  702\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9325307\n",
      "Validation Loss:  0.79706365\n",
      "Epoch:  703\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.93256766\n",
      "Validation Loss:  0.79616654\n",
      "Epoch:  704\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9279845\n",
      "Validation Loss:  0.79627\n",
      "Epoch:  705\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9342016\n",
      "Validation Loss:  0.79589593\n",
      "Epoch:  706\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9345919\n",
      "Validation Loss:  0.79668623\n",
      "Epoch:  707\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.93404144\n",
      "Validation Loss:  0.7983902\n",
      "Epoch:  708\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9302507\n",
      "Validation Loss:  0.7964996\n",
      "Epoch:  709\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.931268\n",
      "Validation Loss:  0.7967141\n",
      "Epoch:  710\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9323053\n",
      "Validation Loss:  0.7967463\n",
      "Epoch:  711\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.93330425\n",
      "Validation Loss:  0.7959407\n",
      "Epoch:  712\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9335734\n",
      "Validation Loss:  0.7960425\n",
      "Epoch:  713\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9284867\n",
      "Validation Loss:  0.7958544\n",
      "Epoch:  714\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9332799\n",
      "Validation Loss:  0.92161494\n",
      "Epoch:  715\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9248204\n",
      "Validation Loss:  0.7959723\n",
      "Epoch:  716\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9262454\n",
      "Validation Loss:  0.79585886\n",
      "Epoch:  717\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9205233\n",
      "Validation Loss:  0.7956663\n",
      "Epoch:  718\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9176071\n",
      "Validation Loss:  0.79631656\n",
      "Epoch:  719\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9284457\n",
      "Validation Loss:  0.7959532\n",
      "Epoch:  720\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9244906\n",
      "Validation Loss:  0.79620856\n",
      "Epoch:  721\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9226328\n",
      "Validation Loss:  0.79618835\n",
      "Epoch:  722\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9260938\n",
      "Validation Loss:  0.7958742\n",
      "Epoch:  723\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9213949\n",
      "Validation Loss:  0.79558927\n",
      "Epoch:  724\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9244492\n",
      "Validation Loss:  0.7954842\n",
      "Epoch:  725\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9272531\n",
      "Validation Loss:  0.7953761\n",
      "Epoch:  726\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9311656\n",
      "Validation Loss:  0.79549015\n",
      "Epoch:  727\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9222974\n",
      "Validation Loss:  0.79626316\n",
      "Epoch:  728\n",
      "Training Accuracy:  0.987012987012987\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9270618\n",
      "Validation Loss:  0.9217454\n",
      "Epoch:  729\n",
      "Training Accuracy:  0.987012987012987\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9233556\n",
      "Validation Loss:  0.7956487\n",
      "Epoch:  730\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9305256\n",
      "Validation Loss:  0.7951046\n",
      "Epoch:  731\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9344763\n",
      "Validation Loss:  0.7963217\n",
      "Epoch:  732\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.92258763\n",
      "Validation Loss:  0.79568374\n",
      "Epoch:  733\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9254469\n",
      "Validation Loss:  0.7954368\n",
      "Epoch:  734\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9172307\n",
      "Validation Loss:  0.79490614\n",
      "Epoch:  735\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9214662\n",
      "Validation Loss:  0.79629725\n",
      "Epoch:  736\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.92068595\n",
      "Validation Loss:  0.7950658\n",
      "Epoch:  737\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.92509586\n",
      "Validation Loss:  0.7965471\n",
      "Epoch:  738\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9221428\n",
      "Validation Loss:  0.7955933\n",
      "Epoch:  739\n",
      "Training Accuracy:  0.987012987012987\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.92662233\n",
      "Validation Loss:  0.79527456\n",
      "Epoch:  740\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.918913\n",
      "Validation Loss:  0.7957686\n",
      "Epoch:  741\n",
      "Training Accuracy:  0.987012987012987\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.92549527\n",
      "Validation Loss:  0.79484314\n",
      "Epoch:  742\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9093846\n",
      "Validation Loss:  0.7958043\n",
      "Epoch:  743\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.919122\n",
      "Validation Loss:  0.7974849\n",
      "Epoch:  744\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.91995424\n",
      "Validation Loss:  0.79526144\n",
      "Epoch:  745\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.91769856\n",
      "Validation Loss:  0.79488575\n",
      "Epoch:  746\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.92424273\n",
      "Validation Loss:  0.7954132\n",
      "Epoch:  747\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9117593\n",
      "Validation Loss:  0.9210684\n",
      "Epoch:  748\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.92596203\n",
      "Validation Loss:  0.7946981\n",
      "Epoch:  749\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.91567\n",
      "Validation Loss:  0.9208608\n",
      "Epoch:  750\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.91972184\n",
      "Validation Loss:  0.79564047\n",
      "Epoch:  751\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.914765\n",
      "Validation Loss:  0.79473513\n",
      "Epoch:  752\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.92971575\n",
      "Validation Loss:  0.79628646\n",
      "Epoch:  753\n",
      "Training Accuracy:  0.987012987012987\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.912758\n",
      "Validation Loss:  0.7948395\n",
      "Epoch:  754\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9133289\n",
      "Validation Loss:  0.7946695\n",
      "Epoch:  755\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.91426027\n",
      "Validation Loss:  0.7946712\n",
      "Epoch:  756\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.91190296\n",
      "Validation Loss:  0.79451525\n",
      "Epoch:  757\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.91437835\n",
      "Validation Loss:  0.79464895\n",
      "Epoch:  758\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.93120027\n",
      "Validation Loss:  0.7947356\n",
      "Epoch:  759\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9167713\n",
      "Validation Loss:  0.795947\n",
      "Epoch:  760\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.921337\n",
      "Validation Loss:  0.7948283\n",
      "Epoch:  761\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90913075\n",
      "Validation Loss:  0.7948658\n",
      "Epoch:  762\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90896684\n",
      "Validation Loss:  0.7950921\n",
      "Epoch:  763\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.92097235\n",
      "Validation Loss:  0.7955985\n",
      "Epoch:  764\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90945625\n",
      "Validation Loss:  0.79570657\n",
      "Epoch:  765\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9169732\n",
      "Validation Loss:  0.7961049\n",
      "Epoch:  766\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.91340953\n",
      "Validation Loss:  0.920959\n",
      "Epoch:  767\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9140491\n",
      "Validation Loss:  0.7944416\n",
      "Epoch:  768\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9100398\n",
      "Validation Loss:  0.79506975\n",
      "Epoch:  769\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9123484\n",
      "Validation Loss:  0.79530245\n",
      "Epoch:  770\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.922798\n",
      "Validation Loss:  0.79442483\n",
      "Epoch:  771\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9187751\n",
      "Validation Loss:  0.79427236\n",
      "Epoch:  772\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9203702\n",
      "Validation Loss:  0.7946559\n",
      "Epoch:  773\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.91707754\n",
      "Validation Loss:  0.79437745\n",
      "Epoch:  774\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.91332835\n",
      "Validation Loss:  0.7947113\n",
      "Epoch:  775\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9084358\n",
      "Validation Loss:  0.79470384\n",
      "Epoch:  776\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90977114\n",
      "Validation Loss:  0.79528797\n",
      "Epoch:  777\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.92187077\n",
      "Validation Loss:  0.79422814\n",
      "Epoch:  778\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9071682\n",
      "Validation Loss:  0.79480034\n",
      "Epoch:  779\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.916415\n",
      "Validation Loss:  0.7946137\n",
      "Epoch:  780\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.92423105\n",
      "Validation Loss:  0.7956754\n",
      "Epoch:  781\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9062417\n",
      "Validation Loss:  0.7941064\n",
      "Epoch:  782\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90494025\n",
      "Validation Loss:  0.79420185\n",
      "Epoch:  783\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.91222644\n",
      "Validation Loss:  0.79415095\n",
      "Epoch:  784\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9101957\n",
      "Validation Loss:  0.79518425\n",
      "Epoch:  785\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9085454\n",
      "Validation Loss:  0.7941872\n",
      "Epoch:  786\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.910199\n",
      "Validation Loss:  0.7943693\n",
      "Epoch:  787\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9090101\n",
      "Validation Loss:  0.79472786\n",
      "Epoch:  788\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90301394\n",
      "Validation Loss:  0.7940365\n",
      "Epoch:  789\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9103409\n",
      "Validation Loss:  0.7941228\n",
      "Epoch:  790\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9022064\n",
      "Validation Loss:  0.793812\n",
      "Epoch:  791\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9037232\n",
      "Validation Loss:  0.7939803\n",
      "Epoch:  792\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90878695\n",
      "Validation Loss:  0.7940379\n",
      "Epoch:  793\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9156204\n",
      "Validation Loss:  0.79403937\n",
      "Epoch:  794\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9112344\n",
      "Validation Loss:  0.79441595\n",
      "Epoch:  795\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.92199177\n",
      "Validation Loss:  0.7940199\n",
      "Epoch:  796\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.904801\n",
      "Validation Loss:  0.79460365\n",
      "Epoch:  797\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9002137\n",
      "Validation Loss:  0.79349595\n",
      "Epoch:  798\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9017378\n",
      "Validation Loss:  0.79342383\n",
      "Epoch:  799\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90414727\n",
      "Validation Loss:  0.793684\n",
      "Epoch:  800\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9190796\n",
      "Validation Loss:  0.7939018\n",
      "Epoch:  801\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9105231\n",
      "Validation Loss:  0.7935058\n",
      "Epoch:  802\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9066319\n",
      "Validation Loss:  0.7931424\n",
      "Epoch:  803\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9224828\n",
      "Validation Loss:  0.7945032\n",
      "Epoch:  804\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9171959\n",
      "Validation Loss:  0.79447323\n",
      "Epoch:  805\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9013171\n",
      "Validation Loss:  0.7941321\n",
      "Epoch:  806\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.91115576\n",
      "Validation Loss:  0.7950157\n",
      "Epoch:  807\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9035528\n",
      "Validation Loss:  0.7937015\n",
      "Epoch:  808\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9087984\n",
      "Validation Loss:  0.7938823\n",
      "Epoch:  809\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.9083136\n",
      "Validation Loss:  0.7972571\n",
      "Epoch:  810\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90319717\n",
      "Validation Loss:  0.79367006\n",
      "Epoch:  811\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90703636\n",
      "Validation Loss:  0.794548\n",
      "Epoch:  812\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.91835487\n",
      "Validation Loss:  0.7935862\n",
      "Epoch:  813\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.9017956\n",
      "Validation Loss:  0.7942348\n",
      "Epoch:  814\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9026533\n",
      "Validation Loss:  0.7933406\n",
      "Epoch:  815\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9198678\n",
      "Validation Loss:  0.7934465\n",
      "Epoch:  816\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.91237724\n",
      "Validation Loss:  0.79328245\n",
      "Epoch:  817\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.909355\n",
      "Validation Loss:  0.7935542\n",
      "Epoch:  818\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90414673\n",
      "Validation Loss:  0.7939823\n",
      "Epoch:  819\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9039519\n",
      "Validation Loss:  0.79432267\n",
      "Epoch:  820\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9105432\n",
      "Validation Loss:  0.7937951\n",
      "Epoch:  821\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.914903\n",
      "Validation Loss:  0.7936806\n",
      "Epoch:  822\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9307783\n",
      "Validation Loss:  0.79299027\n",
      "Epoch:  823\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9156511\n",
      "Validation Loss:  0.7929717\n",
      "Epoch:  824\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8987711\n",
      "Validation Loss:  0.797834\n",
      "Epoch:  825\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9143173\n",
      "Validation Loss:  0.79348487\n",
      "Epoch:  826\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89982736\n",
      "Validation Loss:  0.79385\n",
      "Epoch:  827\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89794576\n",
      "Validation Loss:  0.79259366\n",
      "Epoch:  828\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9114502\n",
      "Validation Loss:  0.7928872\n",
      "Epoch:  829\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9063849\n",
      "Validation Loss:  0.79294336\n",
      "Epoch:  830\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8980317\n",
      "Validation Loss:  0.7934578\n",
      "Epoch:  831\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9187538\n",
      "Validation Loss:  0.7925509\n",
      "Epoch:  832\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90737927\n",
      "Validation Loss:  0.7931813\n",
      "Epoch:  833\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90300184\n",
      "Validation Loss:  0.793561\n",
      "Epoch:  834\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90281713\n",
      "Validation Loss:  0.79384243\n",
      "Epoch:  835\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.9174258\n",
      "Validation Loss:  0.7943544\n",
      "Epoch:  836\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9020151\n",
      "Validation Loss:  0.792349\n",
      "Epoch:  837\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9048453\n",
      "Validation Loss:  0.7930794\n",
      "Epoch:  838\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9131946\n",
      "Validation Loss:  0.7959524\n",
      "Epoch:  839\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9056532\n",
      "Validation Loss:  0.7935338\n",
      "Epoch:  840\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8980231\n",
      "Validation Loss:  0.79365665\n",
      "Epoch:  841\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.91188216\n",
      "Validation Loss:  0.9193972\n",
      "Epoch:  842\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.9116451\n",
      "Validation Loss:  0.79258764\n",
      "Epoch:  843\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9074332\n",
      "Validation Loss:  0.79357785\n",
      "Epoch:  844\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9158762\n",
      "Validation Loss:  0.7934713\n",
      "Epoch:  845\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9025687\n",
      "Validation Loss:  0.793118\n",
      "Epoch:  846\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9108845\n",
      "Validation Loss:  0.79250246\n",
      "Epoch:  847\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9038222\n",
      "Validation Loss:  0.7936264\n",
      "Epoch:  848\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8975403\n",
      "Validation Loss:  0.7931275\n",
      "Epoch:  849\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9079471\n",
      "Validation Loss:  0.79220265\n",
      "Epoch:  850\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89771074\n",
      "Validation Loss:  0.7926633\n",
      "Epoch:  851\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9187714\n",
      "Validation Loss:  0.7932135\n",
      "Epoch:  852\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9027127\n",
      "Validation Loss:  0.7962915\n",
      "Epoch:  853\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.91980094\n",
      "Validation Loss:  0.79254043\n",
      "Epoch:  854\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90156025\n",
      "Validation Loss:  0.79266965\n",
      "Epoch:  855\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.92508066\n",
      "Validation Loss:  0.79257333\n",
      "Epoch:  856\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9121386\n",
      "Validation Loss:  0.79211855\n",
      "Epoch:  857\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8971167\n",
      "Validation Loss:  0.79206496\n",
      "Epoch:  858\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.91368526\n",
      "Validation Loss:  0.7922997\n",
      "Epoch:  859\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89723593\n",
      "Validation Loss:  0.7954874\n",
      "Epoch:  860\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8965995\n",
      "Validation Loss:  0.7924054\n",
      "Epoch:  861\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90164995\n",
      "Validation Loss:  0.7918193\n",
      "Epoch:  862\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.906216\n",
      "Validation Loss:  0.7932429\n",
      "Epoch:  863\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9849246231155779\n",
      "Training Loss:  0.9126261\n",
      "Validation Loss:  0.79275787\n",
      "Epoch:  864\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89736646\n",
      "Validation Loss:  0.792515\n",
      "Epoch:  865\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.91864675\n",
      "Validation Loss:  0.7924271\n",
      "Epoch:  866\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8994611\n",
      "Validation Loss:  0.793011\n",
      "Epoch:  867\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9061024\n",
      "Validation Loss:  0.79247063\n",
      "Epoch:  868\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8970867\n",
      "Validation Loss:  0.7934589\n",
      "Epoch:  869\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9136246\n",
      "Validation Loss:  0.79198885\n",
      "Epoch:  870\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9022323\n",
      "Validation Loss:  0.7923066\n",
      "Epoch:  871\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9036221\n",
      "Validation Loss:  0.7918363\n",
      "Epoch:  872\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9087508\n",
      "Validation Loss:  0.792151\n",
      "Epoch:  873\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89733803\n",
      "Validation Loss:  0.79213476\n",
      "Epoch:  874\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9001338\n",
      "Validation Loss:  0.79193884\n",
      "Epoch:  875\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8968722\n",
      "Validation Loss:  0.79241383\n",
      "Epoch:  876\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90771914\n",
      "Validation Loss:  0.791643\n",
      "Epoch:  877\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9023379\n",
      "Validation Loss:  0.7925481\n",
      "Epoch:  878\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90167534\n",
      "Validation Loss:  0.79270464\n",
      "Epoch:  879\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9076907\n",
      "Validation Loss:  0.79281265\n",
      "Epoch:  880\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9035808\n",
      "Validation Loss:  0.795497\n",
      "Epoch:  881\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8966733\n",
      "Validation Loss:  0.79258436\n",
      "Epoch:  882\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8972117\n",
      "Validation Loss:  0.79222184\n",
      "Epoch:  883\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89962375\n",
      "Validation Loss:  0.7917048\n",
      "Epoch:  884\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8947253\n",
      "Validation Loss:  0.792297\n",
      "Epoch:  885\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90578926\n",
      "Validation Loss:  0.7969933\n",
      "Epoch:  886\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90782154\n",
      "Validation Loss:  0.7924112\n",
      "Epoch:  887\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9021386\n",
      "Validation Loss:  0.79409456\n",
      "Epoch:  888\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8997548\n",
      "Validation Loss:  0.79143035\n",
      "Epoch:  889\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.90591276\n",
      "Validation Loss:  0.7919183\n",
      "Epoch:  890\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90994257\n",
      "Validation Loss:  0.7919279\n",
      "Epoch:  891\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90310526\n",
      "Validation Loss:  0.79256296\n",
      "Epoch:  892\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8952712\n",
      "Validation Loss:  0.79302037\n",
      "Epoch:  893\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90025365\n",
      "Validation Loss:  0.7913794\n",
      "Epoch:  894\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8955316\n",
      "Validation Loss:  0.7931763\n",
      "Epoch:  895\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8990468\n",
      "Validation Loss:  0.7915497\n",
      "Epoch:  896\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.910837\n",
      "Validation Loss:  0.79222983\n",
      "Epoch:  897\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.906094\n",
      "Validation Loss:  0.79206765\n",
      "Epoch:  898\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89761853\n",
      "Validation Loss:  0.79204845\n",
      "Epoch:  899\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90158314\n",
      "Validation Loss:  0.91782707\n",
      "Epoch:  900\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90441\n",
      "Validation Loss:  0.7917429\n",
      "Epoch:  901\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9025956\n",
      "Validation Loss:  0.79080343\n",
      "Epoch:  902\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8990959\n",
      "Validation Loss:  0.7920221\n",
      "Epoch:  903\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9048043\n",
      "Validation Loss:  0.7949029\n",
      "Epoch:  904\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8968197\n",
      "Validation Loss:  0.7917282\n",
      "Epoch:  905\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89875364\n",
      "Validation Loss:  0.7907825\n",
      "Epoch:  906\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90020216\n",
      "Validation Loss:  0.79234684\n",
      "Epoch:  907\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89642984\n",
      "Validation Loss:  0.7928209\n",
      "Epoch:  908\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.895726\n",
      "Validation Loss:  0.79195964\n",
      "Epoch:  909\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8944309\n",
      "Validation Loss:  0.7909923\n",
      "Epoch:  910\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89987123\n",
      "Validation Loss:  0.7908839\n",
      "Epoch:  911\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90072185\n",
      "Validation Loss:  0.7907613\n",
      "Epoch:  912\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8963861\n",
      "Validation Loss:  0.7910221\n",
      "Epoch:  913\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9012112\n",
      "Validation Loss:  0.7908751\n",
      "Epoch:  914\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89846915\n",
      "Validation Loss:  0.79133064\n",
      "Epoch:  915\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8941273\n",
      "Validation Loss:  0.7909265\n",
      "Epoch:  916\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89830613\n",
      "Validation Loss:  0.7945811\n",
      "Epoch:  917\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8950876\n",
      "Validation Loss:  0.79216397\n",
      "Epoch:  918\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8991988\n",
      "Validation Loss:  0.7910539\n",
      "Epoch:  919\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9096065\n",
      "Validation Loss:  0.7909489\n",
      "Epoch:  920\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9093894\n",
      "Validation Loss:  0.79130566\n",
      "Epoch:  921\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90092\n",
      "Validation Loss:  0.7919031\n",
      "Epoch:  922\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9005191\n",
      "Validation Loss:  0.79092264\n",
      "Epoch:  923\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8946508\n",
      "Validation Loss:  0.79079664\n",
      "Epoch:  924\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89641356\n",
      "Validation Loss:  0.79099405\n",
      "Epoch:  925\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.895653\n",
      "Validation Loss:  0.7908415\n",
      "Epoch:  926\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89858145\n",
      "Validation Loss:  0.7927031\n",
      "Epoch:  927\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8941924\n",
      "Validation Loss:  0.7968213\n",
      "Epoch:  928\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90307546\n",
      "Validation Loss:  0.7903086\n",
      "Epoch:  929\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8999469\n",
      "Validation Loss:  0.79108614\n",
      "Epoch:  930\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89402205\n",
      "Validation Loss:  0.7915315\n",
      "Epoch:  931\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9030465\n",
      "Validation Loss:  0.7916803\n",
      "Epoch:  932\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90830195\n",
      "Validation Loss:  0.79117334\n",
      "Epoch:  933\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8920856\n",
      "Validation Loss:  0.79135734\n",
      "Epoch:  934\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89208513\n",
      "Validation Loss:  0.79066485\n",
      "Epoch:  935\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9047558\n",
      "Validation Loss:  0.7905672\n",
      "Epoch:  936\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.891327\n",
      "Validation Loss:  0.7903294\n",
      "Epoch:  937\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9005798\n",
      "Validation Loss:  0.79253834\n",
      "Epoch:  938\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89397156\n",
      "Validation Loss:  0.79046834\n",
      "Epoch:  939\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8913968\n",
      "Validation Loss:  0.79627764\n",
      "Epoch:  940\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90569305\n",
      "Validation Loss:  0.7904231\n",
      "Epoch:  941\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8907794\n",
      "Validation Loss:  0.7911268\n",
      "Epoch:  942\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89195395\n",
      "Validation Loss:  0.7910601\n",
      "Epoch:  943\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90703046\n",
      "Validation Loss:  0.7912362\n",
      "Epoch:  944\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90515447\n",
      "Validation Loss:  0.79242784\n",
      "Epoch:  945\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89653486\n",
      "Validation Loss:  0.7903496\n",
      "Epoch:  946\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8965859\n",
      "Validation Loss:  0.7910234\n",
      "Epoch:  947\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89327574\n",
      "Validation Loss:  0.7911524\n",
      "Epoch:  948\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8984376\n",
      "Validation Loss:  0.7905049\n",
      "Epoch:  949\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8909532\n",
      "Validation Loss:  0.79040015\n",
      "Epoch:  950\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8957588\n",
      "Validation Loss:  0.7911892\n",
      "Epoch:  951\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9007952\n",
      "Validation Loss:  0.7902635\n",
      "Epoch:  952\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8904847\n",
      "Validation Loss:  0.9166108\n",
      "Epoch:  953\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8921951\n",
      "Validation Loss:  0.7908983\n",
      "Epoch:  954\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8964794\n",
      "Validation Loss:  0.79126376\n",
      "Epoch:  955\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89987105\n",
      "Validation Loss:  0.7909489\n",
      "Epoch:  956\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89036894\n",
      "Validation Loss:  0.7900466\n",
      "Epoch:  957\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8904442\n",
      "Validation Loss:  0.79008013\n",
      "Epoch:  958\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89485574\n",
      "Validation Loss:  0.7955274\n",
      "Epoch:  959\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8970493\n",
      "Validation Loss:  0.790263\n",
      "Epoch:  960\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8895563\n",
      "Validation Loss:  0.7907375\n",
      "Epoch:  961\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8886736\n",
      "Validation Loss:  0.79027176\n",
      "Epoch:  962\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89142364\n",
      "Validation Loss:  0.7908104\n",
      "Epoch:  963\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8962766\n",
      "Validation Loss:  0.79238796\n",
      "Epoch:  964\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89015347\n",
      "Validation Loss:  0.7903156\n",
      "Epoch:  965\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89619833\n",
      "Validation Loss:  0.78999597\n",
      "Epoch:  966\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.893942\n",
      "Validation Loss:  0.79121655\n",
      "Epoch:  967\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.89065105\n",
      "Validation Loss:  0.79057837\n",
      "Epoch:  968\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90171194\n",
      "Validation Loss:  0.7913991\n",
      "Epoch:  969\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89260226\n",
      "Validation Loss:  0.79126406\n",
      "Epoch:  970\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8971845\n",
      "Validation Loss:  0.7906681\n",
      "Epoch:  971\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90413815\n",
      "Validation Loss:  0.7897479\n",
      "Epoch:  972\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8999531\n",
      "Validation Loss:  0.7892844\n",
      "Epoch:  973\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89800155\n",
      "Validation Loss:  0.7899205\n",
      "Epoch:  974\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8924495\n",
      "Validation Loss:  0.7898628\n",
      "Epoch:  975\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90370005\n",
      "Validation Loss:  0.78949815\n",
      "Epoch:  976\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8894544\n",
      "Validation Loss:  0.91695833\n",
      "Epoch:  977\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8903038\n",
      "Validation Loss:  0.7899497\n",
      "Epoch:  978\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9002407\n",
      "Validation Loss:  0.789948\n",
      "Epoch:  979\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8920525\n",
      "Validation Loss:  0.79099506\n",
      "Epoch:  980\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8939844\n",
      "Validation Loss:  0.7911135\n",
      "Epoch:  981\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89521194\n",
      "Validation Loss:  0.7891663\n",
      "Epoch:  982\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88787496\n",
      "Validation Loss:  0.78961706\n",
      "Epoch:  983\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8889851\n",
      "Validation Loss:  0.7895339\n",
      "Epoch:  984\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.895536\n",
      "Validation Loss:  0.79000646\n",
      "Epoch:  985\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89474696\n",
      "Validation Loss:  0.7899113\n",
      "Epoch:  986\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8943212\n",
      "Validation Loss:  0.7900054\n",
      "Epoch:  987\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8941154\n",
      "Validation Loss:  0.79101914\n",
      "Epoch:  988\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8942177\n",
      "Validation Loss:  0.9160615\n",
      "Epoch:  989\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89527893\n",
      "Validation Loss:  0.78972\n",
      "Epoch:  990\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8961417\n",
      "Validation Loss:  0.7895588\n",
      "Epoch:  991\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88870007\n",
      "Validation Loss:  0.78943795\n",
      "Epoch:  992\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89515215\n",
      "Validation Loss:  0.78983337\n",
      "Epoch:  993\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8930492\n",
      "Validation Loss:  0.79032797\n",
      "Epoch:  994\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8912562\n",
      "Validation Loss:  0.915593\n",
      "Epoch:  995\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9046818\n",
      "Validation Loss:  0.78888404\n",
      "Epoch:  996\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88958126\n",
      "Validation Loss:  0.78983504\n",
      "Epoch:  997\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8912362\n",
      "Validation Loss:  0.7894548\n",
      "Epoch:  998\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8886235\n",
      "Validation Loss:  0.7892336\n",
      "Epoch:  999\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89052355\n",
      "Validation Loss:  0.7903164\n",
      "Epoch:  1000\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9028593\n",
      "Validation Loss:  0.7889398\n",
      "Epoch:  1001\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.91523254\n",
      "Validation Loss:  0.789641\n",
      "Epoch:  1002\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8965918\n",
      "Validation Loss:  0.7901298\n",
      "Epoch:  1003\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8960656\n",
      "Validation Loss:  0.7889466\n",
      "Epoch:  1004\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90277815\n",
      "Validation Loss:  0.7895297\n",
      "Epoch:  1005\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8955864\n",
      "Validation Loss:  0.7890624\n",
      "Epoch:  1006\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8919548\n",
      "Validation Loss:  0.7891574\n",
      "Epoch:  1007\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8977794\n",
      "Validation Loss:  0.78888625\n",
      "Epoch:  1008\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8901216\n",
      "Validation Loss:  0.79041195\n",
      "Epoch:  1009\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8881377\n",
      "Validation Loss:  0.79041296\n",
      "Epoch:  1010\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8877432\n",
      "Validation Loss:  0.7897932\n",
      "Epoch:  1011\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89170504\n",
      "Validation Loss:  0.788823\n",
      "Epoch:  1012\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8934153\n",
      "Validation Loss:  0.78881896\n",
      "Epoch:  1013\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9001246\n",
      "Validation Loss:  0.7897614\n",
      "Epoch:  1014\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8932031\n",
      "Validation Loss:  0.7905904\n",
      "Epoch:  1015\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88771677\n",
      "Validation Loss:  0.7887665\n",
      "Epoch:  1016\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9062966\n",
      "Validation Loss:  0.78994215\n",
      "Epoch:  1017\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89611\n",
      "Validation Loss:  0.7920802\n",
      "Epoch:  1018\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.89081305\n",
      "Validation Loss:  0.7903158\n",
      "Epoch:  1019\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88711715\n",
      "Validation Loss:  0.7896727\n",
      "Epoch:  1020\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89621294\n",
      "Validation Loss:  0.7897115\n",
      "Epoch:  1021\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88940626\n",
      "Validation Loss:  0.7884818\n",
      "Epoch:  1022\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8972852\n",
      "Validation Loss:  0.91584396\n",
      "Epoch:  1023\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89273894\n",
      "Validation Loss:  0.7947456\n",
      "Epoch:  1024\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.889299\n",
      "Validation Loss:  0.78892606\n",
      "Epoch:  1025\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8954997\n",
      "Validation Loss:  0.7885007\n",
      "Epoch:  1026\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89854425\n",
      "Validation Loss:  0.7905998\n",
      "Epoch:  1027\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8872338\n",
      "Validation Loss:  0.7894188\n",
      "Epoch:  1028\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8859448\n",
      "Validation Loss:  0.7888157\n",
      "Epoch:  1029\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89656675\n",
      "Validation Loss:  0.7897334\n",
      "Epoch:  1030\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89791447\n",
      "Validation Loss:  0.7881898\n",
      "Epoch:  1031\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8961718\n",
      "Validation Loss:  0.78891194\n",
      "Epoch:  1032\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8994854\n",
      "Validation Loss:  0.7887494\n",
      "Epoch:  1033\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90101886\n",
      "Validation Loss:  0.7892844\n",
      "Epoch:  1034\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8936362\n",
      "Validation Loss:  0.91511106\n",
      "Epoch:  1035\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8979741\n",
      "Validation Loss:  0.78913504\n",
      "Epoch:  1036\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8863539\n",
      "Validation Loss:  0.78925127\n",
      "Epoch:  1037\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8949791\n",
      "Validation Loss:  0.78878695\n",
      "Epoch:  1038\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8955016\n",
      "Validation Loss:  0.78896123\n",
      "Epoch:  1039\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8933066\n",
      "Validation Loss:  0.78874886\n",
      "Epoch:  1040\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8859567\n",
      "Validation Loss:  0.7898473\n",
      "Epoch:  1041\n",
      "Training Accuracy:  0.987012987012987\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8946219\n",
      "Validation Loss:  0.7886794\n",
      "Epoch:  1042\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8941573\n",
      "Validation Loss:  0.91577005\n",
      "Epoch:  1043\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8912893\n",
      "Validation Loss:  0.78915864\n",
      "Epoch:  1044\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.888714\n",
      "Validation Loss:  0.91539913\n",
      "Epoch:  1045\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8850973\n",
      "Validation Loss:  0.7884182\n",
      "Epoch:  1046\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89853644\n",
      "Validation Loss:  0.7883875\n",
      "Epoch:  1047\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8932758\n",
      "Validation Loss:  0.7887181\n",
      "Epoch:  1048\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89787877\n",
      "Validation Loss:  0.79162675\n",
      "Epoch:  1049\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9017781\n",
      "Validation Loss:  0.78856784\n",
      "Epoch:  1050\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8861701\n",
      "Validation Loss:  0.7887216\n",
      "Epoch:  1051\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88681406\n",
      "Validation Loss:  0.78974444\n",
      "Epoch:  1052\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8854072\n",
      "Validation Loss:  0.78875685\n",
      "Epoch:  1053\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8868326\n",
      "Validation Loss:  0.78877485\n",
      "Epoch:  1054\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8908291\n",
      "Validation Loss:  0.9148836\n",
      "Epoch:  1055\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8874153\n",
      "Validation Loss:  0.790182\n",
      "Epoch:  1056\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8865418\n",
      "Validation Loss:  0.78848374\n",
      "Epoch:  1057\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89409935\n",
      "Validation Loss:  0.7885223\n",
      "Epoch:  1058\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89224666\n",
      "Validation Loss:  0.7893995\n",
      "Epoch:  1059\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8913661\n",
      "Validation Loss:  0.78818274\n",
      "Epoch:  1060\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9014032\n",
      "Validation Loss:  0.78834015\n",
      "Epoch:  1061\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89857846\n",
      "Validation Loss:  0.78856903\n",
      "Epoch:  1062\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8947614\n",
      "Validation Loss:  0.78905123\n",
      "Epoch:  1063\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89799285\n",
      "Validation Loss:  0.78877527\n",
      "Epoch:  1064\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8950863\n",
      "Validation Loss:  0.7883245\n",
      "Epoch:  1065\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89180773\n",
      "Validation Loss:  0.7887689\n",
      "Epoch:  1066\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8906478\n",
      "Validation Loss:  0.7888635\n",
      "Epoch:  1067\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8983286\n",
      "Validation Loss:  0.78809494\n",
      "Epoch:  1068\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90308684\n",
      "Validation Loss:  0.7884474\n",
      "Epoch:  1069\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9007971\n",
      "Validation Loss:  0.7889942\n",
      "Epoch:  1070\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89429295\n",
      "Validation Loss:  0.78857476\n",
      "Epoch:  1071\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.886341\n",
      "Validation Loss:  0.78862315\n",
      "Epoch:  1072\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88692707\n",
      "Validation Loss:  0.78901225\n",
      "Epoch:  1073\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90346706\n",
      "Validation Loss:  0.7883247\n",
      "Epoch:  1074\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89573395\n",
      "Validation Loss:  0.7885213\n",
      "Epoch:  1075\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8858158\n",
      "Validation Loss:  0.7884754\n",
      "Epoch:  1076\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8907996\n",
      "Validation Loss:  0.7885567\n",
      "Epoch:  1077\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88980794\n",
      "Validation Loss:  0.78896743\n",
      "Epoch:  1078\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88435537\n",
      "Validation Loss:  0.7883104\n",
      "Epoch:  1079\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89375377\n",
      "Validation Loss:  0.7890817\n",
      "Epoch:  1080\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88468325\n",
      "Validation Loss:  0.78849775\n",
      "Epoch:  1081\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8836455\n",
      "Validation Loss:  0.7898989\n",
      "Epoch:  1082\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8844589\n",
      "Validation Loss:  0.78799593\n",
      "Epoch:  1083\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89105606\n",
      "Validation Loss:  0.78925943\n",
      "Epoch:  1084\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8904672\n",
      "Validation Loss:  0.7879766\n",
      "Epoch:  1085\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88468426\n",
      "Validation Loss:  0.78971106\n",
      "Epoch:  1086\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8942224\n",
      "Validation Loss:  0.7884246\n",
      "Epoch:  1087\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8904725\n",
      "Validation Loss:  0.7893818\n",
      "Epoch:  1088\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8829465\n",
      "Validation Loss:  0.78854644\n",
      "Epoch:  1089\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8859467\n",
      "Validation Loss:  0.7883069\n",
      "Epoch:  1090\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8843174\n",
      "Validation Loss:  0.7881252\n",
      "Epoch:  1091\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88547647\n",
      "Validation Loss:  0.7884956\n",
      "Epoch:  1092\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88472754\n",
      "Validation Loss:  0.7879116\n",
      "Epoch:  1093\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88840777\n",
      "Validation Loss:  0.788256\n",
      "Epoch:  1094\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88332814\n",
      "Validation Loss:  0.78794044\n",
      "Epoch:  1095\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8832345\n",
      "Validation Loss:  0.7891204\n",
      "Epoch:  1096\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88844144\n",
      "Validation Loss:  0.7880643\n",
      "Epoch:  1097\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8887837\n",
      "Validation Loss:  0.7877144\n",
      "Epoch:  1098\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89238465\n",
      "Validation Loss:  0.7886404\n",
      "Epoch:  1099\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8825423\n",
      "Validation Loss:  0.78828365\n",
      "Epoch:  1100\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8904323\n",
      "Validation Loss:  0.7874814\n",
      "Epoch:  1101\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89473546\n",
      "Validation Loss:  0.78801453\n",
      "Epoch:  1102\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8938961\n",
      "Validation Loss:  0.7877123\n",
      "Epoch:  1103\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.89892703\n",
      "Validation Loss:  0.7879768\n",
      "Epoch:  1104\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8826648\n",
      "Validation Loss:  0.78777015\n",
      "Epoch:  1105\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89164525\n",
      "Validation Loss:  0.78794724\n",
      "Epoch:  1106\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8872825\n",
      "Validation Loss:  0.78796095\n",
      "Epoch:  1107\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88180006\n",
      "Validation Loss:  0.78741884\n",
      "Epoch:  1108\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8819973\n",
      "Validation Loss:  0.78796273\n",
      "Epoch:  1109\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8972031\n",
      "Validation Loss:  0.78770405\n",
      "Epoch:  1110\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8910439\n",
      "Validation Loss:  0.7923022\n",
      "Epoch:  1111\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89500946\n",
      "Validation Loss:  0.78771025\n",
      "Epoch:  1112\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88495713\n",
      "Validation Loss:  0.78843963\n",
      "Epoch:  1113\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8832431\n",
      "Validation Loss:  0.7878604\n",
      "Epoch:  1114\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88893783\n",
      "Validation Loss:  0.7911357\n",
      "Epoch:  1115\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.894343\n",
      "Validation Loss:  0.7879402\n",
      "Epoch:  1116\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89017415\n",
      "Validation Loss:  0.7884954\n",
      "Epoch:  1117\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8868107\n",
      "Validation Loss:  0.78778046\n",
      "Epoch:  1118\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.887947\n",
      "Validation Loss:  0.78813595\n",
      "Epoch:  1119\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8978482\n",
      "Validation Loss:  0.7884701\n",
      "Epoch:  1120\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89571464\n",
      "Validation Loss:  0.78891915\n",
      "Epoch:  1121\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8944243\n",
      "Validation Loss:  0.7874779\n",
      "Epoch:  1122\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8818792\n",
      "Validation Loss:  0.78922254\n",
      "Epoch:  1123\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88212657\n",
      "Validation Loss:  0.78764117\n",
      "Epoch:  1124\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8909616\n",
      "Validation Loss:  0.7888091\n",
      "Epoch:  1125\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8876519\n",
      "Validation Loss:  0.7901029\n",
      "Epoch:  1126\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8925141\n",
      "Validation Loss:  0.78749067\n",
      "Epoch:  1127\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88323927\n",
      "Validation Loss:  0.7880059\n",
      "Epoch:  1128\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8915594\n",
      "Validation Loss:  0.7873581\n",
      "Epoch:  1129\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90051824\n",
      "Validation Loss:  0.7899703\n",
      "Epoch:  1130\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8880793\n",
      "Validation Loss:  0.7876982\n",
      "Epoch:  1131\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88349974\n",
      "Validation Loss:  0.788154\n",
      "Epoch:  1132\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88981396\n",
      "Validation Loss:  0.78764045\n",
      "Epoch:  1133\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88346624\n",
      "Validation Loss:  0.78781176\n",
      "Epoch:  1134\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8820555\n",
      "Validation Loss:  0.7902565\n",
      "Epoch:  1135\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8871124\n",
      "Validation Loss:  0.78786165\n",
      "Epoch:  1136\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8906411\n",
      "Validation Loss:  0.7883376\n",
      "Epoch:  1137\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8842354\n",
      "Validation Loss:  0.91410923\n",
      "Epoch:  1138\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8854785\n",
      "Validation Loss:  0.7874001\n",
      "Epoch:  1139\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88450325\n",
      "Validation Loss:  0.7877645\n",
      "Epoch:  1140\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.88415766\n",
      "Validation Loss:  0.7879834\n",
      "Epoch:  1141\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8905964\n",
      "Validation Loss:  0.7880999\n",
      "Epoch:  1142\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8824681\n",
      "Validation Loss:  0.78746146\n",
      "Epoch:  1143\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8814723\n",
      "Validation Loss:  0.7878381\n",
      "Epoch:  1144\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88726926\n",
      "Validation Loss:  0.7875811\n",
      "Epoch:  1145\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8854275\n",
      "Validation Loss:  0.7870294\n",
      "Epoch:  1146\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.888375\n",
      "Validation Loss:  0.787611\n",
      "Epoch:  1147\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89045185\n",
      "Validation Loss:  0.7880311\n",
      "Epoch:  1148\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90293646\n",
      "Validation Loss:  0.7877837\n",
      "Epoch:  1149\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88576037\n",
      "Validation Loss:  0.7873677\n",
      "Epoch:  1150\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8810756\n",
      "Validation Loss:  0.78871864\n",
      "Epoch:  1151\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8905651\n",
      "Validation Loss:  0.79078084\n",
      "Epoch:  1152\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89394397\n",
      "Validation Loss:  0.7886413\n",
      "Epoch:  1153\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8820851\n",
      "Validation Loss:  0.7878776\n",
      "Epoch:  1154\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89512914\n",
      "Validation Loss:  0.7871814\n",
      "Epoch:  1155\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8865434\n",
      "Validation Loss:  0.7875052\n",
      "Epoch:  1156\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88455474\n",
      "Validation Loss:  0.7873097\n",
      "Epoch:  1157\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88217795\n",
      "Validation Loss:  0.7888231\n",
      "Epoch:  1158\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8802381\n",
      "Validation Loss:  0.7878253\n",
      "Epoch:  1159\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8822019\n",
      "Validation Loss:  0.7872167\n",
      "Epoch:  1160\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.882163\n",
      "Validation Loss:  0.78854597\n",
      "Epoch:  1161\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88065606\n",
      "Validation Loss:  0.7869412\n",
      "Epoch:  1162\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88401103\n",
      "Validation Loss:  0.7871937\n",
      "Epoch:  1163\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8833796\n",
      "Validation Loss:  0.78770316\n",
      "Epoch:  1164\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8808056\n",
      "Validation Loss:  0.7869748\n",
      "Epoch:  1165\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8859195\n",
      "Validation Loss:  0.78736573\n",
      "Epoch:  1166\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8872475\n",
      "Validation Loss:  0.78692836\n",
      "Epoch:  1167\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8849308\n",
      "Validation Loss:  0.7875195\n",
      "Epoch:  1168\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8880171\n",
      "Validation Loss:  0.7872263\n",
      "Epoch:  1169\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8950215\n",
      "Validation Loss:  0.789139\n",
      "Epoch:  1170\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8834024\n",
      "Validation Loss:  0.78706837\n",
      "Epoch:  1171\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8826498\n",
      "Validation Loss:  0.78771454\n",
      "Epoch:  1172\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8840899\n",
      "Validation Loss:  0.78677183\n",
      "Epoch:  1173\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87970227\n",
      "Validation Loss:  0.786904\n",
      "Epoch:  1174\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88263583\n",
      "Validation Loss:  0.7867633\n",
      "Epoch:  1175\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8823708\n",
      "Validation Loss:  0.79011494\n",
      "Epoch:  1176\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.881027\n",
      "Validation Loss:  0.7870936\n",
      "Epoch:  1177\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88171536\n",
      "Validation Loss:  0.78672755\n",
      "Epoch:  1178\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88055277\n",
      "Validation Loss:  0.78662455\n",
      "Epoch:  1179\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8919146\n",
      "Validation Loss:  0.7871694\n",
      "Epoch:  1180\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8889438\n",
      "Validation Loss:  0.91434014\n",
      "Epoch:  1181\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88237697\n",
      "Validation Loss:  0.7866985\n",
      "Epoch:  1182\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8898787\n",
      "Validation Loss:  0.78650707\n",
      "Epoch:  1183\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8935472\n",
      "Validation Loss:  0.7869317\n",
      "Epoch:  1184\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88277566\n",
      "Validation Loss:  0.7874128\n",
      "Epoch:  1185\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88464934\n",
      "Validation Loss:  0.7866653\n",
      "Epoch:  1186\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.890142\n",
      "Validation Loss:  0.78702533\n",
      "Epoch:  1187\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.884398\n",
      "Validation Loss:  0.7872799\n",
      "Epoch:  1188\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88304067\n",
      "Validation Loss:  0.9135886\n",
      "Epoch:  1189\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87928087\n",
      "Validation Loss:  0.9153041\n",
      "Epoch:  1190\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8796535\n",
      "Validation Loss:  0.78691256\n",
      "Epoch:  1191\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89485544\n",
      "Validation Loss:  0.78704226\n",
      "Epoch:  1192\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88693035\n",
      "Validation Loss:  0.7871914\n",
      "Epoch:  1193\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8804152\n",
      "Validation Loss:  0.78672296\n",
      "Epoch:  1194\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.879501\n",
      "Validation Loss:  0.7866144\n",
      "Epoch:  1195\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8829337\n",
      "Validation Loss:  0.7872771\n",
      "Epoch:  1196\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88403183\n",
      "Validation Loss:  0.792334\n",
      "Epoch:  1197\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8850417\n",
      "Validation Loss:  0.7865592\n",
      "Epoch:  1198\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88648325\n",
      "Validation Loss:  0.78728014\n",
      "Epoch:  1199\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8788102\n",
      "Validation Loss:  0.7867637\n",
      "Epoch:  1200\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88395745\n",
      "Validation Loss:  0.7864498\n",
      "Epoch:  1201\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8814906\n",
      "Validation Loss:  0.78746855\n",
      "Epoch:  1202\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89087754\n",
      "Validation Loss:  0.7880789\n",
      "Epoch:  1203\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88051885\n",
      "Validation Loss:  0.78693783\n",
      "Epoch:  1204\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8820173\n",
      "Validation Loss:  0.78687006\n",
      "Epoch:  1205\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.888049\n",
      "Validation Loss:  0.7871826\n",
      "Epoch:  1206\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88412917\n",
      "Validation Loss:  0.78736204\n",
      "Epoch:  1207\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8890771\n",
      "Validation Loss:  0.7870494\n",
      "Epoch:  1208\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88665175\n",
      "Validation Loss:  0.7865539\n",
      "Epoch:  1209\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88135916\n",
      "Validation Loss:  0.78654087\n",
      "Epoch:  1210\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8784569\n",
      "Validation Loss:  0.91310126\n",
      "Epoch:  1211\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8882204\n",
      "Validation Loss:  0.7866853\n",
      "Epoch:  1212\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8785451\n",
      "Validation Loss:  0.7875236\n",
      "Epoch:  1213\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8819201\n",
      "Validation Loss:  0.78695434\n",
      "Epoch:  1214\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87943447\n",
      "Validation Loss:  0.7865463\n",
      "Epoch:  1215\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8828958\n",
      "Validation Loss:  0.78660077\n",
      "Epoch:  1216\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8796016\n",
      "Validation Loss:  0.786456\n",
      "Epoch:  1217\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8824372\n",
      "Validation Loss:  0.7867969\n",
      "Epoch:  1218\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8870278\n",
      "Validation Loss:  0.7867323\n",
      "Epoch:  1219\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.877788\n",
      "Validation Loss:  0.7883596\n",
      "Epoch:  1220\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87987673\n",
      "Validation Loss:  0.7871273\n",
      "Epoch:  1221\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8892761\n",
      "Validation Loss:  0.78956074\n",
      "Epoch:  1222\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87913626\n",
      "Validation Loss:  0.78631634\n",
      "Epoch:  1223\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8918834\n",
      "Validation Loss:  0.7872383\n",
      "Epoch:  1224\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8803254\n",
      "Validation Loss:  0.78628004\n",
      "Epoch:  1225\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88807034\n",
      "Validation Loss:  0.78638446\n",
      "Epoch:  1226\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88244057\n",
      "Validation Loss:  0.7867618\n",
      "Epoch:  1227\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87823063\n",
      "Validation Loss:  0.7866903\n",
      "Epoch:  1228\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.87798923\n",
      "Validation Loss:  0.78622335\n",
      "Epoch:  1229\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8856374\n",
      "Validation Loss:  0.7870132\n",
      "Epoch:  1230\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8805753\n",
      "Validation Loss:  0.78990734\n",
      "Epoch:  1231\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8776081\n",
      "Validation Loss:  0.78988534\n",
      "Epoch:  1232\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8867867\n",
      "Validation Loss:  0.78622216\n",
      "Epoch:  1233\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.882853\n",
      "Validation Loss:  0.7868628\n",
      "Epoch:  1234\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8887437\n",
      "Validation Loss:  0.78624374\n",
      "Epoch:  1235\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.879452\n",
      "Validation Loss:  0.7864805\n",
      "Epoch:  1236\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88569057\n",
      "Validation Loss:  0.78662646\n",
      "Epoch:  1237\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8894838\n",
      "Validation Loss:  0.7859147\n",
      "Epoch:  1238\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.88848424\n",
      "Validation Loss:  0.78623474\n",
      "Epoch:  1239\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8832004\n",
      "Validation Loss:  0.78627735\n",
      "Epoch:  1240\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8778952\n",
      "Validation Loss:  0.786386\n",
      "Epoch:  1241\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87850136\n",
      "Validation Loss:  0.78661627\n",
      "Epoch:  1242\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8891836\n",
      "Validation Loss:  0.78615874\n",
      "Epoch:  1243\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8809274\n",
      "Validation Loss:  0.7870782\n",
      "Epoch:  1244\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8785581\n",
      "Validation Loss:  0.7863495\n",
      "Epoch:  1245\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8795082\n",
      "Validation Loss:  0.78662664\n",
      "Epoch:  1246\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88371146\n",
      "Validation Loss:  0.78796583\n",
      "Epoch:  1247\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8805505\n",
      "Validation Loss:  0.786736\n",
      "Epoch:  1248\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87804586\n",
      "Validation Loss:  0.78600806\n",
      "Epoch:  1249\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89236623\n",
      "Validation Loss:  0.7860985\n",
      "Epoch:  1250\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88403887\n",
      "Validation Loss:  0.7868525\n",
      "Epoch:  1251\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8814086\n",
      "Validation Loss:  0.7866699\n",
      "Epoch:  1252\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.90026456\n",
      "Validation Loss:  0.7857709\n",
      "Epoch:  1253\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88174903\n",
      "Validation Loss:  0.78630906\n",
      "Epoch:  1254\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8797716\n",
      "Validation Loss:  0.7864579\n",
      "Epoch:  1255\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.87643427\n",
      "Validation Loss:  0.78602076\n",
      "Epoch:  1256\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89146936\n",
      "Validation Loss:  0.78666276\n",
      "Epoch:  1257\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8829396\n",
      "Validation Loss:  0.7863286\n",
      "Epoch:  1258\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8813228\n",
      "Validation Loss:  0.78644806\n",
      "Epoch:  1259\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8814761\n",
      "Validation Loss:  0.78747237\n",
      "Epoch:  1260\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87773705\n",
      "Validation Loss:  0.7862878\n",
      "Epoch:  1261\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88479227\n",
      "Validation Loss:  0.7867609\n",
      "Epoch:  1262\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88439006\n",
      "Validation Loss:  0.78659093\n",
      "Epoch:  1263\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8882696\n",
      "Validation Loss:  0.7863142\n",
      "Epoch:  1264\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88527477\n",
      "Validation Loss:  0.78608185\n",
      "Epoch:  1265\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.878116\n",
      "Validation Loss:  0.7867041\n",
      "Epoch:  1266\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.879612\n",
      "Validation Loss:  0.7861457\n",
      "Epoch:  1267\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8824249\n",
      "Validation Loss:  0.7862051\n",
      "Epoch:  1268\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.881589\n",
      "Validation Loss:  0.7859054\n",
      "Epoch:  1269\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88462263\n",
      "Validation Loss:  0.78611714\n",
      "Epoch:  1270\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89269006\n",
      "Validation Loss:  0.78594935\n",
      "Epoch:  1271\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8797079\n",
      "Validation Loss:  0.7859101\n",
      "Epoch:  1272\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8824093\n",
      "Validation Loss:  0.7858518\n",
      "Epoch:  1273\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88947386\n",
      "Validation Loss:  0.78670937\n",
      "Epoch:  1274\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87935454\n",
      "Validation Loss:  0.78669125\n",
      "Epoch:  1275\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8800226\n",
      "Validation Loss:  0.7883273\n",
      "Epoch:  1276\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.87792504\n",
      "Validation Loss:  0.7857343\n",
      "Epoch:  1277\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8851009\n",
      "Validation Loss:  0.78690255\n",
      "Epoch:  1278\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87766504\n",
      "Validation Loss:  0.78690094\n",
      "Epoch:  1279\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88423496\n",
      "Validation Loss:  0.7863825\n",
      "Epoch:  1280\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8892755\n",
      "Validation Loss:  0.9135663\n",
      "Epoch:  1281\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8763102\n",
      "Validation Loss:  0.7862181\n",
      "Epoch:  1282\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8925983\n",
      "Validation Loss:  0.7864256\n",
      "Epoch:  1283\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8766373\n",
      "Validation Loss:  0.78645664\n",
      "Epoch:  1284\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88577247\n",
      "Validation Loss:  0.78813213\n",
      "Epoch:  1285\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8888215\n",
      "Validation Loss:  0.7860568\n",
      "Epoch:  1286\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8945782\n",
      "Validation Loss:  0.7877574\n",
      "Epoch:  1287\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87696695\n",
      "Validation Loss:  0.78683823\n",
      "Epoch:  1288\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8829071\n",
      "Validation Loss:  0.7860066\n",
      "Epoch:  1289\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8801409\n",
      "Validation Loss:  0.7858407\n",
      "Epoch:  1290\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87713486\n",
      "Validation Loss:  0.7863932\n",
      "Epoch:  1291\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8848332\n",
      "Validation Loss:  0.7864515\n",
      "Epoch:  1292\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8830208\n",
      "Validation Loss:  0.7857085\n",
      "Epoch:  1293\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8856284\n",
      "Validation Loss:  0.7863992\n",
      "Epoch:  1294\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8780167\n",
      "Validation Loss:  0.78573024\n",
      "Epoch:  1295\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8820263\n",
      "Validation Loss:  0.78627336\n",
      "Epoch:  1296\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87530786\n",
      "Validation Loss:  0.78575546\n",
      "Epoch:  1297\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8801389\n",
      "Validation Loss:  0.7863479\n",
      "Epoch:  1298\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8791579\n",
      "Validation Loss:  0.7858587\n",
      "Epoch:  1299\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8765506\n",
      "Validation Loss:  0.7869007\n",
      "Epoch:  1300\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87821853\n",
      "Validation Loss:  0.78707266\n",
      "Epoch:  1301\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8872634\n",
      "Validation Loss:  0.78594625\n",
      "Epoch:  1302\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8792393\n",
      "Validation Loss:  0.78612906\n",
      "Epoch:  1303\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8801689\n",
      "Validation Loss:  0.7858661\n",
      "Epoch:  1304\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87513226\n",
      "Validation Loss:  0.78646153\n",
      "Epoch:  1305\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8855877\n",
      "Validation Loss:  0.7857318\n",
      "Epoch:  1306\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88291377\n",
      "Validation Loss:  0.78851277\n",
      "Epoch:  1307\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8771676\n",
      "Validation Loss:  0.7860487\n",
      "Epoch:  1308\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8904075\n",
      "Validation Loss:  0.78603786\n",
      "Epoch:  1309\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8907999\n",
      "Validation Loss:  0.78653663\n",
      "Epoch:  1310\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8754793\n",
      "Validation Loss:  0.7871851\n",
      "Epoch:  1311\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8782537\n",
      "Validation Loss:  0.78589803\n",
      "Epoch:  1312\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8782821\n",
      "Validation Loss:  0.78608006\n",
      "Epoch:  1313\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87787944\n",
      "Validation Loss:  0.7856332\n",
      "Epoch:  1314\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8767549\n",
      "Validation Loss:  0.78550094\n",
      "Epoch:  1315\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8877333\n",
      "Validation Loss:  0.78692263\n",
      "Epoch:  1316\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87776655\n",
      "Validation Loss:  0.78562844\n",
      "Epoch:  1317\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87891144\n",
      "Validation Loss:  0.78634346\n",
      "Epoch:  1318\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88012236\n",
      "Validation Loss:  0.78742164\n",
      "Epoch:  1319\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88221025\n",
      "Validation Loss:  0.7856924\n",
      "Epoch:  1320\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.878324\n",
      "Validation Loss:  0.78589284\n",
      "Epoch:  1321\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87704796\n",
      "Validation Loss:  0.78549916\n",
      "Epoch:  1322\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87590516\n",
      "Validation Loss:  0.7862092\n",
      "Epoch:  1323\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87536067\n",
      "Validation Loss:  0.78573895\n",
      "Epoch:  1324\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8877392\n",
      "Validation Loss:  0.7853599\n",
      "Epoch:  1325\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.877187\n",
      "Validation Loss:  0.7860528\n",
      "Epoch:  1326\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88609207\n",
      "Validation Loss:  0.78591746\n",
      "Epoch:  1327\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8773917\n",
      "Validation Loss:  0.78552324\n",
      "Epoch:  1328\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8748693\n",
      "Validation Loss:  0.7856046\n",
      "Epoch:  1329\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8791447\n",
      "Validation Loss:  0.78616333\n",
      "Epoch:  1330\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8804132\n",
      "Validation Loss:  0.785879\n",
      "Epoch:  1331\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8771608\n",
      "Validation Loss:  0.7878848\n",
      "Epoch:  1332\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8802874\n",
      "Validation Loss:  0.78661627\n",
      "Epoch:  1333\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8756254\n",
      "Validation Loss:  0.78537375\n",
      "Epoch:  1334\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87613463\n",
      "Validation Loss:  0.7853239\n",
      "Epoch:  1335\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88383484\n",
      "Validation Loss:  0.7854938\n",
      "Epoch:  1336\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88166475\n",
      "Validation Loss:  0.78569853\n",
      "Epoch:  1337\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87618077\n",
      "Validation Loss:  0.78596646\n",
      "Epoch:  1338\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.883634\n",
      "Validation Loss:  0.91219056\n",
      "Epoch:  1339\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8771397\n",
      "Validation Loss:  0.78578794\n",
      "Epoch:  1340\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.874608\n",
      "Validation Loss:  0.78564185\n",
      "Epoch:  1341\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8778189\n",
      "Validation Loss:  0.9127234\n",
      "Epoch:  1342\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8757907\n",
      "Validation Loss:  0.78615236\n",
      "Epoch:  1343\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8758865\n",
      "Validation Loss:  0.78513443\n",
      "Epoch:  1344\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87582713\n",
      "Validation Loss:  0.7852616\n",
      "Epoch:  1345\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8769832\n",
      "Validation Loss:  0.78580093\n",
      "Epoch:  1346\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8869556\n",
      "Validation Loss:  0.7853045\n",
      "Epoch:  1347\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8786824\n",
      "Validation Loss:  0.7857074\n",
      "Epoch:  1348\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87595546\n",
      "Validation Loss:  0.7854298\n",
      "Epoch:  1349\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8759356\n",
      "Validation Loss:  0.78561753\n",
      "Epoch:  1350\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87874025\n",
      "Validation Loss:  0.7853629\n",
      "Epoch:  1351\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8757985\n",
      "Validation Loss:  0.78511685\n",
      "Epoch:  1352\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8762352\n",
      "Validation Loss:  0.7853737\n",
      "Epoch:  1353\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88114226\n",
      "Validation Loss:  0.7861015\n",
      "Epoch:  1354\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8842734\n",
      "Validation Loss:  0.7853978\n",
      "Epoch:  1355\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8809055\n",
      "Validation Loss:  0.7855582\n",
      "Epoch:  1356\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88037264\n",
      "Validation Loss:  0.78541136\n",
      "Epoch:  1357\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88963544\n",
      "Validation Loss:  0.7854957\n",
      "Epoch:  1358\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87722266\n",
      "Validation Loss:  0.7855787\n",
      "Epoch:  1359\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8758213\n",
      "Validation Loss:  0.7863125\n",
      "Epoch:  1360\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88532454\n",
      "Validation Loss:  0.7852158\n",
      "Epoch:  1361\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8739485\n",
      "Validation Loss:  0.7859451\n",
      "Epoch:  1362\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87572104\n",
      "Validation Loss:  0.7873922\n",
      "Epoch:  1363\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88074875\n",
      "Validation Loss:  0.7860308\n",
      "Epoch:  1364\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8785545\n",
      "Validation Loss:  0.7859028\n",
      "Epoch:  1365\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8759053\n",
      "Validation Loss:  0.7854604\n",
      "Epoch:  1366\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87859243\n",
      "Validation Loss:  0.7852296\n",
      "Epoch:  1367\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87536156\n",
      "Validation Loss:  0.78508985\n",
      "Epoch:  1368\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8738518\n",
      "Validation Loss:  0.7854257\n",
      "Epoch:  1369\n",
      "Training Accuracy:  0.9880952380952381\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8814219\n",
      "Validation Loss:  0.785501\n",
      "Epoch:  1370\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8815899\n",
      "Validation Loss:  0.7855015\n",
      "Epoch:  1371\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87393814\n",
      "Validation Loss:  0.7858763\n",
      "Epoch:  1372\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8771374\n",
      "Validation Loss:  0.7865038\n",
      "Epoch:  1373\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8739749\n",
      "Validation Loss:  0.9117759\n",
      "Epoch:  1374\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8791829\n",
      "Validation Loss:  0.7852686\n",
      "Epoch:  1375\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87822783\n",
      "Validation Loss:  0.78517103\n",
      "Epoch:  1376\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88392013\n",
      "Validation Loss:  0.78503025\n",
      "Epoch:  1377\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.873489\n",
      "Validation Loss:  0.7852112\n",
      "Epoch:  1378\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8864613\n",
      "Validation Loss:  0.78528804\n",
      "Epoch:  1379\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87609184\n",
      "Validation Loss:  0.7852616\n",
      "Epoch:  1380\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.9000771\n",
      "Validation Loss:  0.78497636\n",
      "Epoch:  1381\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88229966\n",
      "Validation Loss:  0.78560305\n",
      "Epoch:  1382\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87324476\n",
      "Validation Loss:  0.7944446\n",
      "Epoch:  1383\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8786973\n",
      "Validation Loss:  0.7850327\n",
      "Epoch:  1384\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8773071\n",
      "Validation Loss:  0.7856425\n",
      "Epoch:  1385\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8825059\n",
      "Validation Loss:  0.7859341\n",
      "Epoch:  1386\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8767104\n",
      "Validation Loss:  0.7876995\n",
      "Epoch:  1387\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8801981\n",
      "Validation Loss:  0.7855049\n",
      "Epoch:  1388\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8742829\n",
      "Validation Loss:  0.9136931\n",
      "Epoch:  1389\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8743749\n",
      "Validation Loss:  0.78511256\n",
      "Epoch:  1390\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88498074\n",
      "Validation Loss:  0.78513676\n",
      "Epoch:  1391\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8767256\n",
      "Validation Loss:  0.7852111\n",
      "Epoch:  1392\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8776778\n",
      "Validation Loss:  0.7850092\n",
      "Epoch:  1393\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8737193\n",
      "Validation Loss:  0.7851863\n",
      "Epoch:  1394\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8736915\n",
      "Validation Loss:  0.78504163\n",
      "Epoch:  1395\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88173693\n",
      "Validation Loss:  0.78537506\n",
      "Epoch:  1396\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88566184\n",
      "Validation Loss:  0.78617287\n",
      "Epoch:  1397\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8839614\n",
      "Validation Loss:  0.7851672\n",
      "Epoch:  1398\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8742497\n",
      "Validation Loss:  0.7856143\n",
      "Epoch:  1399\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8794995\n",
      "Validation Loss:  0.78540885\n",
      "Epoch:  1400\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.875738\n",
      "Validation Loss:  0.78549117\n",
      "Epoch:  1401\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87574744\n",
      "Validation Loss:  0.7852724\n",
      "Epoch:  1402\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87381864\n",
      "Validation Loss:  0.78509325\n",
      "Epoch:  1403\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87525094\n",
      "Validation Loss:  0.78503495\n",
      "Epoch:  1404\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.878715\n",
      "Validation Loss:  0.78506833\n",
      "Epoch:  1405\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8840136\n",
      "Validation Loss:  0.7849943\n",
      "Epoch:  1406\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8784766\n",
      "Validation Loss:  0.7858319\n",
      "Epoch:  1407\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8800158\n",
      "Validation Loss:  0.7855715\n",
      "Epoch:  1408\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87559515\n",
      "Validation Loss:  0.7848917\n",
      "Epoch:  1409\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8727478\n",
      "Validation Loss:  0.78823406\n",
      "Epoch:  1410\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8739972\n",
      "Validation Loss:  0.7850781\n",
      "Epoch:  1411\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8744093\n",
      "Validation Loss:  0.78565407\n",
      "Epoch:  1412\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8854268\n",
      "Validation Loss:  0.9120742\n",
      "Epoch:  1413\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87385863\n",
      "Validation Loss:  0.785359\n",
      "Epoch:  1414\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87827307\n",
      "Validation Loss:  0.9123767\n",
      "Epoch:  1415\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8728913\n",
      "Validation Loss:  0.7851337\n",
      "Epoch:  1416\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87395525\n",
      "Validation Loss:  0.7849299\n",
      "Epoch:  1417\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8751138\n",
      "Validation Loss:  0.78475124\n",
      "Epoch:  1418\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8725202\n",
      "Validation Loss:  0.7853875\n",
      "Epoch:  1419\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87641716\n",
      "Validation Loss:  0.7848009\n",
      "Epoch:  1420\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8728453\n",
      "Validation Loss:  0.9116292\n",
      "Epoch:  1421\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8753579\n",
      "Validation Loss:  0.7847959\n",
      "Epoch:  1422\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8741533\n",
      "Validation Loss:  0.7855979\n",
      "Epoch:  1423\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87445956\n",
      "Validation Loss:  0.7856409\n",
      "Epoch:  1424\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87267107\n",
      "Validation Loss:  0.78464884\n",
      "Epoch:  1425\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8764587\n",
      "Validation Loss:  0.78522676\n",
      "Epoch:  1426\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.874722\n",
      "Validation Loss:  0.7846461\n",
      "Epoch:  1427\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87443113\n",
      "Validation Loss:  0.78475076\n",
      "Epoch:  1428\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8753423\n",
      "Validation Loss:  0.78805673\n",
      "Epoch:  1429\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87263256\n",
      "Validation Loss:  0.7847372\n",
      "Epoch:  1430\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.874837\n",
      "Validation Loss:  0.78525656\n",
      "Epoch:  1431\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8723424\n",
      "Validation Loss:  0.7851033\n",
      "Epoch:  1432\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87439656\n",
      "Validation Loss:  0.7852642\n",
      "Epoch:  1433\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.89731205\n",
      "Validation Loss:  0.7847567\n",
      "Epoch:  1434\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87649786\n",
      "Validation Loss:  0.78487664\n",
      "Epoch:  1435\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87235576\n",
      "Validation Loss:  0.7846877\n",
      "Epoch:  1436\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88146365\n",
      "Validation Loss:  0.78477293\n",
      "Epoch:  1437\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8727192\n",
      "Validation Loss:  0.7854417\n",
      "Epoch:  1438\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8790664\n",
      "Validation Loss:  0.7848745\n",
      "Epoch:  1439\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87227386\n",
      "Validation Loss:  0.78497314\n",
      "Epoch:  1440\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87532896\n",
      "Validation Loss:  0.7850109\n",
      "Epoch:  1441\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87315744\n",
      "Validation Loss:  0.78448355\n",
      "Epoch:  1442\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87776357\n",
      "Validation Loss:  0.7847315\n",
      "Epoch:  1443\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87377995\n",
      "Validation Loss:  0.78456146\n",
      "Epoch:  1444\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8809439\n",
      "Validation Loss:  0.78466356\n",
      "Epoch:  1445\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8756424\n",
      "Validation Loss:  0.7850216\n",
      "Epoch:  1446\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88710797\n",
      "Validation Loss:  0.78515774\n",
      "Epoch:  1447\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8748373\n",
      "Validation Loss:  0.78445524\n",
      "Epoch:  1448\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87645406\n",
      "Validation Loss:  0.7855827\n",
      "Epoch:  1449\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87591916\n",
      "Validation Loss:  0.7874662\n",
      "Epoch:  1450\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8850815\n",
      "Validation Loss:  0.78478956\n",
      "Epoch:  1451\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8741237\n",
      "Validation Loss:  0.78457725\n",
      "Epoch:  1452\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8730258\n",
      "Validation Loss:  0.7845772\n",
      "Epoch:  1453\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87487996\n",
      "Validation Loss:  0.7848359\n",
      "Epoch:  1454\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8777016\n",
      "Validation Loss:  0.7848095\n",
      "Epoch:  1455\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87294126\n",
      "Validation Loss:  0.784911\n",
      "Epoch:  1456\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8760694\n",
      "Validation Loss:  0.78500766\n",
      "Epoch:  1457\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8736174\n",
      "Validation Loss:  0.78459835\n",
      "Epoch:  1458\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8862323\n",
      "Validation Loss:  0.784779\n",
      "Epoch:  1459\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87591356\n",
      "Validation Loss:  0.7849647\n",
      "Epoch:  1460\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87333816\n",
      "Validation Loss:  0.7846288\n",
      "Epoch:  1461\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8760582\n",
      "Validation Loss:  0.7856081\n",
      "Epoch:  1462\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8723676\n",
      "Validation Loss:  0.78448755\n",
      "Epoch:  1463\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8777938\n",
      "Validation Loss:  0.7846138\n",
      "Epoch:  1464\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88055396\n",
      "Validation Loss:  0.7844877\n",
      "Epoch:  1465\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8720098\n",
      "Validation Loss:  0.7850061\n",
      "Epoch:  1466\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87642837\n",
      "Validation Loss:  0.78700453\n",
      "Epoch:  1467\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87815964\n",
      "Validation Loss:  0.78458196\n",
      "Epoch:  1468\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8770569\n",
      "Validation Loss:  0.78447574\n",
      "Epoch:  1469\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8725752\n",
      "Validation Loss:  0.7845116\n",
      "Epoch:  1470\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8775906\n",
      "Validation Loss:  0.7845327\n",
      "Epoch:  1471\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.88497674\n",
      "Validation Loss:  0.78457737\n",
      "Epoch:  1472\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8844645\n",
      "Validation Loss:  0.7845354\n",
      "Epoch:  1473\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8757996\n",
      "Validation Loss:  0.78446007\n",
      "Epoch:  1474\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8736977\n",
      "Validation Loss:  0.78468364\n",
      "Epoch:  1475\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87353724\n",
      "Validation Loss:  0.784344\n",
      "Epoch:  1476\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87465173\n",
      "Validation Loss:  0.7850591\n",
      "Epoch:  1477\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87413925\n",
      "Validation Loss:  0.78449595\n",
      "Epoch:  1478\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88184893\n",
      "Validation Loss:  0.7845053\n",
      "Epoch:  1479\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.875473\n",
      "Validation Loss:  0.78529865\n",
      "Epoch:  1480\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87221545\n",
      "Validation Loss:  0.7892308\n",
      "Epoch:  1481\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88319194\n",
      "Validation Loss:  0.7844357\n",
      "Epoch:  1482\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8788693\n",
      "Validation Loss:  0.7848543\n",
      "Epoch:  1483\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88966167\n",
      "Validation Loss:  0.7844805\n",
      "Epoch:  1484\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.87136793\n",
      "Validation Loss:  0.7843999\n",
      "Epoch:  1485\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8742365\n",
      "Validation Loss:  0.784346\n",
      "Epoch:  1486\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8740711\n",
      "Validation Loss:  0.7848491\n",
      "Epoch:  1487\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87308836\n",
      "Validation Loss:  0.7860666\n",
      "Epoch:  1488\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8728562\n",
      "Validation Loss:  0.78485113\n",
      "Epoch:  1489\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8783232\n",
      "Validation Loss:  0.78471714\n",
      "Epoch:  1490\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.873143\n",
      "Validation Loss:  0.7844081\n",
      "Epoch:  1491\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8747563\n",
      "Validation Loss:  0.7849116\n",
      "Epoch:  1492\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8823227\n",
      "Validation Loss:  0.78500736\n",
      "Epoch:  1493\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87138087\n",
      "Validation Loss:  0.9112516\n",
      "Epoch:  1494\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.871259\n",
      "Validation Loss:  0.78479\n",
      "Epoch:  1495\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8737569\n",
      "Validation Loss:  0.7847875\n",
      "Epoch:  1496\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87205935\n",
      "Validation Loss:  0.78410995\n",
      "Epoch:  1497\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87507826\n",
      "Validation Loss:  0.7844005\n",
      "Epoch:  1498\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87268126\n",
      "Validation Loss:  0.7843548\n",
      "Epoch:  1499\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87589467\n",
      "Validation Loss:  0.9112967\n",
      "Epoch:  1500\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87326384\n",
      "Validation Loss:  0.7845661\n",
      "Epoch:  1501\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87386775\n",
      "Validation Loss:  0.7852831\n",
      "Epoch:  1502\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8708833\n",
      "Validation Loss:  0.78407\n",
      "Epoch:  1503\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87232673\n",
      "Validation Loss:  0.7846004\n",
      "Epoch:  1504\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88121784\n",
      "Validation Loss:  0.78424054\n",
      "Epoch:  1505\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8894115\n",
      "Validation Loss:  0.7842697\n",
      "Epoch:  1506\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8727857\n",
      "Validation Loss:  0.784644\n",
      "Epoch:  1507\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87183744\n",
      "Validation Loss:  0.78441375\n",
      "Epoch:  1508\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8712269\n",
      "Validation Loss:  0.7846695\n",
      "Epoch:  1509\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8762877\n",
      "Validation Loss:  0.7844819\n",
      "Epoch:  1510\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87153614\n",
      "Validation Loss:  0.7842283\n",
      "Epoch:  1511\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8736405\n",
      "Validation Loss:  0.78430885\n",
      "Epoch:  1512\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87478757\n",
      "Validation Loss:  0.78443277\n",
      "Epoch:  1513\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88112634\n",
      "Validation Loss:  0.78527063\n",
      "Epoch:  1514\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8760334\n",
      "Validation Loss:  0.78438103\n",
      "Epoch:  1515\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87665373\n",
      "Validation Loss:  0.9116301\n",
      "Epoch:  1516\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87454945\n",
      "Validation Loss:  0.78531665\n",
      "Epoch:  1517\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8747475\n",
      "Validation Loss:  0.7848633\n",
      "Epoch:  1518\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8708078\n",
      "Validation Loss:  0.7848434\n",
      "Epoch:  1519\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8776488\n",
      "Validation Loss:  0.7842136\n",
      "Epoch:  1520\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8719326\n",
      "Validation Loss:  0.7849819\n",
      "Epoch:  1521\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87253326\n",
      "Validation Loss:  0.7845971\n",
      "Epoch:  1522\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8791578\n",
      "Validation Loss:  0.7840853\n",
      "Epoch:  1523\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8794121\n",
      "Validation Loss:  0.784571\n",
      "Epoch:  1524\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87564635\n",
      "Validation Loss:  0.7842932\n",
      "Epoch:  1525\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8804017\n",
      "Validation Loss:  0.78556067\n",
      "Epoch:  1526\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8720523\n",
      "Validation Loss:  0.7841517\n",
      "Epoch:  1527\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87242913\n",
      "Validation Loss:  0.78426486\n",
      "Epoch:  1528\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87539107\n",
      "Validation Loss:  0.7872779\n",
      "Epoch:  1529\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88087523\n",
      "Validation Loss:  0.7849408\n",
      "Epoch:  1530\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8801065\n",
      "Validation Loss:  0.78611183\n",
      "Epoch:  1531\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8729024\n",
      "Validation Loss:  0.78418857\n",
      "Epoch:  1532\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87040776\n",
      "Validation Loss:  0.911397\n",
      "Epoch:  1533\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8705553\n",
      "Validation Loss:  0.91103077\n",
      "Epoch:  1534\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8734594\n",
      "Validation Loss:  0.7848731\n",
      "Epoch:  1535\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8781153\n",
      "Validation Loss:  0.7838484\n",
      "Epoch:  1536\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8733611\n",
      "Validation Loss:  0.7841944\n",
      "Epoch:  1537\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8774539\n",
      "Validation Loss:  0.7866861\n",
      "Epoch:  1538\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.873433\n",
      "Validation Loss:  0.7842878\n",
      "Epoch:  1539\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8765086\n",
      "Validation Loss:  0.7854689\n",
      "Epoch:  1540\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8698162\n",
      "Validation Loss:  0.78652966\n",
      "Epoch:  1541\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87362725\n",
      "Validation Loss:  0.7845387\n",
      "Epoch:  1542\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87624437\n",
      "Validation Loss:  0.784507\n",
      "Epoch:  1543\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87273717\n",
      "Validation Loss:  0.78458536\n",
      "Epoch:  1544\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8740253\n",
      "Validation Loss:  0.78439\n",
      "Epoch:  1545\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8736807\n",
      "Validation Loss:  0.784386\n",
      "Epoch:  1546\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86993307\n",
      "Validation Loss:  0.7853418\n",
      "Epoch:  1547\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8740194\n",
      "Validation Loss:  0.78428537\n",
      "Epoch:  1548\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87640333\n",
      "Validation Loss:  0.7867979\n",
      "Epoch:  1549\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8698294\n",
      "Validation Loss:  0.7847032\n",
      "Epoch:  1550\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8724717\n",
      "Validation Loss:  0.7854087\n",
      "Epoch:  1551\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8712033\n",
      "Validation Loss:  0.7842394\n",
      "Epoch:  1552\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87398\n",
      "Validation Loss:  0.7839851\n",
      "Epoch:  1553\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.87266594\n",
      "Validation Loss:  0.7840477\n",
      "Epoch:  1554\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8734096\n",
      "Validation Loss:  0.7841342\n",
      "Epoch:  1555\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87834364\n",
      "Validation Loss:  0.7840226\n",
      "Epoch:  1556\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8721203\n",
      "Validation Loss:  0.7838835\n",
      "Epoch:  1557\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.871037\n",
      "Validation Loss:  0.78399885\n",
      "Epoch:  1558\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8795388\n",
      "Validation Loss:  0.78403413\n",
      "Epoch:  1559\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8775992\n",
      "Validation Loss:  0.7871763\n",
      "Epoch:  1560\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8694536\n",
      "Validation Loss:  0.7846856\n",
      "Epoch:  1561\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8730996\n",
      "Validation Loss:  0.78424263\n",
      "Epoch:  1562\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8705218\n",
      "Validation Loss:  0.7845618\n",
      "Epoch:  1563\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8707156\n",
      "Validation Loss:  0.78605014\n",
      "Epoch:  1564\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8716387\n",
      "Validation Loss:  0.78513396\n",
      "Epoch:  1565\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8729972\n",
      "Validation Loss:  0.78429073\n",
      "Epoch:  1566\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86955947\n",
      "Validation Loss:  0.7837496\n",
      "Epoch:  1567\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8847044\n",
      "Validation Loss:  0.7837635\n",
      "Epoch:  1568\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8792849\n",
      "Validation Loss:  0.78439367\n",
      "Epoch:  1569\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8710584\n",
      "Validation Loss:  0.78397673\n",
      "Epoch:  1570\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8701035\n",
      "Validation Loss:  0.784901\n",
      "Epoch:  1571\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87135947\n",
      "Validation Loss:  0.7844519\n",
      "Epoch:  1572\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86929065\n",
      "Validation Loss:  0.784555\n",
      "Epoch:  1573\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8692487\n",
      "Validation Loss:  0.7839255\n",
      "Epoch:  1574\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8745548\n",
      "Validation Loss:  0.7840643\n",
      "Epoch:  1575\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8726787\n",
      "Validation Loss:  0.7841269\n",
      "Epoch:  1576\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.875421\n",
      "Validation Loss:  0.78386825\n",
      "Epoch:  1577\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8783727\n",
      "Validation Loss:  0.7840881\n",
      "Epoch:  1578\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8711318\n",
      "Validation Loss:  0.9124652\n",
      "Epoch:  1579\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8724204\n",
      "Validation Loss:  0.78433126\n",
      "Epoch:  1580\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8694286\n",
      "Validation Loss:  0.78392035\n",
      "Epoch:  1581\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8725715\n",
      "Validation Loss:  0.78403324\n",
      "Epoch:  1582\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8707155\n",
      "Validation Loss:  0.7851056\n",
      "Epoch:  1583\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87036186\n",
      "Validation Loss:  0.9104277\n",
      "Epoch:  1584\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8699226\n",
      "Validation Loss:  0.78420204\n",
      "Epoch:  1585\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87069553\n",
      "Validation Loss:  0.7843022\n",
      "Epoch:  1586\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8749401\n",
      "Validation Loss:  0.78428346\n",
      "Epoch:  1587\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87118095\n",
      "Validation Loss:  0.7843788\n",
      "Epoch:  1588\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8711342\n",
      "Validation Loss:  0.7845168\n",
      "Epoch:  1589\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8697836\n",
      "Validation Loss:  0.7838129\n",
      "Epoch:  1590\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87850064\n",
      "Validation Loss:  0.784062\n",
      "Epoch:  1591\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86929137\n",
      "Validation Loss:  0.7848959\n",
      "Epoch:  1592\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8722145\n",
      "Validation Loss:  0.78427684\n",
      "Epoch:  1593\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8708861\n",
      "Validation Loss:  0.7841086\n",
      "Epoch:  1594\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8718723\n",
      "Validation Loss:  0.7836894\n",
      "Epoch:  1595\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.87220746\n",
      "Validation Loss:  0.78384703\n",
      "Epoch:  1596\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8729291\n",
      "Validation Loss:  0.78421164\n",
      "Epoch:  1597\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8690834\n",
      "Validation Loss:  0.7839113\n",
      "Epoch:  1598\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87006485\n",
      "Validation Loss:  0.78452414\n",
      "Epoch:  1599\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86988986\n",
      "Validation Loss:  0.7836831\n",
      "Epoch:  1600\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86870265\n",
      "Validation Loss:  0.78457767\n",
      "Epoch:  1601\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8781572\n",
      "Validation Loss:  0.784053\n",
      "Epoch:  1602\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87096775\n",
      "Validation Loss:  0.78424054\n",
      "Epoch:  1603\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8696872\n",
      "Validation Loss:  0.7840858\n",
      "Epoch:  1604\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8702501\n",
      "Validation Loss:  0.784592\n",
      "Epoch:  1605\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8703674\n",
      "Validation Loss:  0.7838515\n",
      "Epoch:  1606\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87443006\n",
      "Validation Loss:  0.7839721\n",
      "Epoch:  1607\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8694288\n",
      "Validation Loss:  0.7838674\n",
      "Epoch:  1608\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8702732\n",
      "Validation Loss:  0.7838089\n",
      "Epoch:  1609\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.871769\n",
      "Validation Loss:  0.78418094\n",
      "Epoch:  1610\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8695102\n",
      "Validation Loss:  0.783891\n",
      "Epoch:  1611\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87095654\n",
      "Validation Loss:  0.7839852\n",
      "Epoch:  1612\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8712319\n",
      "Validation Loss:  0.7839707\n",
      "Epoch:  1613\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8761986\n",
      "Validation Loss:  0.78395635\n",
      "Epoch:  1614\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8750767\n",
      "Validation Loss:  0.78376293\n",
      "Epoch:  1615\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8704523\n",
      "Validation Loss:  0.784\n",
      "Epoch:  1616\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8699864\n",
      "Validation Loss:  0.7837521\n",
      "Epoch:  1617\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.870676\n",
      "Validation Loss:  0.7839786\n",
      "Epoch:  1618\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87087554\n",
      "Validation Loss:  0.78442085\n",
      "Epoch:  1619\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8726967\n",
      "Validation Loss:  0.7838151\n",
      "Epoch:  1620\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87150675\n",
      "Validation Loss:  0.7838188\n",
      "Epoch:  1621\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8698183\n",
      "Validation Loss:  0.78367966\n",
      "Epoch:  1622\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8705036\n",
      "Validation Loss:  0.78439957\n",
      "Epoch:  1623\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8706013\n",
      "Validation Loss:  0.7868394\n",
      "Epoch:  1624\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8812129\n",
      "Validation Loss:  0.78434706\n",
      "Epoch:  1625\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.870463\n",
      "Validation Loss:  0.7836827\n",
      "Epoch:  1626\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8730942\n",
      "Validation Loss:  0.7839969\n",
      "Epoch:  1627\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.871652\n",
      "Validation Loss:  0.78441447\n",
      "Epoch:  1628\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8701342\n",
      "Validation Loss:  0.78378946\n",
      "Epoch:  1629\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8778149\n",
      "Validation Loss:  0.78375113\n",
      "Epoch:  1630\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8742926\n",
      "Validation Loss:  0.78436947\n",
      "Epoch:  1631\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8696084\n",
      "Validation Loss:  0.7838046\n",
      "Epoch:  1632\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8708655\n",
      "Validation Loss:  0.7838384\n",
      "Epoch:  1633\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8745931\n",
      "Validation Loss:  0.78395647\n",
      "Epoch:  1634\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87181836\n",
      "Validation Loss:  0.7836448\n",
      "Epoch:  1635\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8715784\n",
      "Validation Loss:  0.78440905\n",
      "Epoch:  1636\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8781783\n",
      "Validation Loss:  0.78356344\n",
      "Epoch:  1637\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87168807\n",
      "Validation Loss:  0.7840406\n",
      "Epoch:  1638\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86821496\n",
      "Validation Loss:  0.7835906\n",
      "Epoch:  1639\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.871346\n",
      "Validation Loss:  0.7837663\n",
      "Epoch:  1640\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86880285\n",
      "Validation Loss:  0.78366727\n",
      "Epoch:  1641\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8694054\n",
      "Validation Loss:  0.7836384\n",
      "Epoch:  1642\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8705274\n",
      "Validation Loss:  0.78584397\n",
      "Epoch:  1643\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86904466\n",
      "Validation Loss:  0.783906\n",
      "Epoch:  1644\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8753857\n",
      "Validation Loss:  0.78362125\n",
      "Epoch:  1645\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8745887\n",
      "Validation Loss:  0.7834925\n",
      "Epoch:  1646\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8820068\n",
      "Validation Loss:  0.7835711\n",
      "Epoch:  1647\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87501353\n",
      "Validation Loss:  0.78356045\n",
      "Epoch:  1648\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8688997\n",
      "Validation Loss:  0.7835563\n",
      "Epoch:  1649\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87140214\n",
      "Validation Loss:  0.7840895\n",
      "Epoch:  1650\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8697775\n",
      "Validation Loss:  0.7835366\n",
      "Epoch:  1651\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86883676\n",
      "Validation Loss:  0.78365415\n",
      "Epoch:  1652\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87116426\n",
      "Validation Loss:  0.7837444\n",
      "Epoch:  1653\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86844426\n",
      "Validation Loss:  0.7833824\n",
      "Epoch:  1654\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8711678\n",
      "Validation Loss:  0.78337866\n",
      "Epoch:  1655\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8701662\n",
      "Validation Loss:  0.78353375\n",
      "Epoch:  1656\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8694598\n",
      "Validation Loss:  0.78339255\n",
      "Epoch:  1657\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8731562\n",
      "Validation Loss:  0.78386945\n",
      "Epoch:  1658\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87244666\n",
      "Validation Loss:  0.7837996\n",
      "Epoch:  1659\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8686776\n",
      "Validation Loss:  0.7836112\n",
      "Epoch:  1660\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8738865\n",
      "Validation Loss:  0.7837019\n",
      "Epoch:  1661\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8680418\n",
      "Validation Loss:  0.7836842\n",
      "Epoch:  1662\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8699177\n",
      "Validation Loss:  0.7836877\n",
      "Epoch:  1663\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87053156\n",
      "Validation Loss:  0.78381914\n",
      "Epoch:  1664\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8672842\n",
      "Validation Loss:  0.7832565\n",
      "Epoch:  1665\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86819565\n",
      "Validation Loss:  0.78348607\n",
      "Epoch:  1666\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87526435\n",
      "Validation Loss:  0.78451777\n",
      "Epoch:  1667\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86942667\n",
      "Validation Loss:  0.7839224\n",
      "Epoch:  1668\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86765075\n",
      "Validation Loss:  0.7833873\n",
      "Epoch:  1669\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8688204\n",
      "Validation Loss:  0.78338623\n",
      "Epoch:  1670\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8732887\n",
      "Validation Loss:  0.78554636\n",
      "Epoch:  1671\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88001317\n",
      "Validation Loss:  0.7839076\n",
      "Epoch:  1672\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8703545\n",
      "Validation Loss:  0.9100771\n",
      "Epoch:  1673\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8691176\n",
      "Validation Loss:  0.7838813\n",
      "Epoch:  1674\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86933744\n",
      "Validation Loss:  0.7833987\n",
      "Epoch:  1675\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8713011\n",
      "Validation Loss:  0.7833671\n",
      "Epoch:  1676\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8759018\n",
      "Validation Loss:  0.7838949\n",
      "Epoch:  1677\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8745174\n",
      "Validation Loss:  0.78350145\n",
      "Epoch:  1678\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8756331\n",
      "Validation Loss:  0.78366476\n",
      "Epoch:  1679\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8684358\n",
      "Validation Loss:  0.7852914\n",
      "Epoch:  1680\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8679131\n",
      "Validation Loss:  0.78356254\n",
      "Epoch:  1681\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87116945\n",
      "Validation Loss:  0.783331\n",
      "Epoch:  1682\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8702749\n",
      "Validation Loss:  0.7834634\n",
      "Epoch:  1683\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8770712\n",
      "Validation Loss:  0.78371465\n",
      "Epoch:  1684\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8678034\n",
      "Validation Loss:  0.78350705\n",
      "Epoch:  1685\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8773265\n",
      "Validation Loss:  0.7836426\n",
      "Epoch:  1686\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8726462\n",
      "Validation Loss:  0.78359205\n",
      "Epoch:  1687\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87033165\n",
      "Validation Loss:  0.7836485\n",
      "Epoch:  1688\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8691344\n",
      "Validation Loss:  0.7837912\n",
      "Epoch:  1689\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8685617\n",
      "Validation Loss:  0.78329957\n",
      "Epoch:  1690\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8669572\n",
      "Validation Loss:  0.7835275\n",
      "Epoch:  1691\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87308145\n",
      "Validation Loss:  0.7834529\n",
      "Epoch:  1692\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8724735\n",
      "Validation Loss:  0.78343886\n",
      "Epoch:  1693\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8710526\n",
      "Validation Loss:  0.78356457\n",
      "Epoch:  1694\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86963546\n",
      "Validation Loss:  0.7856642\n",
      "Epoch:  1695\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87201345\n",
      "Validation Loss:  0.78328943\n",
      "Epoch:  1696\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8677309\n",
      "Validation Loss:  0.7864061\n",
      "Epoch:  1697\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.869686\n",
      "Validation Loss:  0.78339195\n",
      "Epoch:  1698\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87054\n",
      "Validation Loss:  0.7835373\n",
      "Epoch:  1699\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87028515\n",
      "Validation Loss:  0.7839046\n",
      "Epoch:  1700\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8699653\n",
      "Validation Loss:  0.7833006\n",
      "Epoch:  1701\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86930037\n",
      "Validation Loss:  0.78329235\n",
      "Epoch:  1702\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8822805\n",
      "Validation Loss:  0.78370506\n",
      "Epoch:  1703\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87887913\n",
      "Validation Loss:  0.7835551\n",
      "Epoch:  1704\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87040037\n",
      "Validation Loss:  0.7839618\n",
      "Epoch:  1705\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.867688\n",
      "Validation Loss:  0.7882128\n",
      "Epoch:  1706\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86812466\n",
      "Validation Loss:  0.7832946\n",
      "Epoch:  1707\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8731033\n",
      "Validation Loss:  0.7854543\n",
      "Epoch:  1708\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86839145\n",
      "Validation Loss:  0.91426283\n",
      "Epoch:  1709\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8690401\n",
      "Validation Loss:  0.7833882\n",
      "Epoch:  1710\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8752386\n",
      "Validation Loss:  0.7832595\n",
      "Epoch:  1711\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86870694\n",
      "Validation Loss:  0.78325856\n",
      "Epoch:  1712\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8689293\n",
      "Validation Loss:  0.7834205\n",
      "Epoch:  1713\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8699201\n",
      "Validation Loss:  0.784587\n",
      "Epoch:  1714\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86750174\n",
      "Validation Loss:  0.7831931\n",
      "Epoch:  1715\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86984324\n",
      "Validation Loss:  0.783305\n",
      "Epoch:  1716\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8674086\n",
      "Validation Loss:  0.7860637\n",
      "Epoch:  1717\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8703085\n",
      "Validation Loss:  0.7832962\n",
      "Epoch:  1718\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86889565\n",
      "Validation Loss:  0.78362614\n",
      "Epoch:  1719\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8675869\n",
      "Validation Loss:  0.78317547\n",
      "Epoch:  1720\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86724955\n",
      "Validation Loss:  0.7832237\n",
      "Epoch:  1721\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8715349\n",
      "Validation Loss:  0.78337145\n",
      "Epoch:  1722\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.868354\n",
      "Validation Loss:  0.7833267\n",
      "Epoch:  1723\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87111425\n",
      "Validation Loss:  0.7832681\n",
      "Epoch:  1724\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8699606\n",
      "Validation Loss:  0.7837165\n",
      "Epoch:  1725\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8718495\n",
      "Validation Loss:  0.7834696\n",
      "Epoch:  1726\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8734933\n",
      "Validation Loss:  0.7832758\n",
      "Epoch:  1727\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8676101\n",
      "Validation Loss:  0.78336895\n",
      "Epoch:  1728\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8676926\n",
      "Validation Loss:  0.78317696\n",
      "Epoch:  1729\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8727698\n",
      "Validation Loss:  0.9101444\n",
      "Epoch:  1730\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8676808\n",
      "Validation Loss:  0.7841536\n",
      "Epoch:  1731\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86806476\n",
      "Validation Loss:  0.7832413\n",
      "Epoch:  1732\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8841171\n",
      "Validation Loss:  0.78308207\n",
      "Epoch:  1733\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8670442\n",
      "Validation Loss:  0.7832766\n",
      "Epoch:  1734\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86653554\n",
      "Validation Loss:  0.7830997\n",
      "Epoch:  1735\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8690811\n",
      "Validation Loss:  0.7834359\n",
      "Epoch:  1736\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.86885834\n",
      "Validation Loss:  0.7834934\n",
      "Epoch:  1737\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8676849\n",
      "Validation Loss:  0.7835144\n",
      "Epoch:  1738\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.87060976\n",
      "Validation Loss:  0.9098996\n",
      "Epoch:  1739\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86794364\n",
      "Validation Loss:  0.7835986\n",
      "Epoch:  1740\n",
      "Training Accuracy:  0.9891774891774892\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87078655\n",
      "Validation Loss:  0.7842421\n",
      "Epoch:  1741\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8689422\n",
      "Validation Loss:  0.7831872\n",
      "Epoch:  1742\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8688727\n",
      "Validation Loss:  0.7833524\n",
      "Epoch:  1743\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8683398\n",
      "Validation Loss:  0.7832677\n",
      "Epoch:  1744\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86801475\n",
      "Validation Loss:  0.78321934\n",
      "Epoch:  1745\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8744944\n",
      "Validation Loss:  0.7830709\n",
      "Epoch:  1746\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8683825\n",
      "Validation Loss:  0.78401834\n",
      "Epoch:  1747\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87024736\n",
      "Validation Loss:  0.7830582\n",
      "Epoch:  1748\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8683167\n",
      "Validation Loss:  0.7832187\n",
      "Epoch:  1749\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.88337666\n",
      "Validation Loss:  0.783063\n",
      "Epoch:  1750\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8675968\n",
      "Validation Loss:  0.78405005\n",
      "Epoch:  1751\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8705464\n",
      "Validation Loss:  0.78323805\n",
      "Epoch:  1752\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8752538\n",
      "Validation Loss:  0.7843827\n",
      "Epoch:  1753\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86778206\n",
      "Validation Loss:  0.7832033\n",
      "Epoch:  1754\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87835944\n",
      "Validation Loss:  0.783053\n",
      "Epoch:  1755\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87110466\n",
      "Validation Loss:  0.78364265\n",
      "Epoch:  1756\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86684334\n",
      "Validation Loss:  0.7829433\n",
      "Epoch:  1757\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8706254\n",
      "Validation Loss:  0.7837582\n",
      "Epoch:  1758\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86752295\n",
      "Validation Loss:  0.78316545\n",
      "Epoch:  1759\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8708714\n",
      "Validation Loss:  0.7834858\n",
      "Epoch:  1760\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86894345\n",
      "Validation Loss:  0.78386873\n",
      "Epoch:  1761\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87514174\n",
      "Validation Loss:  0.7860063\n",
      "Epoch:  1762\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8677\n",
      "Validation Loss:  0.78298515\n",
      "Epoch:  1763\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8676989\n",
      "Validation Loss:  0.7831071\n",
      "Epoch:  1764\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8676625\n",
      "Validation Loss:  0.7833694\n",
      "Epoch:  1765\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.876334\n",
      "Validation Loss:  0.7831569\n",
      "Epoch:  1766\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8684171\n",
      "Validation Loss:  0.78313917\n",
      "Epoch:  1767\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8690208\n",
      "Validation Loss:  0.90986544\n",
      "Epoch:  1768\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.866643\n",
      "Validation Loss:  0.78369147\n",
      "Epoch:  1769\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8666758\n",
      "Validation Loss:  0.7835421\n",
      "Epoch:  1770\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8664313\n",
      "Validation Loss:  0.7830275\n",
      "Epoch:  1771\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.866294\n",
      "Validation Loss:  0.7846927\n",
      "Epoch:  1772\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8681379\n",
      "Validation Loss:  0.78332174\n",
      "Epoch:  1773\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.86874837\n",
      "Validation Loss:  0.7831126\n",
      "Epoch:  1774\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8695652\n",
      "Validation Loss:  0.7852613\n",
      "Epoch:  1775\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8659897\n",
      "Validation Loss:  0.7832692\n",
      "Epoch:  1776\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8681363\n",
      "Validation Loss:  0.78352594\n",
      "Epoch:  1777\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86783105\n",
      "Validation Loss:  0.7841341\n",
      "Epoch:  1778\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87678003\n",
      "Validation Loss:  0.7835659\n",
      "Epoch:  1779\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8679805\n",
      "Validation Loss:  0.78401756\n",
      "Epoch:  1780\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8677589\n",
      "Validation Loss:  0.7835239\n",
      "Epoch:  1781\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8700034\n",
      "Validation Loss:  0.78441185\n",
      "Epoch:  1782\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86582386\n",
      "Validation Loss:  0.78345627\n",
      "Epoch:  1783\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86759645\n",
      "Validation Loss:  0.78284746\n",
      "Epoch:  1784\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86873114\n",
      "Validation Loss:  0.783179\n",
      "Epoch:  1785\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87037486\n",
      "Validation Loss:  0.7835286\n",
      "Epoch:  1786\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87205887\n",
      "Validation Loss:  0.78370285\n",
      "Epoch:  1787\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86634105\n",
      "Validation Loss:  0.7832212\n",
      "Epoch:  1788\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86779606\n",
      "Validation Loss:  0.78316337\n",
      "Epoch:  1789\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8661164\n",
      "Validation Loss:  0.7835898\n",
      "Epoch:  1790\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8662775\n",
      "Validation Loss:  0.7829738\n",
      "Epoch:  1791\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8819433\n",
      "Validation Loss:  0.7830995\n",
      "Epoch:  1792\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86760336\n",
      "Validation Loss:  0.7832815\n",
      "Epoch:  1793\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87078804\n",
      "Validation Loss:  0.9101252\n",
      "Epoch:  1794\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8673055\n",
      "Validation Loss:  0.78308076\n",
      "Epoch:  1795\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86573535\n",
      "Validation Loss:  0.78282267\n",
      "Epoch:  1796\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86941123\n",
      "Validation Loss:  0.7829865\n",
      "Epoch:  1797\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86835086\n",
      "Validation Loss:  0.7830132\n",
      "Epoch:  1798\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8681785\n",
      "Validation Loss:  0.78277224\n",
      "Epoch:  1799\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8669281\n",
      "Validation Loss:  0.7834443\n",
      "Epoch:  1800\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8664656\n",
      "Validation Loss:  0.7828127\n",
      "Epoch:  1801\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8712996\n",
      "Validation Loss:  0.7828163\n",
      "Epoch:  1802\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8662495\n",
      "Validation Loss:  0.782775\n",
      "Epoch:  1803\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8675109\n",
      "Validation Loss:  0.91007465\n",
      "Epoch:  1804\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86932653\n",
      "Validation Loss:  0.7836461\n",
      "Epoch:  1805\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8688327\n",
      "Validation Loss:  0.90956414\n",
      "Epoch:  1806\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8679366\n",
      "Validation Loss:  0.78291684\n",
      "Epoch:  1807\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86784637\n",
      "Validation Loss:  0.7830843\n",
      "Epoch:  1808\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86616045\n",
      "Validation Loss:  0.782814\n",
      "Epoch:  1809\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8706991\n",
      "Validation Loss:  0.782965\n",
      "Epoch:  1810\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86643666\n",
      "Validation Loss:  0.78337425\n",
      "Epoch:  1811\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8653734\n",
      "Validation Loss:  0.7827576\n",
      "Epoch:  1812\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8658726\n",
      "Validation Loss:  0.78285027\n",
      "Epoch:  1813\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8679655\n",
      "Validation Loss:  0.7829941\n",
      "Epoch:  1814\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87057936\n",
      "Validation Loss:  0.7828336\n",
      "Epoch:  1815\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86611295\n",
      "Validation Loss:  0.7841207\n",
      "Epoch:  1816\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8730302\n",
      "Validation Loss:  0.78313166\n",
      "Epoch:  1817\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8666599\n",
      "Validation Loss:  0.7827236\n",
      "Epoch:  1818\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8679033\n",
      "Validation Loss:  0.7832106\n",
      "Epoch:  1819\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86687386\n",
      "Validation Loss:  0.783329\n",
      "Epoch:  1820\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87484574\n",
      "Validation Loss:  0.78282976\n",
      "Epoch:  1821\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8681786\n",
      "Validation Loss:  0.783006\n",
      "Epoch:  1822\n",
      "Training Accuracy:  0.9902597402597403\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8705615\n",
      "Validation Loss:  0.7843265\n",
      "Epoch:  1823\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86588085\n",
      "Validation Loss:  0.78287834\n",
      "Epoch:  1824\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8673122\n",
      "Validation Loss:  0.78298247\n",
      "Epoch:  1825\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8655209\n",
      "Validation Loss:  0.7826056\n",
      "Epoch:  1826\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86812973\n",
      "Validation Loss:  0.78558195\n",
      "Epoch:  1827\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86531746\n",
      "Validation Loss:  0.7833332\n",
      "Epoch:  1828\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87571627\n",
      "Validation Loss:  0.7832294\n",
      "Epoch:  1829\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8664044\n",
      "Validation Loss:  0.7830314\n",
      "Epoch:  1830\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8705002\n",
      "Validation Loss:  0.78405225\n",
      "Epoch:  1831\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8738653\n",
      "Validation Loss:  0.7827094\n",
      "Epoch:  1832\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86678696\n",
      "Validation Loss:  0.78281504\n",
      "Epoch:  1833\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86936504\n",
      "Validation Loss:  0.78289896\n",
      "Epoch:  1834\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8668722\n",
      "Validation Loss:  0.7829107\n",
      "Epoch:  1835\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8692019\n",
      "Validation Loss:  0.9097272\n",
      "Epoch:  1836\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8656746\n",
      "Validation Loss:  0.7832171\n",
      "Epoch:  1837\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86634254\n",
      "Validation Loss:  0.78527457\n",
      "Epoch:  1838\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8649408\n",
      "Validation Loss:  0.78289217\n",
      "Epoch:  1839\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8764099\n",
      "Validation Loss:  0.78298396\n",
      "Epoch:  1840\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8739966\n",
      "Validation Loss:  0.78260416\n",
      "Epoch:  1841\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8654847\n",
      "Validation Loss:  0.78320754\n",
      "Epoch:  1842\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8662009\n",
      "Validation Loss:  0.78273314\n",
      "Epoch:  1843\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86796564\n",
      "Validation Loss:  0.7826559\n",
      "Epoch:  1844\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8719788\n",
      "Validation Loss:  0.7828699\n",
      "Epoch:  1845\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86524546\n",
      "Validation Loss:  0.78325856\n",
      "Epoch:  1846\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86684793\n",
      "Validation Loss:  0.7828983\n",
      "Epoch:  1847\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8651531\n",
      "Validation Loss:  0.78264105\n",
      "Epoch:  1848\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8673072\n",
      "Validation Loss:  0.7827634\n",
      "Epoch:  1849\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86541545\n",
      "Validation Loss:  0.7826742\n",
      "Epoch:  1850\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8648593\n",
      "Validation Loss:  0.78284615\n",
      "Epoch:  1851\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.868455\n",
      "Validation Loss:  0.7826901\n",
      "Epoch:  1852\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86553395\n",
      "Validation Loss:  0.7826341\n",
      "Epoch:  1853\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87259954\n",
      "Validation Loss:  0.78270656\n",
      "Epoch:  1854\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.868564\n",
      "Validation Loss:  0.78277797\n",
      "Epoch:  1855\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8647868\n",
      "Validation Loss:  0.7829872\n",
      "Epoch:  1856\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8769437\n",
      "Validation Loss:  0.78276473\n",
      "Epoch:  1857\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8753036\n",
      "Validation Loss:  0.7825151\n",
      "Epoch:  1858\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.867941\n",
      "Validation Loss:  0.78356504\n",
      "Epoch:  1859\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8652132\n",
      "Validation Loss:  0.7829176\n",
      "Epoch:  1860\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8684564\n",
      "Validation Loss:  0.7829384\n",
      "Epoch:  1861\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8648317\n",
      "Validation Loss:  0.7830097\n",
      "Epoch:  1862\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8663618\n",
      "Validation Loss:  0.7827524\n",
      "Epoch:  1863\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86697024\n",
      "Validation Loss:  0.7830642\n",
      "Epoch:  1864\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8667056\n",
      "Validation Loss:  0.7830429\n",
      "Epoch:  1865\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86579245\n",
      "Validation Loss:  0.7827562\n",
      "Epoch:  1866\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8701731\n",
      "Validation Loss:  0.7854171\n",
      "Epoch:  1867\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8651414\n",
      "Validation Loss:  0.7849456\n",
      "Epoch:  1868\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8663025\n",
      "Validation Loss:  0.78272927\n",
      "Epoch:  1869\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87266207\n",
      "Validation Loss:  0.78292227\n",
      "Epoch:  1870\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86621743\n",
      "Validation Loss:  0.7825486\n",
      "Epoch:  1871\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.86714673\n",
      "Validation Loss:  0.78264433\n",
      "Epoch:  1872\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8668815\n",
      "Validation Loss:  0.78269994\n",
      "Epoch:  1873\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8661448\n",
      "Validation Loss:  0.7854204\n",
      "Epoch:  1874\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8654839\n",
      "Validation Loss:  0.7826325\n",
      "Epoch:  1875\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86781055\n",
      "Validation Loss:  0.7826742\n",
      "Epoch:  1876\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86891294\n",
      "Validation Loss:  0.7826675\n",
      "Epoch:  1877\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8673787\n",
      "Validation Loss:  0.7833243\n",
      "Epoch:  1878\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86576676\n",
      "Validation Loss:  0.7827752\n",
      "Epoch:  1879\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86748034\n",
      "Validation Loss:  0.78296566\n",
      "Epoch:  1880\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8661328\n",
      "Validation Loss:  0.78472656\n",
      "Epoch:  1881\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8667496\n",
      "Validation Loss:  0.7828058\n",
      "Epoch:  1882\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86724526\n",
      "Validation Loss:  0.7831129\n",
      "Epoch:  1883\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86701757\n",
      "Validation Loss:  0.78290087\n",
      "Epoch:  1884\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8663305\n",
      "Validation Loss:  0.7825947\n",
      "Epoch:  1885\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8654949\n",
      "Validation Loss:  0.7847113\n",
      "Epoch:  1886\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8658575\n",
      "Validation Loss:  0.7825614\n",
      "Epoch:  1887\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8693426\n",
      "Validation Loss:  0.7825077\n",
      "Epoch:  1888\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8674388\n",
      "Validation Loss:  0.78284127\n",
      "Epoch:  1889\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8658722\n",
      "Validation Loss:  0.7825254\n",
      "Epoch:  1890\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86996496\n",
      "Validation Loss:  0.7825573\n",
      "Epoch:  1891\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8649171\n",
      "Validation Loss:  0.7826662\n",
      "Epoch:  1892\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8663515\n",
      "Validation Loss:  0.7824113\n",
      "Epoch:  1893\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8645082\n",
      "Validation Loss:  0.7828966\n",
      "Epoch:  1894\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8667187\n",
      "Validation Loss:  0.7830718\n",
      "Epoch:  1895\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8695506\n",
      "Validation Loss:  0.7825227\n",
      "Epoch:  1896\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86746895\n",
      "Validation Loss:  0.7826647\n",
      "Epoch:  1897\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86462134\n",
      "Validation Loss:  0.782565\n",
      "Epoch:  1898\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8648604\n",
      "Validation Loss:  0.7827997\n",
      "Epoch:  1899\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.869108\n",
      "Validation Loss:  0.7829404\n",
      "Epoch:  1900\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86650854\n",
      "Validation Loss:  0.78279394\n",
      "Epoch:  1901\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8644087\n",
      "Validation Loss:  0.7826638\n",
      "Epoch:  1902\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8725393\n",
      "Validation Loss:  0.78272307\n",
      "Epoch:  1903\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86754644\n",
      "Validation Loss:  0.783089\n",
      "Epoch:  1904\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86504096\n",
      "Validation Loss:  0.78263825\n",
      "Epoch:  1905\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86843693\n",
      "Validation Loss:  0.7825791\n",
      "Epoch:  1906\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8648618\n",
      "Validation Loss:  0.78284365\n",
      "Epoch:  1907\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8658281\n",
      "Validation Loss:  0.7825428\n",
      "Epoch:  1908\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8687246\n",
      "Validation Loss:  0.78251964\n",
      "Epoch:  1909\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86885744\n",
      "Validation Loss:  0.78262204\n",
      "Epoch:  1910\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8646583\n",
      "Validation Loss:  0.7827898\n",
      "Epoch:  1911\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8727498\n",
      "Validation Loss:  0.78343546\n",
      "Epoch:  1912\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86402816\n",
      "Validation Loss:  0.90924305\n",
      "Epoch:  1913\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86458373\n",
      "Validation Loss:  0.7825035\n",
      "Epoch:  1914\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8645521\n",
      "Validation Loss:  0.7827249\n",
      "Epoch:  1915\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8649974\n",
      "Validation Loss:  0.7828388\n",
      "Epoch:  1916\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86664987\n",
      "Validation Loss:  0.7824451\n",
      "Epoch:  1917\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8729506\n",
      "Validation Loss:  0.78251207\n",
      "Epoch:  1918\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86633044\n",
      "Validation Loss:  0.78265923\n",
      "Epoch:  1919\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86540794\n",
      "Validation Loss:  0.7824014\n",
      "Epoch:  1920\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8648603\n",
      "Validation Loss:  0.78242165\n",
      "Epoch:  1921\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8642534\n",
      "Validation Loss:  0.78247887\n",
      "Epoch:  1922\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86420053\n",
      "Validation Loss:  0.78313315\n",
      "Epoch:  1923\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86867815\n",
      "Validation Loss:  0.7831314\n",
      "Epoch:  1924\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86691654\n",
      "Validation Loss:  0.782353\n",
      "Epoch:  1925\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86572963\n",
      "Validation Loss:  0.783459\n",
      "Epoch:  1926\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8644566\n",
      "Validation Loss:  0.78246933\n",
      "Epoch:  1927\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8647118\n",
      "Validation Loss:  0.7824029\n",
      "Epoch:  1928\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8674206\n",
      "Validation Loss:  0.7826409\n",
      "Epoch:  1929\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86724305\n",
      "Validation Loss:  0.7824451\n",
      "Epoch:  1930\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86417747\n",
      "Validation Loss:  0.78251874\n",
      "Epoch:  1931\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86402714\n",
      "Validation Loss:  0.7824806\n",
      "Epoch:  1932\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8651667\n",
      "Validation Loss:  0.7833372\n",
      "Epoch:  1933\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8754567\n",
      "Validation Loss:  0.78247654\n",
      "Epoch:  1934\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8681016\n",
      "Validation Loss:  0.78246516\n",
      "Epoch:  1935\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8751083\n",
      "Validation Loss:  0.7828087\n",
      "Epoch:  1936\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8668349\n",
      "Validation Loss:  0.7826639\n",
      "Epoch:  1937\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.864912\n",
      "Validation Loss:  0.7828059\n",
      "Epoch:  1938\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86814696\n",
      "Validation Loss:  0.7826263\n",
      "Epoch:  1939\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86577016\n",
      "Validation Loss:  0.7828883\n",
      "Epoch:  1940\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86442983\n",
      "Validation Loss:  0.7824459\n",
      "Epoch:  1941\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86389107\n",
      "Validation Loss:  0.7823972\n",
      "Epoch:  1942\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86458147\n",
      "Validation Loss:  0.7826949\n",
      "Epoch:  1943\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86457783\n",
      "Validation Loss:  0.78257245\n",
      "Epoch:  1944\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86681104\n",
      "Validation Loss:  0.78248155\n",
      "Epoch:  1945\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87501293\n",
      "Validation Loss:  0.78263474\n",
      "Epoch:  1946\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86400276\n",
      "Validation Loss:  0.7827903\n",
      "Epoch:  1947\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.87076277\n",
      "Validation Loss:  0.7827423\n",
      "Epoch:  1948\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8665798\n",
      "Validation Loss:  0.7823028\n",
      "Epoch:  1949\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86755496\n",
      "Validation Loss:  0.78259754\n",
      "Epoch:  1950\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86587447\n",
      "Validation Loss:  0.78224903\n",
      "Epoch:  1951\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8680678\n",
      "Validation Loss:  0.7824965\n",
      "Epoch:  1952\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8642395\n",
      "Validation Loss:  0.782433\n",
      "Epoch:  1953\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87849706\n",
      "Validation Loss:  0.78461844\n",
      "Epoch:  1954\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86502033\n",
      "Validation Loss:  0.78269833\n",
      "Epoch:  1955\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86454284\n",
      "Validation Loss:  0.782679\n",
      "Epoch:  1956\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8759027\n",
      "Validation Loss:  0.7825012\n",
      "Epoch:  1957\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8654099\n",
      "Validation Loss:  0.7823528\n",
      "Epoch:  1958\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8636944\n",
      "Validation Loss:  0.7824203\n",
      "Epoch:  1959\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8659148\n",
      "Validation Loss:  0.78249806\n",
      "Epoch:  1960\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9899497487437185\n",
      "Training Loss:  0.8664258\n",
      "Validation Loss:  0.78245556\n",
      "Epoch:  1961\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86409783\n",
      "Validation Loss:  0.78251535\n",
      "Epoch:  1962\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8653217\n",
      "Validation Loss:  0.7826872\n",
      "Epoch:  1963\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.865979\n",
      "Validation Loss:  0.78265935\n",
      "Epoch:  1964\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.864113\n",
      "Validation Loss:  0.78258514\n",
      "Epoch:  1965\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8639068\n",
      "Validation Loss:  0.782228\n",
      "Epoch:  1966\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86412895\n",
      "Validation Loss:  0.7823647\n",
      "Epoch:  1967\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86840814\n",
      "Validation Loss:  0.78257114\n",
      "Epoch:  1968\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86525834\n",
      "Validation Loss:  0.7822878\n",
      "Epoch:  1969\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86601216\n",
      "Validation Loss:  0.7824573\n",
      "Epoch:  1970\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86477304\n",
      "Validation Loss:  0.7832907\n",
      "Epoch:  1971\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8654643\n",
      "Validation Loss:  0.7825707\n",
      "Epoch:  1972\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86615556\n",
      "Validation Loss:  0.7823356\n",
      "Epoch:  1973\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86403584\n",
      "Validation Loss:  0.7841908\n",
      "Epoch:  1974\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86539257\n",
      "Validation Loss:  0.9090282\n",
      "Epoch:  1975\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87055004\n",
      "Validation Loss:  0.7824431\n",
      "Epoch:  1976\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86380005\n",
      "Validation Loss:  0.7828147\n",
      "Epoch:  1977\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86631835\n",
      "Validation Loss:  0.78230244\n",
      "Epoch:  1978\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8651662\n",
      "Validation Loss:  0.7825851\n",
      "Epoch:  1979\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.87064195\n",
      "Validation Loss:  0.78304875\n",
      "Epoch:  1980\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8699328\n",
      "Validation Loss:  0.7829687\n",
      "Epoch:  1981\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8632495\n",
      "Validation Loss:  0.7821266\n",
      "Epoch:  1982\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.865673\n",
      "Validation Loss:  0.78240633\n",
      "Epoch:  1983\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86529815\n",
      "Validation Loss:  0.7822524\n",
      "Epoch:  1984\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8656678\n",
      "Validation Loss:  0.78233147\n",
      "Epoch:  1985\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8637977\n",
      "Validation Loss:  0.7825985\n",
      "Epoch:  1986\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86702496\n",
      "Validation Loss:  0.7828065\n",
      "Epoch:  1987\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86377096\n",
      "Validation Loss:  0.78227603\n",
      "Epoch:  1988\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8655704\n",
      "Validation Loss:  0.78227466\n",
      "Epoch:  1989\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86556554\n",
      "Validation Loss:  0.7823147\n",
      "Epoch:  1990\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8650055\n",
      "Validation Loss:  0.7826435\n",
      "Epoch:  1991\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8676934\n",
      "Validation Loss:  0.7823679\n",
      "Epoch:  1992\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86562425\n",
      "Validation Loss:  0.7822834\n",
      "Epoch:  1993\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86962885\n",
      "Validation Loss:  0.7829933\n",
      "Epoch:  1994\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.86420894\n",
      "Validation Loss:  0.7823392\n",
      "Epoch:  1995\n",
      "Training Accuracy:  0.9924242424242424\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8637623\n",
      "Validation Loss:  0.7825073\n",
      "Epoch:  1996\n",
      "Training Accuracy:  0.9913419913419913\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8634727\n",
      "Validation Loss:  0.7822134\n",
      "Epoch:  1997\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8635373\n",
      "Validation Loss:  0.90941554\n",
      "Epoch:  1998\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8632101\n",
      "Validation Loss:  0.78319293\n",
      "Epoch:  1999\n",
      "Training Accuracy:  0.9935064935064936\n",
      "Validation Accuracy:  0.9949748743718593\n",
      "Training Loss:  0.8632422\n",
      "Validation Loss:  0.78252\n"
     ]
    }
   ],
   "source": [
    "# Now let's do the training!\n",
    "\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "mymodel = myMultiLayerPerceptron(77,4) # creating a model instance with input dimension 1\n",
    "\n",
    "best_model = mymodel\n",
    "max_val_acc = 0\n",
    "\n",
    "# Three hyper parameters for training\n",
    "lr = 0.00001\n",
    "batch_size = 32\n",
    "N_epochs = 2000\n",
    "\n",
    "# Create dataloaders for training and validation\n",
    "train_dataloader = DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
    "validate_dataloader = DataLoader(validate_set,batch_size = batch_size,shuffle = True)\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.Adam(mymodel.parameters(), lr = lr) # this line creates a optimizer, and we tell optimizer we are optimizing the parameters in mymodel\n",
    "\n",
    "training_losses = [] # training losses of each epoch\n",
    "validate_losses = [] # validation losses of each epoch\n",
    "training_losses_all = [] # training losses of each SGD iteration\n",
    "train_acc_list = [] # training accuracy of each epoch\n",
    "val_acc_list = [] # validation accuracy of each epoch\n",
    "\n",
    "# set class weights\n",
    "class_weights = torch.tensor([1, 5, 15, 15], dtype=torch.float32)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "\n",
    "gd_steps = 0\n",
    "N_batches = len(train_dataloader)\n",
    "\n",
    "for epoch in range(N_epochs):\n",
    "    print(\"Epoch: \", epoch)\n",
    "    batch_loss = []\n",
    "    train_acc = []\n",
    "    for batch_id, (x_batch, y_batch) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # pass input data to get the prediction outputs by the current model\n",
    "        prediction = mymodel(x_batch)\n",
    "\n",
    "        # compare prediction and the actual output and compute the loss\n",
    "        loss = criterion(prediction, y_batch)\n",
    "        batch_loss.append(loss.detach().numpy())\n",
    "        training_losses_all.append(loss.detach().numpy())\n",
    "        \n",
    "        # compute the gradient\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "    # calculate the training accuracy\n",
    "    pred = mymodel(x_train)\n",
    "    pred = pred.detach().numpy()\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    acc = np.mean(pred == np.argmax(y_train.numpy(), axis=1))\n",
    "    train_acc_list.append(acc)\n",
    "    print(\"Training Accuracy: \", acc)\n",
    "\n",
    "    # Calculate Validation Loss\n",
    "    validate_batch_loss = []\n",
    "    validate_acc = []\n",
    "    for batch_id, (x_batch, y_batch) in enumerate(validate_dataloader):\n",
    "        # pass input data to get the prediction outputs by the current model\n",
    "        prediction = mymodel(x_batch)\n",
    "        # compare prediction and the actual output and compute the loss\n",
    "        loss = criterion(prediction, y_batch)\n",
    "        validate_batch_loss.append(loss.detach().numpy())\n",
    "        \n",
    "\n",
    "        pred = mymodel(x_batch)\n",
    "        pred = pred.detach().numpy()\n",
    "        pred = np.argmax(pred, axis=1)\n",
    "    ## Calculate the validation accuracy\n",
    "    pred = mymodel(x_validate)\n",
    "    pred = pred.detach().numpy()\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    acc = np.mean(pred == np.argmax(y_validate.numpy(), axis=1))\n",
    "    val_acc_list.append(acc)\n",
    "    print(\"Validation Accuracy: \", acc)\n",
    "\n",
    "\n",
    "    cur_val_loss=np.mean(np.array(validate_batch_loss))\n",
    "    cur_epoch_loss = np.mean(np.array(batch_loss))\n",
    "\n",
    "    validate_losses.append(cur_val_loss)\n",
    "    training_losses.append(cur_epoch_loss)\n",
    "\n",
    "    print(\"Training Loss: \", cur_epoch_loss)\n",
    "    print(\"Validation Loss: \", cur_val_loss)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))  \n",
    "plt.plot(training_losses_all)  \n",
    "\n",
    "plt.title('train loss per SGD iteration')\n",
    "plt.xlabel('batch iteration')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))  \n",
    "plt.plot(training_losses)  \n",
    "plt.plot(validate_losses)\n",
    "plt.title('train and validate loss across different epochs')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE loss')\n",
    "plt.legend(['train loss', 'validate loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "60e129e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_acc_list)\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7a616bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(val_acc_list)\n",
    "plt.title('Validation Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ae4225b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy:  0.9762845849802372\n"
     ]
    }
   ],
   "source": [
    "## calculate baseline test accuracy\n",
    "baseline_accuracy = np.mean(np.argmax(y_test.numpy(), axis=1) == 0)\n",
    "print(\"Baseline accuracy: \", baseline_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f00425f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9993, 0.0047, 0.0035, 0.0047],\n",
      "        [0.9974, 0.0074, 0.0117, 0.0094],\n",
      "        [0.9969, 0.0072, 0.0146, 0.0082],\n",
      "        ...,\n",
      "        [0.9960, 0.0070, 0.0156, 0.0227],\n",
      "        [0.9993, 0.0048, 0.0037, 0.0049],\n",
      "        [0.0757, 0.1115, 0.9782, 0.1262]], grad_fn=<SigmoidBackward0>)\n",
      "Test Accuracy:  0.9841897233201581\n"
     ]
    }
   ],
   "source": [
    "## calculate test accuracy\n",
    "pred = mymodel(x_test)\n",
    "print(pred)\n",
    "pred = pred.detach().numpy()\n",
    "pred = np.argmax(pred, axis=1)\n",
    "acc = np.mean(pred == np.argmax(y_test.numpy(), axis=1))\n",
    "print(\"Test Accuracy: \", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6c9eda09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class accuracy:  [1.0, 0.0, 1.0, 0.5]\n"
     ]
    }
   ],
   "source": [
    "## calculate accuracy for each class\n",
    "class_acc = []\n",
    "for i in range(4):\n",
    "    class_acc.append(np.mean(pred[np.argmax(y_test.numpy(), axis=1) == i] == i))\n",
    "print(\"Class accuracy: \", class_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toolchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
