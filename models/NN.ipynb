{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b69cff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.ml import Pipeline,Transformer\n",
    "from pyspark.ml.feature import Imputer,StandardScaler,StringIndexer,OneHotEncoder, VectorAssembler\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb917af8",
   "metadata": {},
   "source": [
    "## Create a pipeline for data engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "580aca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"src_ip\",\"dst_ip\",\n",
    "\"src_port\",\"dst_port\",\"protocol\",\n",
    "\"timestamp\",\"flow_duration\",\n",
    "\"flow_byts_s\",\"flow_pkts_s\",\n",
    "\"fwd_pkts_s\",\"bwd_pkts_s\",\n",
    "\"tot_fwd_pkts\",\"tot_bwd_pkts\",\n",
    "\"totlen_fwd_pkts\",\"totlen_bwd_pkts\",\n",
    "\"fwd_pkt_len_max\",\"fwd_pkt_len_min\",\n",
    "\"fwd_pkt_len_mean\",\"fwd_pkt_len_std\",\n",
    "\"bwd_pkt_len_max\",\"bwd_pkt_len_min\",\n",
    "\"bwd_pkt_len_mean\",\"bwd_pkt_len_std\",\n",
    "\"pkt_len_max\",\"pkt_len_min\",\n",
    "\"pkt_len_mean\",\"pkt_len_std\",\n",
    "\"pkt_len_var\",\"fwd_header_len\",\n",
    "\"bwd_header_len\",\"fwd_seg_size_min\",\n",
    "\"fwd_act_data_pkts\",\"flow_iat_mean\",\n",
    "\"flow_iat_max\",\"flow_iat_min\",\n",
    "\"flow_iat_std\",\"fwd_iat_tot\",\n",
    "\"fwd_iat_max\",\"fwd_iat_min\",\n",
    "\"fwd_iat_mean\",\"fwd_iat_std\",\n",
    "\"bwd_iat_tot\",\"bwd_iat_max\",\n",
    "\"bwd_iat_min\",\"bwd_iat_mean\",\n",
    "\"bwd_iat_std\",\"fwd_psh_flags\",\n",
    "\"bwd_psh_flags\",\"fwd_urg_flags\",\n",
    "\"bwd_urg_flags\",\"fin_flag_cnt\",\n",
    "\"syn_flag_cnt\",\"rst_flag_cnt\",\n",
    "\"psh_flag_cnt\",\"ack_flag_cnt\",\n",
    "\"urg_flag_cnt\",\"ece_flag_cnt\",\n",
    "\"down_up_ratio\",\"pkt_size_avg\",\n",
    "\"init_fwd_win_byts\",\"init_bwd_win_byts\",\n",
    "\"active_max\",\"active_min\",\n",
    "\"active_mean\",\"active_std\",\n",
    "\"idle_max\",\"idle_min\",\n",
    "\"idle_mean\",\"idle_std\",\n",
    "\"fwd_byts_b_avg\",\"fwd_pkts_b_avg\",\n",
    "\"bwd_byts_b_avg\",\"bwd_pkts_b_avg\",\n",
    "\"fwd_blk_rate_avg\",\"bwd_blk_rate_avg\",\n",
    "\"fwd_seg_size_avg\",\"bwd_seg_size_avg\",\n",
    "\"cwr_flag_count\",\"subflow_fwd_pkts\",\n",
    "\"subflow_bwd_pkts\",\"subflow_fwd_byts\",\n",
    "\"subflow_bwd_byts\"]\n",
    "\n",
    "\n",
    "feature_cols = [\"protocol\",\"flow_duration\",\n",
    "\"flow_byts_s\",\"flow_pkts_s\",\n",
    "\"fwd_pkts_s\",\"bwd_pkts_s\",\n",
    "\"tot_fwd_pkts\",\"tot_bwd_pkts\",\n",
    "\"totlen_fwd_pkts\",\"totlen_bwd_pkts\",\n",
    "\"fwd_pkt_len_max\",\"fwd_pkt_len_min\",\n",
    "\"fwd_pkt_len_mean\",\"fwd_pkt_len_std\",\n",
    "\"bwd_pkt_len_max\",\"bwd_pkt_len_min\",\n",
    "\"bwd_pkt_len_mean\",\"bwd_pkt_len_std\",\n",
    "\"pkt_len_max\",\"pkt_len_min\",\n",
    "\"pkt_len_mean\",\"pkt_len_std\",\n",
    "\"pkt_len_var\",\"fwd_header_len\",\n",
    "\"bwd_header_len\",\"fwd_seg_size_min\",\n",
    "\"fwd_act_data_pkts\",\"flow_iat_mean\",\n",
    "\"flow_iat_max\",\"flow_iat_min\",\n",
    "\"flow_iat_std\",\"fwd_iat_tot\",\n",
    "\"fwd_iat_max\",\"fwd_iat_min\",\n",
    "\"fwd_iat_mean\",\"fwd_iat_std\",\n",
    "\"bwd_iat_tot\",\"bwd_iat_max\",\n",
    "\"bwd_iat_min\",\"bwd_iat_mean\",\n",
    "\"bwd_iat_std\",\"fwd_psh_flags\",\n",
    "\"bwd_psh_flags\",\"fwd_urg_flags\",\n",
    "\"bwd_urg_flags\",\"fin_flag_cnt\",\n",
    "\"syn_flag_cnt\",\"rst_flag_cnt\",\n",
    "\"psh_flag_cnt\",\"ack_flag_cnt\",\n",
    "\"urg_flag_cnt\",\"ece_flag_cnt\",\n",
    "\"down_up_ratio\",\"pkt_size_avg\",\n",
    "\"init_fwd_win_byts\",\"init_bwd_win_byts\",\n",
    "\"active_max\",\"active_min\",\n",
    "\"active_mean\",\"active_std\",\n",
    "\"idle_max\",\"idle_min\",\n",
    "\"idle_mean\",\"idle_std\",\n",
    "\"fwd_byts_b_avg\",\"fwd_pkts_b_avg\",\n",
    "\"bwd_byts_b_avg\",\"bwd_pkts_b_avg\",\n",
    "\"fwd_blk_rate_avg\",\"bwd_blk_rate_avg\",\n",
    "\"fwd_seg_size_avg\",\"bwd_seg_size_avg\",\n",
    "\"cwr_flag_count\",\"subflow_fwd_pkts\",\n",
    "\"subflow_bwd_pkts\",\"subflow_fwd_byts\",\n",
    "\"subflow_bwd_byts\"]\n",
    "\n",
    "c2_ip = [\"24.144.84.186\", \"146.190.174.24\", \"64.23.181.184\"]\n",
    "\n",
    "drop_cols = [\"timestamp\", \"src_ip\", \"dst_ip\", \"src_port\", \"dst_port\"]\n",
    "\n",
    "class OutcomeCreater(Transformer): # this defines a transformer that creates the outcome column\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        # Create a new column 'outcome' that is 1 if the destination IP or source IP is in c2_ip, 0 otherwise\n",
    "\n",
    "        output_df = dataset.withColumn(\"outcome\", when((col(\"dst_ip\").isin(c2_ip)) | (col(\"src_ip\").isin(c2_ip)),1).otherwise(0))\n",
    "\n",
    "        return output_df\n",
    "\n",
    "class FeatureTypeCaster(Transformer): # this transformer will cast the columns as appropriate types  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        output_df = dataset\n",
    "        for col_name in feature_cols:\n",
    "            output_df = output_df.withColumn(col_name,col(col_name).cast(DoubleType()))\n",
    "\n",
    "        return output_df\n",
    "\n",
    "class ColumnDropper(Transformer): # this transformer drops unnecessary columns\n",
    "    def __init__(self, columns_to_drop = None):\n",
    "        super().__init__()\n",
    "        self.columns_to_drop=columns_to_drop\n",
    "    def _transform(self, dataset):\n",
    "        output_df = dataset\n",
    "        for col_name in self.columns_to_drop:\n",
    "            output_df = output_df.drop(col_name)\n",
    "        return output_df\n",
    "\n",
    "def get_preprocess_pipeline():\n",
    "    # Stage where columns are casted as appropriate types\n",
    "    stage_typecaster = FeatureTypeCaster()\n",
    "\n",
    "    # Stage where all relevant features are assembled into a vector (and dropping a few)\n",
    "    stage_vector_assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"vectorized_features\")\n",
    "\n",
    "    # Stage where we scale the columns\n",
    "    stage_scaler = StandardScaler(inputCol= 'vectorized_features', outputCol= 'features')\n",
    "    \n",
    "    # Stage for creating the outcome column representing whether there is attack \n",
    "    stage_outcome = OutcomeCreater()\n",
    "\n",
    "    # Removing all unnecessary columbs, only keeping the 'features' and 'outcome' columns\n",
    "    stage_column_dropper = ColumnDropper(columns_to_drop = feature_cols + ['vectorized_features'] + drop_cols)\n",
    "\n",
    "    # Connect the columns into a pipeline\n",
    "    pipeline = Pipeline(stages=[stage_typecaster, stage_vector_assembler,stage_scaler,stage_outcome,stage_column_dropper])\n",
    "    return pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb46588",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "74c83a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "# os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "# os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"SystemsToolChains\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "c2_data_raw = spark.read.csv('metasploit.csv',header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9f2a6e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- src_ip: string (nullable = true)\n",
      " |-- dst_ip: string (nullable = true)\n",
      " |-- src_port: string (nullable = true)\n",
      " |-- dst_port: string (nullable = true)\n",
      " |-- protocol: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- flow_duration: string (nullable = true)\n",
      " |-- flow_byts_s: string (nullable = true)\n",
      " |-- flow_pkts_s: string (nullable = true)\n",
      " |-- fwd_pkts_s: string (nullable = true)\n",
      " |-- bwd_pkts_s: string (nullable = true)\n",
      " |-- tot_fwd_pkts: string (nullable = true)\n",
      " |-- tot_bwd_pkts: string (nullable = true)\n",
      " |-- totlen_fwd_pkts: string (nullable = true)\n",
      " |-- totlen_bwd_pkts: string (nullable = true)\n",
      " |-- fwd_pkt_len_max: string (nullable = true)\n",
      " |-- fwd_pkt_len_min: string (nullable = true)\n",
      " |-- fwd_pkt_len_mean: string (nullable = true)\n",
      " |-- fwd_pkt_len_std: string (nullable = true)\n",
      " |-- bwd_pkt_len_max: string (nullable = true)\n",
      " |-- bwd_pkt_len_min: string (nullable = true)\n",
      " |-- bwd_pkt_len_mean: string (nullable = true)\n",
      " |-- bwd_pkt_len_std: string (nullable = true)\n",
      " |-- pkt_len_max: string (nullable = true)\n",
      " |-- pkt_len_min: string (nullable = true)\n",
      " |-- pkt_len_mean: string (nullable = true)\n",
      " |-- pkt_len_std: string (nullable = true)\n",
      " |-- pkt_len_var: string (nullable = true)\n",
      " |-- fwd_header_len: string (nullable = true)\n",
      " |-- bwd_header_len: string (nullable = true)\n",
      " |-- fwd_seg_size_min: string (nullable = true)\n",
      " |-- fwd_act_data_pkts: string (nullable = true)\n",
      " |-- flow_iat_mean: string (nullable = true)\n",
      " |-- flow_iat_max: string (nullable = true)\n",
      " |-- flow_iat_min: string (nullable = true)\n",
      " |-- flow_iat_std: string (nullable = true)\n",
      " |-- fwd_iat_tot: string (nullable = true)\n",
      " |-- fwd_iat_max: string (nullable = true)\n",
      " |-- fwd_iat_min: string (nullable = true)\n",
      " |-- fwd_iat_mean: string (nullable = true)\n",
      " |-- fwd_iat_std: string (nullable = true)\n",
      " |-- bwd_iat_tot: string (nullable = true)\n",
      " |-- bwd_iat_max: string (nullable = true)\n",
      " |-- bwd_iat_min: string (nullable = true)\n",
      " |-- bwd_iat_mean: string (nullable = true)\n",
      " |-- bwd_iat_std: string (nullable = true)\n",
      " |-- fwd_psh_flags: string (nullable = true)\n",
      " |-- bwd_psh_flags: string (nullable = true)\n",
      " |-- fwd_urg_flags: string (nullable = true)\n",
      " |-- bwd_urg_flags: string (nullable = true)\n",
      " |-- fin_flag_cnt: string (nullable = true)\n",
      " |-- syn_flag_cnt: string (nullable = true)\n",
      " |-- rst_flag_cnt: string (nullable = true)\n",
      " |-- psh_flag_cnt: string (nullable = true)\n",
      " |-- ack_flag_cnt: string (nullable = true)\n",
      " |-- urg_flag_cnt: string (nullable = true)\n",
      " |-- ece_flag_cnt: string (nullable = true)\n",
      " |-- down_up_ratio: string (nullable = true)\n",
      " |-- pkt_size_avg: string (nullable = true)\n",
      " |-- init_fwd_win_byts: string (nullable = true)\n",
      " |-- init_bwd_win_byts: string (nullable = true)\n",
      " |-- active_max: string (nullable = true)\n",
      " |-- active_min: string (nullable = true)\n",
      " |-- active_mean: string (nullable = true)\n",
      " |-- active_std: string (nullable = true)\n",
      " |-- idle_max: string (nullable = true)\n",
      " |-- idle_min: string (nullable = true)\n",
      " |-- idle_mean: string (nullable = true)\n",
      " |-- idle_std: string (nullable = true)\n",
      " |-- fwd_byts_b_avg: string (nullable = true)\n",
      " |-- fwd_pkts_b_avg: string (nullable = true)\n",
      " |-- bwd_byts_b_avg: string (nullable = true)\n",
      " |-- bwd_pkts_b_avg: string (nullable = true)\n",
      " |-- fwd_blk_rate_avg: string (nullable = true)\n",
      " |-- bwd_blk_rate_avg: string (nullable = true)\n",
      " |-- fwd_seg_size_avg: string (nullable = true)\n",
      " |-- bwd_seg_size_avg: string (nullable = true)\n",
      " |-- cwr_flag_count: string (nullable = true)\n",
      " |-- subflow_fwd_pkts: string (nullable = true)\n",
      " |-- subflow_bwd_pkts: string (nullable = true)\n",
      " |-- subflow_fwd_byts: string (nullable = true)\n",
      " |-- subflow_bwd_byts: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c2_data_raw.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b604d5f",
   "metadata": {},
   "source": [
    "## Drop some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e6d703cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_pipeline = get_preprocess_pipeline()\n",
    "preprocess_pipeline_model = preprocess_pipeline.fit(c2_data_raw)\n",
    "c2_data = preprocess_pipeline_model.transform(c2_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bc4a9e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|            features|outcome|\n",
      "+--------------------+-------+\n",
      "|(77,[0,1,2,3,4,6,...|      0|\n",
      "|(77,[0,1,2,3,4,6,...|      0|\n",
      "|(77,[0,1,2,3,4,6,...|      0|\n",
      "|(77,[0,1,2,3,4,6,...|      0|\n",
      "|(77,[0,1,2,3,4,6,...|      0|\n",
      "|[1.16303595213837...|      1|\n",
      "|[1.16303595213837...|      1|\n",
      "|(77,[0,1,2,3,4,5,...|      0|\n",
      "|(77,[0,1,2,3,4,5,...|      0|\n",
      "|(77,[0,6,8,10,11,...|      0|\n",
      "|(77,[0,6,8,10,11,...|      0|\n",
      "|(77,[0,6,8,10,11,...|      0|\n",
      "|(77,[0,1,2,3,4,5,...|      0|\n",
      "|(77,[0,6,8,10,11,...|      0|\n",
      "|(77,[0,6,8,10,11,...|      0|\n",
      "|(77,[0,6,8,10,11,...|      0|\n",
      "|[1.16303595213837...|      0|\n",
      "|[1.16303595213837...|      0|\n",
      "|(77,[0,1,2,3,4,6,...|      0|\n",
      "|(77,[0,1,2,3,4,6,...|      0|\n",
      "|(77,[0,1,2,3,4,6,...|      0|\n",
      "|[1.16303595213837...|      1|\n",
      "|(77,[0,1,2,3,4,6,...|      0|\n",
      "|[1.16303595213837...|      1|\n",
      "|[1.16303595213837...|      0|\n",
      "|(77,[0,1,2,3,4,5,...|      0|\n",
      "|[1.16303595213837...|      0|\n",
      "|[1.16303595213837...|      0|\n",
      "|(77,[0,1,2,3,4,5,...|      0|\n",
      "|[1.16303595213837...|      0|\n",
      "+--------------------+-------+\n",
      "only showing top 30 rows\n",
      "\n",
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- outcome: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c2_data.show(30)\n",
    "c2_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b33dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data into training, validation, and test sets\n",
    "train, test = c2_data.randomSplit([0.8, 0.2], seed=12345)\n",
    "train, validation = train.randomSplit([0.8, 0.2], seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_train_pandas = train.toPandas()\n",
    "c2_test_pandas = test.toPandas()\n",
    "c2f_validate_pandas = validation.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class MyDataset(Dataset): \n",
    "    def __init__(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.x[idx],self.y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(np.array(c2_train_pandas['features'].values.tolist(), np.float32))\n",
    "y_train = torch.from_numpy(np.array(c2_train_pandas['outcome'].values.tolist(), np.float32)).unsqueeze(1)\n",
    "\n",
    "x_validate = torch.from_numpy(np.array(c2f_validate_pandas['features'].values.tolist(), np.float32))\n",
    "y_validate = torch.from_numpy(np.array(c2f_validate_pandas['outcome'].values.tolist(), np.float32)).unsqueeze(1)\n",
    "\n",
    "x_test = torch.from_numpy(np.array(c2_test_pandas['features'].values.tolist(), np.float32))\n",
    "y_test = torch.from_numpy(np.array(c2_test_pandas['outcome'].values.tolist(), np.float32)).unsqueeze(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([736, 1])\n",
      "torch.Size([173, 1])\n",
      "torch.Size([195, 1])\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_validate.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([736, 77])\n",
      "torch.Size([173, 77])\n",
      "torch.Size([195, 77])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_validate.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MyDataset(x_train,y_train)\n",
    "validate_set = MyDataset(x_validate,y_validate)\n",
    "test_set = MyDataset(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myMultiLayerPerceptron(\n",
      "  (sequential): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=77, out_features=50, bias=True)\n",
      "    (2): Tanh()\n",
      "    (3): Linear(in_features=50, out_features=20, bias=True)\n",
      "    (4): Tanh()\n",
      "    (5): Linear(in_features=20, out_features=1, bias=True)\n",
      "    (6): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Example: using Sequential in Pytorch\n",
    "\n",
    "class myMultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super().__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(input_dim,50),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50,20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20,output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        y = self.sequential(x)\n",
    "        return y\n",
    "    \n",
    "model1 = myMultiLayerPerceptron(77,1)\n",
    "print(model1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Training Loss:  0.2795223\n",
      "Validation Loss:  0.27644697\n",
      "Epoch:  1\n",
      "Training Loss:  0.27826986\n",
      "Validation Loss:  0.27649724\n",
      "Epoch:  2\n",
      "Training Loss:  0.27683568\n",
      "Validation Loss:  0.27062663\n",
      "Epoch:  3\n",
      "Training Loss:  0.2779314\n",
      "Validation Loss:  0.27182707\n",
      "Epoch:  4\n",
      "Training Loss:  0.27714777\n",
      "Validation Loss:  0.27185014\n",
      "Epoch:  5\n",
      "Training Loss:  0.2763184\n",
      "Validation Loss:  0.27629897\n",
      "Epoch:  6\n",
      "Training Loss:  0.27548894\n",
      "Validation Loss:  0.27357137\n",
      "Epoch:  7\n",
      "Training Loss:  0.27672744\n",
      "Validation Loss:  0.27573174\n",
      "Epoch:  8\n",
      "Training Loss:  0.27663344\n",
      "Validation Loss:  0.27402538\n",
      "Epoch:  9\n",
      "Training Loss:  0.2744116\n",
      "Validation Loss:  0.27319393\n",
      "Epoch:  10\n",
      "Training Loss:  0.27390903\n",
      "Validation Loss:  0.27308127\n",
      "Epoch:  11\n",
      "Training Loss:  0.27448502\n",
      "Validation Loss:  0.27119008\n",
      "Epoch:  12\n",
      "Training Loss:  0.27297673\n",
      "Validation Loss:  0.27196136\n",
      "Epoch:  13\n",
      "Training Loss:  0.27323085\n",
      "Validation Loss:  0.2677848\n",
      "Epoch:  14\n",
      "Training Loss:  0.27216044\n",
      "Validation Loss:  0.2674581\n",
      "Epoch:  15\n",
      "Training Loss:  0.27164674\n",
      "Validation Loss:  0.26959324\n",
      "Epoch:  16\n",
      "Training Loss:  0.27023885\n",
      "Validation Loss:  0.27282187\n",
      "Epoch:  17\n",
      "Training Loss:  0.27093747\n",
      "Validation Loss:  0.27135125\n",
      "Epoch:  18\n",
      "Training Loss:  0.27119133\n",
      "Validation Loss:  0.27373025\n",
      "Epoch:  19\n",
      "Training Loss:  0.27179614\n",
      "Validation Loss:  0.27031475\n",
      "Epoch:  20\n",
      "Training Loss:  0.2699023\n",
      "Validation Loss:  0.2659392\n",
      "Epoch:  21\n",
      "Training Loss:  0.26956156\n",
      "Validation Loss:  0.26734084\n",
      "Epoch:  22\n",
      "Training Loss:  0.26944244\n",
      "Validation Loss:  0.26665905\n",
      "Epoch:  23\n",
      "Training Loss:  0.2688617\n",
      "Validation Loss:  0.2670093\n",
      "Epoch:  24\n",
      "Training Loss:  0.26814607\n",
      "Validation Loss:  0.2631929\n",
      "Epoch:  25\n",
      "Training Loss:  0.2671862\n",
      "Validation Loss:  0.26504442\n",
      "Epoch:  26\n",
      "Training Loss:  0.2682836\n",
      "Validation Loss:  0.26516807\n",
      "Epoch:  27\n",
      "Training Loss:  0.26697943\n",
      "Validation Loss:  0.2597536\n",
      "Epoch:  28\n",
      "Training Loss:  0.26637533\n",
      "Validation Loss:  0.2667648\n",
      "Epoch:  29\n",
      "Training Loss:  0.26706427\n",
      "Validation Loss:  0.2651752\n",
      "Epoch:  30\n",
      "Training Loss:  0.26536515\n",
      "Validation Loss:  0.26261723\n",
      "Epoch:  31\n",
      "Training Loss:  0.2656682\n",
      "Validation Loss:  0.26519254\n",
      "Epoch:  32\n",
      "Training Loss:  0.26503214\n",
      "Validation Loss:  0.2640412\n",
      "Epoch:  33\n",
      "Training Loss:  0.26481912\n",
      "Validation Loss:  0.26268283\n",
      "Epoch:  34\n",
      "Training Loss:  0.26368287\n",
      "Validation Loss:  0.26070905\n",
      "Epoch:  35\n",
      "Training Loss:  0.26401463\n",
      "Validation Loss:  0.26270238\n",
      "Epoch:  36\n",
      "Training Loss:  0.26316068\n",
      "Validation Loss:  0.26445967\n",
      "Epoch:  37\n",
      "Training Loss:  0.2624476\n",
      "Validation Loss:  0.25813726\n",
      "Epoch:  38\n",
      "Training Loss:  0.26243448\n",
      "Validation Loss:  0.26139733\n",
      "Epoch:  39\n",
      "Training Loss:  0.26218903\n",
      "Validation Loss:  0.25683486\n",
      "Epoch:  40\n",
      "Training Loss:  0.26284674\n",
      "Validation Loss:  0.25671446\n",
      "Epoch:  41\n",
      "Training Loss:  0.26039684\n",
      "Validation Loss:  0.25774354\n",
      "Epoch:  42\n",
      "Training Loss:  0.26112834\n",
      "Validation Loss:  0.25798392\n",
      "Epoch:  43\n",
      "Training Loss:  0.25950125\n",
      "Validation Loss:  0.25600544\n",
      "Epoch:  44\n",
      "Training Loss:  0.2606575\n",
      "Validation Loss:  0.25502893\n",
      "Epoch:  45\n",
      "Training Loss:  0.2604095\n",
      "Validation Loss:  0.25568372\n",
      "Epoch:  46\n",
      "Training Loss:  0.2589863\n",
      "Validation Loss:  0.25670323\n",
      "Epoch:  47\n",
      "Training Loss:  0.2602963\n",
      "Validation Loss:  0.25357413\n",
      "Epoch:  48\n",
      "Training Loss:  0.25920984\n",
      "Validation Loss:  0.25498927\n",
      "Epoch:  49\n",
      "Training Loss:  0.2576564\n",
      "Validation Loss:  0.25689387\n",
      "Epoch:  50\n",
      "Training Loss:  0.25848144\n",
      "Validation Loss:  0.25444618\n",
      "Epoch:  51\n",
      "Training Loss:  0.25738573\n",
      "Validation Loss:  0.2563747\n",
      "Epoch:  52\n",
      "Training Loss:  0.25774562\n",
      "Validation Loss:  0.25317657\n",
      "Epoch:  53\n",
      "Training Loss:  0.25675103\n",
      "Validation Loss:  0.25548196\n",
      "Epoch:  54\n",
      "Training Loss:  0.25615948\n",
      "Validation Loss:  0.25522217\n",
      "Epoch:  55\n",
      "Training Loss:  0.25540423\n",
      "Validation Loss:  0.252292\n",
      "Epoch:  56\n",
      "Training Loss:  0.2548778\n",
      "Validation Loss:  0.25180566\n",
      "Epoch:  57\n",
      "Training Loss:  0.25492427\n",
      "Validation Loss:  0.25324598\n",
      "Epoch:  58\n",
      "Training Loss:  0.25466344\n",
      "Validation Loss:  0.25408116\n",
      "Epoch:  59\n",
      "Training Loss:  0.25428334\n",
      "Validation Loss:  0.25253412\n",
      "Epoch:  60\n",
      "Training Loss:  0.25475988\n",
      "Validation Loss:  0.25229836\n",
      "Epoch:  61\n",
      "Training Loss:  0.25359717\n",
      "Validation Loss:  0.25101534\n",
      "Epoch:  62\n",
      "Training Loss:  0.25181848\n",
      "Validation Loss:  0.25331053\n",
      "Epoch:  63\n",
      "Training Loss:  0.2535831\n",
      "Validation Loss:  0.24986462\n",
      "Epoch:  64\n",
      "Training Loss:  0.25218025\n",
      "Validation Loss:  0.24690975\n",
      "Epoch:  65\n",
      "Training Loss:  0.2514347\n",
      "Validation Loss:  0.24749683\n",
      "Epoch:  66\n",
      "Training Loss:  0.25042346\n",
      "Validation Loss:  0.24806826\n",
      "Epoch:  67\n",
      "Training Loss:  0.2508613\n",
      "Validation Loss:  0.2453065\n",
      "Epoch:  68\n",
      "Training Loss:  0.24912289\n",
      "Validation Loss:  0.24499471\n",
      "Epoch:  69\n",
      "Training Loss:  0.24848397\n",
      "Validation Loss:  0.24929272\n",
      "Epoch:  70\n",
      "Training Loss:  0.24902008\n",
      "Validation Loss:  0.24598844\n",
      "Epoch:  71\n",
      "Training Loss:  0.25040606\n",
      "Validation Loss:  0.24533157\n",
      "Epoch:  72\n",
      "Training Loss:  0.24830501\n",
      "Validation Loss:  0.2463553\n",
      "Epoch:  73\n",
      "Training Loss:  0.24852054\n",
      "Validation Loss:  0.24755602\n",
      "Epoch:  74\n",
      "Training Loss:  0.2482634\n",
      "Validation Loss:  0.24717814\n",
      "Epoch:  75\n",
      "Training Loss:  0.24796937\n",
      "Validation Loss:  0.2427663\n",
      "Epoch:  76\n",
      "Training Loss:  0.24731176\n",
      "Validation Loss:  0.24530809\n",
      "Epoch:  77\n",
      "Training Loss:  0.24474631\n",
      "Validation Loss:  0.24549837\n",
      "Epoch:  78\n",
      "Training Loss:  0.24567528\n",
      "Validation Loss:  0.2418036\n",
      "Epoch:  79\n",
      "Training Loss:  0.24690172\n",
      "Validation Loss:  0.2475739\n",
      "Epoch:  80\n",
      "Training Loss:  0.2447606\n",
      "Validation Loss:  0.24373607\n",
      "Epoch:  81\n",
      "Training Loss:  0.24513663\n",
      "Validation Loss:  0.24198912\n",
      "Epoch:  82\n",
      "Training Loss:  0.24498883\n",
      "Validation Loss:  0.24163072\n",
      "Epoch:  83\n",
      "Training Loss:  0.24399535\n",
      "Validation Loss:  0.24006547\n",
      "Epoch:  84\n",
      "Training Loss:  0.24438705\n",
      "Validation Loss:  0.24061857\n",
      "Epoch:  85\n",
      "Training Loss:  0.24446863\n",
      "Validation Loss:  0.24245703\n",
      "Epoch:  86\n",
      "Training Loss:  0.24237089\n",
      "Validation Loss:  0.24105512\n",
      "Epoch:  87\n",
      "Training Loss:  0.24461757\n",
      "Validation Loss:  0.23721235\n",
      "Epoch:  88\n",
      "Training Loss:  0.24221705\n",
      "Validation Loss:  0.23973264\n",
      "Epoch:  89\n",
      "Training Loss:  0.2429559\n",
      "Validation Loss:  0.23837988\n",
      "Epoch:  90\n",
      "Training Loss:  0.24071938\n",
      "Validation Loss:  0.23766802\n",
      "Epoch:  91\n",
      "Training Loss:  0.239552\n",
      "Validation Loss:  0.23849875\n",
      "Epoch:  92\n",
      "Training Loss:  0.2402685\n",
      "Validation Loss:  0.23728383\n",
      "Epoch:  93\n",
      "Training Loss:  0.24077499\n",
      "Validation Loss:  0.23374242\n",
      "Epoch:  94\n",
      "Training Loss:  0.24030088\n",
      "Validation Loss:  0.23740776\n",
      "Epoch:  95\n",
      "Training Loss:  0.2393986\n",
      "Validation Loss:  0.24109297\n",
      "Epoch:  96\n",
      "Training Loss:  0.24074194\n",
      "Validation Loss:  0.2349509\n",
      "Epoch:  97\n",
      "Training Loss:  0.23815495\n",
      "Validation Loss:  0.23438333\n",
      "Epoch:  98\n",
      "Training Loss:  0.23914012\n",
      "Validation Loss:  0.23809643\n",
      "Epoch:  99\n",
      "Training Loss:  0.23949242\n",
      "Validation Loss:  0.23718815\n",
      "Epoch:  100\n",
      "Training Loss:  0.23768842\n",
      "Validation Loss:  0.23332886\n",
      "Epoch:  101\n",
      "Training Loss:  0.23814233\n",
      "Validation Loss:  0.2340142\n",
      "Epoch:  102\n",
      "Training Loss:  0.23632845\n",
      "Validation Loss:  0.23670517\n",
      "Epoch:  103\n",
      "Training Loss:  0.2365417\n",
      "Validation Loss:  0.23442833\n",
      "Epoch:  104\n",
      "Training Loss:  0.23462225\n",
      "Validation Loss:  0.23717797\n",
      "Epoch:  105\n",
      "Training Loss:  0.23478392\n",
      "Validation Loss:  0.23512767\n",
      "Epoch:  106\n",
      "Training Loss:  0.23548843\n",
      "Validation Loss:  0.23675156\n",
      "Epoch:  107\n",
      "Training Loss:  0.23610055\n",
      "Validation Loss:  0.23249264\n",
      "Epoch:  108\n",
      "Training Loss:  0.23557553\n",
      "Validation Loss:  0.23227113\n",
      "Epoch:  109\n",
      "Training Loss:  0.23366302\n",
      "Validation Loss:  0.23075174\n",
      "Epoch:  110\n",
      "Training Loss:  0.23361838\n",
      "Validation Loss:  0.23289025\n",
      "Epoch:  111\n",
      "Training Loss:  0.23412767\n",
      "Validation Loss:  0.2297528\n",
      "Epoch:  112\n",
      "Training Loss:  0.23470941\n",
      "Validation Loss:  0.22834848\n",
      "Epoch:  113\n",
      "Training Loss:  0.23398961\n",
      "Validation Loss:  0.23086739\n",
      "Epoch:  114\n",
      "Training Loss:  0.23126961\n",
      "Validation Loss:  0.22700982\n",
      "Epoch:  115\n",
      "Training Loss:  0.23314635\n",
      "Validation Loss:  0.23144467\n",
      "Epoch:  116\n",
      "Training Loss:  0.23294237\n",
      "Validation Loss:  0.23037988\n",
      "Epoch:  117\n",
      "Training Loss:  0.23116802\n",
      "Validation Loss:  0.22679447\n",
      "Epoch:  118\n",
      "Training Loss:  0.23117323\n",
      "Validation Loss:  0.22604401\n",
      "Epoch:  119\n",
      "Training Loss:  0.22976223\n",
      "Validation Loss:  0.224862\n",
      "Epoch:  120\n",
      "Training Loss:  0.2290758\n",
      "Validation Loss:  0.22914167\n",
      "Epoch:  121\n",
      "Training Loss:  0.23028171\n",
      "Validation Loss:  0.22721203\n",
      "Epoch:  122\n",
      "Training Loss:  0.2311841\n",
      "Validation Loss:  0.22621387\n",
      "Epoch:  123\n",
      "Training Loss:  0.22734787\n",
      "Validation Loss:  0.22848476\n",
      "Epoch:  124\n",
      "Training Loss:  0.22874673\n",
      "Validation Loss:  0.22842316\n",
      "Epoch:  125\n",
      "Training Loss:  0.22851138\n",
      "Validation Loss:  0.2274723\n",
      "Epoch:  126\n",
      "Training Loss:  0.22969486\n",
      "Validation Loss:  0.22376783\n",
      "Epoch:  127\n",
      "Training Loss:  0.22784773\n",
      "Validation Loss:  0.22465533\n",
      "Epoch:  128\n",
      "Training Loss:  0.22802341\n",
      "Validation Loss:  0.22134155\n",
      "Epoch:  129\n",
      "Training Loss:  0.22590686\n",
      "Validation Loss:  0.23032312\n",
      "Epoch:  130\n",
      "Training Loss:  0.22658932\n",
      "Validation Loss:  0.22273262\n",
      "Epoch:  131\n",
      "Training Loss:  0.22431506\n",
      "Validation Loss:  0.22398324\n",
      "Epoch:  132\n",
      "Training Loss:  0.2258964\n",
      "Validation Loss:  0.22378261\n",
      "Epoch:  133\n",
      "Training Loss:  0.22547175\n",
      "Validation Loss:  0.22277606\n",
      "Epoch:  134\n",
      "Training Loss:  0.22583358\n",
      "Validation Loss:  0.22144048\n",
      "Epoch:  135\n",
      "Training Loss:  0.22441848\n",
      "Validation Loss:  0.21933536\n",
      "Epoch:  136\n",
      "Training Loss:  0.22665206\n",
      "Validation Loss:  0.22519173\n",
      "Epoch:  137\n",
      "Training Loss:  0.22384216\n",
      "Validation Loss:  0.22348763\n",
      "Epoch:  138\n",
      "Training Loss:  0.22368504\n",
      "Validation Loss:  0.21905078\n",
      "Epoch:  139\n",
      "Training Loss:  0.22402415\n",
      "Validation Loss:  0.2234825\n",
      "Epoch:  140\n",
      "Training Loss:  0.22201586\n",
      "Validation Loss:  0.2200681\n",
      "Epoch:  141\n",
      "Training Loss:  0.22313643\n",
      "Validation Loss:  0.22059862\n",
      "Epoch:  142\n",
      "Training Loss:  0.22190067\n",
      "Validation Loss:  0.22189085\n",
      "Epoch:  143\n",
      "Training Loss:  0.22379294\n",
      "Validation Loss:  0.22023177\n",
      "Epoch:  144\n",
      "Training Loss:  0.22185345\n",
      "Validation Loss:  0.21411479\n",
      "Epoch:  145\n",
      "Training Loss:  0.22201853\n",
      "Validation Loss:  0.2190284\n",
      "Epoch:  146\n",
      "Training Loss:  0.220251\n",
      "Validation Loss:  0.21725081\n",
      "Epoch:  147\n",
      "Training Loss:  0.21987355\n",
      "Validation Loss:  0.21892405\n",
      "Epoch:  148\n",
      "Training Loss:  0.2200206\n",
      "Validation Loss:  0.21786161\n",
      "Epoch:  149\n",
      "Training Loss:  0.22002739\n",
      "Validation Loss:  0.21592242\n",
      "Epoch:  150\n",
      "Training Loss:  0.21878454\n",
      "Validation Loss:  0.216743\n",
      "Epoch:  151\n",
      "Training Loss:  0.22063197\n",
      "Validation Loss:  0.21799918\n",
      "Epoch:  152\n",
      "Training Loss:  0.21869023\n",
      "Validation Loss:  0.2178188\n",
      "Epoch:  153\n",
      "Training Loss:  0.21861918\n",
      "Validation Loss:  0.21378095\n",
      "Epoch:  154\n",
      "Training Loss:  0.21791038\n",
      "Validation Loss:  0.21710311\n",
      "Epoch:  155\n",
      "Training Loss:  0.21821497\n",
      "Validation Loss:  0.21497817\n",
      "Epoch:  156\n",
      "Training Loss:  0.21700776\n",
      "Validation Loss:  0.21415012\n",
      "Epoch:  157\n",
      "Training Loss:  0.21650238\n",
      "Validation Loss:  0.21139814\n",
      "Epoch:  158\n",
      "Training Loss:  0.21761079\n",
      "Validation Loss:  0.21109462\n",
      "Epoch:  159\n",
      "Training Loss:  0.21686077\n",
      "Validation Loss:  0.21437587\n",
      "Epoch:  160\n",
      "Training Loss:  0.21610841\n",
      "Validation Loss:  0.21738523\n",
      "Epoch:  161\n",
      "Training Loss:  0.21601692\n",
      "Validation Loss:  0.21199055\n",
      "Epoch:  162\n",
      "Training Loss:  0.21487252\n",
      "Validation Loss:  0.21179415\n",
      "Epoch:  163\n",
      "Training Loss:  0.2152451\n",
      "Validation Loss:  0.21157044\n",
      "Epoch:  164\n",
      "Training Loss:  0.21470869\n",
      "Validation Loss:  0.20949261\n",
      "Epoch:  165\n",
      "Training Loss:  0.21406339\n",
      "Validation Loss:  0.21257067\n",
      "Epoch:  166\n",
      "Training Loss:  0.21401066\n",
      "Validation Loss:  0.209891\n",
      "Epoch:  167\n",
      "Training Loss:  0.21277209\n",
      "Validation Loss:  0.21264298\n",
      "Epoch:  168\n",
      "Training Loss:  0.21286908\n",
      "Validation Loss:  0.21050262\n",
      "Epoch:  169\n",
      "Training Loss:  0.21289416\n",
      "Validation Loss:  0.20835422\n",
      "Epoch:  170\n",
      "Training Loss:  0.21394026\n",
      "Validation Loss:  0.2099657\n",
      "Epoch:  171\n",
      "Training Loss:  0.21122727\n",
      "Validation Loss:  0.21116336\n",
      "Epoch:  172\n",
      "Training Loss:  0.21278243\n",
      "Validation Loss:  0.20739377\n",
      "Epoch:  173\n",
      "Training Loss:  0.21245992\n",
      "Validation Loss:  0.21033378\n",
      "Epoch:  174\n",
      "Training Loss:  0.21124269\n",
      "Validation Loss:  0.20572615\n",
      "Epoch:  175\n",
      "Training Loss:  0.20959747\n",
      "Validation Loss:  0.21032648\n",
      "Epoch:  176\n",
      "Training Loss:  0.21097526\n",
      "Validation Loss:  0.2087184\n",
      "Epoch:  177\n",
      "Training Loss:  0.21069093\n",
      "Validation Loss:  0.20645668\n",
      "Epoch:  178\n",
      "Training Loss:  0.21027124\n",
      "Validation Loss:  0.20674038\n",
      "Epoch:  179\n",
      "Training Loss:  0.21047924\n",
      "Validation Loss:  0.20908253\n",
      "Epoch:  180\n",
      "Training Loss:  0.20945613\n",
      "Validation Loss:  0.2060533\n",
      "Epoch:  181\n",
      "Training Loss:  0.20767964\n",
      "Validation Loss:  0.20817487\n",
      "Epoch:  182\n",
      "Training Loss:  0.20957424\n",
      "Validation Loss:  0.20723528\n",
      "Epoch:  183\n",
      "Training Loss:  0.20782666\n",
      "Validation Loss:  0.20693462\n",
      "Epoch:  184\n",
      "Training Loss:  0.20707072\n",
      "Validation Loss:  0.201011\n",
      "Epoch:  185\n",
      "Training Loss:  0.20912303\n",
      "Validation Loss:  0.20570529\n",
      "Epoch:  186\n",
      "Training Loss:  0.20671459\n",
      "Validation Loss:  0.20828374\n",
      "Epoch:  187\n",
      "Training Loss:  0.2066298\n",
      "Validation Loss:  0.20381291\n",
      "Epoch:  188\n",
      "Training Loss:  0.2086667\n",
      "Validation Loss:  0.20584379\n",
      "Epoch:  189\n",
      "Training Loss:  0.20509847\n",
      "Validation Loss:  0.20106806\n",
      "Epoch:  190\n",
      "Training Loss:  0.20595685\n",
      "Validation Loss:  0.20130588\n",
      "Epoch:  191\n",
      "Training Loss:  0.20628019\n",
      "Validation Loss:  0.2048263\n",
      "Epoch:  192\n",
      "Training Loss:  0.20743589\n",
      "Validation Loss:  0.2014053\n",
      "Epoch:  193\n",
      "Training Loss:  0.20527755\n",
      "Validation Loss:  0.2016884\n",
      "Epoch:  194\n",
      "Training Loss:  0.20410034\n",
      "Validation Loss:  0.20197845\n",
      "Epoch:  195\n",
      "Training Loss:  0.20490271\n",
      "Validation Loss:  0.2014243\n",
      "Epoch:  196\n",
      "Training Loss:  0.20527193\n",
      "Validation Loss:  0.200567\n",
      "Epoch:  197\n",
      "Training Loss:  0.20368111\n",
      "Validation Loss:  0.20183332\n",
      "Epoch:  198\n",
      "Training Loss:  0.20390059\n",
      "Validation Loss:  0.19742711\n",
      "Epoch:  199\n",
      "Training Loss:  0.20255464\n",
      "Validation Loss:  0.20213671\n",
      "Epoch:  200\n",
      "Training Loss:  0.20362118\n",
      "Validation Loss:  0.19834791\n",
      "Epoch:  201\n",
      "Training Loss:  0.20334685\n",
      "Validation Loss:  0.19695161\n",
      "Epoch:  202\n",
      "Training Loss:  0.20121954\n",
      "Validation Loss:  0.19788791\n",
      "Epoch:  203\n",
      "Training Loss:  0.20205562\n",
      "Validation Loss:  0.19869508\n",
      "Epoch:  204\n",
      "Training Loss:  0.20124869\n",
      "Validation Loss:  0.19576631\n",
      "Epoch:  205\n",
      "Training Loss:  0.20049839\n",
      "Validation Loss:  0.19659217\n",
      "Epoch:  206\n",
      "Training Loss:  0.20137183\n",
      "Validation Loss:  0.19525822\n",
      "Epoch:  207\n",
      "Training Loss:  0.20030169\n",
      "Validation Loss:  0.19639815\n",
      "Epoch:  208\n",
      "Training Loss:  0.20013766\n",
      "Validation Loss:  0.19508071\n",
      "Epoch:  209\n",
      "Training Loss:  0.19855091\n",
      "Validation Loss:  0.19871037\n",
      "Epoch:  210\n",
      "Training Loss:  0.20024748\n",
      "Validation Loss:  0.19499479\n",
      "Epoch:  211\n",
      "Training Loss:  0.19917351\n",
      "Validation Loss:  0.19527572\n",
      "Epoch:  212\n",
      "Training Loss:  0.1986245\n",
      "Validation Loss:  0.19718336\n",
      "Epoch:  213\n",
      "Training Loss:  0.19650392\n",
      "Validation Loss:  0.19282354\n",
      "Epoch:  214\n",
      "Training Loss:  0.19911273\n",
      "Validation Loss:  0.19355993\n",
      "Epoch:  215\n",
      "Training Loss:  0.19852762\n",
      "Validation Loss:  0.19598371\n",
      "Epoch:  216\n",
      "Training Loss:  0.19644494\n",
      "Validation Loss:  0.19259213\n",
      "Epoch:  217\n",
      "Training Loss:  0.19507106\n",
      "Validation Loss:  0.19278263\n",
      "Epoch:  218\n",
      "Training Loss:  0.19641536\n",
      "Validation Loss:  0.19608124\n",
      "Epoch:  219\n",
      "Training Loss:  0.19684489\n",
      "Validation Loss:  0.1927213\n",
      "Epoch:  220\n",
      "Training Loss:  0.19594459\n",
      "Validation Loss:  0.18795954\n",
      "Epoch:  221\n",
      "Training Loss:  0.19536097\n",
      "Validation Loss:  0.19325669\n",
      "Epoch:  222\n",
      "Training Loss:  0.195833\n",
      "Validation Loss:  0.1926651\n",
      "Epoch:  223\n",
      "Training Loss:  0.19542477\n",
      "Validation Loss:  0.18850772\n",
      "Epoch:  224\n",
      "Training Loss:  0.19489947\n",
      "Validation Loss:  0.18966104\n",
      "Epoch:  225\n",
      "Training Loss:  0.19265202\n",
      "Validation Loss:  0.18878227\n",
      "Epoch:  226\n",
      "Training Loss:  0.1957756\n",
      "Validation Loss:  0.18964718\n",
      "Epoch:  227\n",
      "Training Loss:  0.19232786\n",
      "Validation Loss:  0.18970244\n",
      "Epoch:  228\n",
      "Training Loss:  0.1921596\n",
      "Validation Loss:  0.1884739\n",
      "Epoch:  229\n",
      "Training Loss:  0.19181436\n",
      "Validation Loss:  0.19088106\n",
      "Epoch:  230\n",
      "Training Loss:  0.19216952\n",
      "Validation Loss:  0.1918958\n",
      "Epoch:  231\n",
      "Training Loss:  0.1926258\n",
      "Validation Loss:  0.18535392\n",
      "Epoch:  232\n",
      "Training Loss:  0.19177707\n",
      "Validation Loss:  0.19012828\n",
      "Epoch:  233\n",
      "Training Loss:  0.19162264\n",
      "Validation Loss:  0.18825297\n",
      "Epoch:  234\n",
      "Training Loss:  0.19290891\n",
      "Validation Loss:  0.1862865\n",
      "Epoch:  235\n",
      "Training Loss:  0.19163406\n",
      "Validation Loss:  0.18715133\n",
      "Epoch:  236\n",
      "Training Loss:  0.19101709\n",
      "Validation Loss:  0.18821712\n",
      "Epoch:  237\n",
      "Training Loss:  0.18917961\n",
      "Validation Loss:  0.18874393\n",
      "Epoch:  238\n",
      "Training Loss:  0.19027382\n",
      "Validation Loss:  0.18574798\n",
      "Epoch:  239\n",
      "Training Loss:  0.18820265\n",
      "Validation Loss:  0.18663381\n",
      "Epoch:  240\n",
      "Training Loss:  0.18970287\n",
      "Validation Loss:  0.19091481\n",
      "Epoch:  241\n",
      "Training Loss:  0.19025803\n",
      "Validation Loss:  0.18917768\n",
      "Epoch:  242\n",
      "Training Loss:  0.18750615\n",
      "Validation Loss:  0.18432616\n",
      "Epoch:  243\n",
      "Training Loss:  0.18963192\n",
      "Validation Loss:  0.1822439\n",
      "Epoch:  244\n",
      "Training Loss:  0.18897136\n",
      "Validation Loss:  0.18613064\n",
      "Epoch:  245\n",
      "Training Loss:  0.18774976\n",
      "Validation Loss:  0.1855746\n",
      "Epoch:  246\n",
      "Training Loss:  0.18786003\n",
      "Validation Loss:  0.18124813\n",
      "Epoch:  247\n",
      "Training Loss:  0.18908393\n",
      "Validation Loss:  0.18668711\n",
      "Epoch:  248\n",
      "Training Loss:  0.18768601\n",
      "Validation Loss:  0.18219112\n",
      "Epoch:  249\n",
      "Training Loss:  0.18726854\n",
      "Validation Loss:  0.17981358\n",
      "Epoch:  250\n",
      "Training Loss:  0.18638723\n",
      "Validation Loss:  0.18378568\n",
      "Epoch:  251\n",
      "Training Loss:  0.18727192\n",
      "Validation Loss:  0.1802058\n",
      "Epoch:  252\n",
      "Training Loss:  0.18811898\n",
      "Validation Loss:  0.1832218\n",
      "Epoch:  253\n",
      "Training Loss:  0.18532531\n",
      "Validation Loss:  0.18191014\n",
      "Epoch:  254\n",
      "Training Loss:  0.1846858\n",
      "Validation Loss:  0.17908084\n",
      "Epoch:  255\n",
      "Training Loss:  0.18334901\n",
      "Validation Loss:  0.17719309\n",
      "Epoch:  256\n",
      "Training Loss:  0.18345903\n",
      "Validation Loss:  0.18176378\n",
      "Epoch:  257\n",
      "Training Loss:  0.18580462\n",
      "Validation Loss:  0.17776193\n",
      "Epoch:  258\n",
      "Training Loss:  0.18408906\n",
      "Validation Loss:  0.18090637\n",
      "Epoch:  259\n",
      "Training Loss:  0.18422645\n",
      "Validation Loss:  0.18173474\n",
      "Epoch:  260\n",
      "Training Loss:  0.18276823\n",
      "Validation Loss:  0.17746748\n",
      "Epoch:  261\n",
      "Training Loss:  0.18393995\n",
      "Validation Loss:  0.17825378\n",
      "Epoch:  262\n",
      "Training Loss:  0.18378565\n",
      "Validation Loss:  0.17867796\n",
      "Epoch:  263\n",
      "Training Loss:  0.18282528\n",
      "Validation Loss:  0.18014258\n",
      "Epoch:  264\n",
      "Training Loss:  0.18262388\n",
      "Validation Loss:  0.17413248\n",
      "Epoch:  265\n",
      "Training Loss:  0.1830645\n",
      "Validation Loss:  0.17665905\n",
      "Epoch:  266\n",
      "Training Loss:  0.18103674\n",
      "Validation Loss:  0.1783176\n",
      "Epoch:  267\n",
      "Training Loss:  0.18100373\n",
      "Validation Loss:  0.17818463\n",
      "Epoch:  268\n",
      "Training Loss:  0.18066502\n",
      "Validation Loss:  0.17483789\n",
      "Epoch:  269\n",
      "Training Loss:  0.18097314\n",
      "Validation Loss:  0.1778877\n",
      "Epoch:  270\n",
      "Training Loss:  0.1816073\n",
      "Validation Loss:  0.17553769\n",
      "Epoch:  271\n",
      "Training Loss:  0.18011908\n",
      "Validation Loss:  0.17632258\n",
      "Epoch:  272\n",
      "Training Loss:  0.17935796\n",
      "Validation Loss:  0.17805474\n",
      "Epoch:  273\n",
      "Training Loss:  0.17925349\n",
      "Validation Loss:  0.17601734\n",
      "Epoch:  274\n",
      "Training Loss:  0.17951924\n",
      "Validation Loss:  0.1709423\n",
      "Epoch:  275\n",
      "Training Loss:  0.1777722\n",
      "Validation Loss:  0.17630863\n",
      "Epoch:  276\n",
      "Training Loss:  0.17928676\n",
      "Validation Loss:  0.17599191\n",
      "Epoch:  277\n",
      "Training Loss:  0.17905855\n",
      "Validation Loss:  0.17640114\n",
      "Epoch:  278\n",
      "Training Loss:  0.17769793\n",
      "Validation Loss:  0.17659284\n",
      "Epoch:  279\n",
      "Training Loss:  0.17759329\n",
      "Validation Loss:  0.17694391\n",
      "Epoch:  280\n",
      "Training Loss:  0.17809053\n",
      "Validation Loss:  0.17504038\n",
      "Epoch:  281\n",
      "Training Loss:  0.17806341\n",
      "Validation Loss:  0.17034118\n",
      "Epoch:  282\n",
      "Training Loss:  0.1760534\n",
      "Validation Loss:  0.17259626\n",
      "Epoch:  283\n",
      "Training Loss:  0.17615986\n",
      "Validation Loss:  0.17502779\n",
      "Epoch:  284\n",
      "Training Loss:  0.17586975\n",
      "Validation Loss:  0.1731837\n",
      "Epoch:  285\n",
      "Training Loss:  0.17497084\n",
      "Validation Loss:  0.17365299\n",
      "Epoch:  286\n",
      "Training Loss:  0.17435542\n",
      "Validation Loss:  0.17252783\n",
      "Epoch:  287\n",
      "Training Loss:  0.17536464\n",
      "Validation Loss:  0.17404915\n",
      "Epoch:  288\n",
      "Training Loss:  0.17621192\n",
      "Validation Loss:  0.17055126\n",
      "Epoch:  289\n",
      "Training Loss:  0.17611986\n",
      "Validation Loss:  0.17565583\n",
      "Epoch:  290\n",
      "Training Loss:  0.17485236\n",
      "Validation Loss:  0.17043395\n",
      "Epoch:  291\n",
      "Training Loss:  0.17498617\n",
      "Validation Loss:  0.17312807\n",
      "Epoch:  292\n",
      "Training Loss:  0.17357694\n",
      "Validation Loss:  0.16910423\n",
      "Epoch:  293\n",
      "Training Loss:  0.174262\n",
      "Validation Loss:  0.17132671\n",
      "Epoch:  294\n",
      "Training Loss:  0.17315361\n",
      "Validation Loss:  0.17056279\n",
      "Epoch:  295\n",
      "Training Loss:  0.1735657\n",
      "Validation Loss:  0.16839212\n",
      "Epoch:  296\n",
      "Training Loss:  0.17173044\n",
      "Validation Loss:  0.1697874\n",
      "Epoch:  297\n",
      "Training Loss:  0.17349899\n",
      "Validation Loss:  0.17024441\n",
      "Epoch:  298\n",
      "Training Loss:  0.17268442\n",
      "Validation Loss:  0.16611809\n",
      "Epoch:  299\n",
      "Training Loss:  0.17204584\n",
      "Validation Loss:  0.16849989\n",
      "Epoch:  300\n",
      "Training Loss:  0.17161116\n",
      "Validation Loss:  0.16975625\n",
      "Epoch:  301\n",
      "Training Loss:  0.17114419\n",
      "Validation Loss:  0.16477276\n",
      "Epoch:  302\n",
      "Training Loss:  0.17079711\n",
      "Validation Loss:  0.16697614\n",
      "Epoch:  303\n",
      "Training Loss:  0.1710328\n",
      "Validation Loss:  0.16518086\n",
      "Epoch:  304\n",
      "Training Loss:  0.16822122\n",
      "Validation Loss:  0.17030232\n",
      "Epoch:  305\n",
      "Training Loss:  0.16837071\n",
      "Validation Loss:  0.167998\n",
      "Epoch:  306\n",
      "Training Loss:  0.17001115\n",
      "Validation Loss:  0.16296656\n",
      "Epoch:  307\n",
      "Training Loss:  0.16904221\n",
      "Validation Loss:  0.1645694\n",
      "Epoch:  308\n",
      "Training Loss:  0.16871406\n",
      "Validation Loss:  0.16695614\n",
      "Epoch:  309\n",
      "Training Loss:  0.17068806\n",
      "Validation Loss:  0.16717845\n",
      "Epoch:  310\n",
      "Training Loss:  0.16836525\n",
      "Validation Loss:  0.16325778\n",
      "Epoch:  311\n",
      "Training Loss:  0.16842526\n",
      "Validation Loss:  0.16311269\n",
      "Epoch:  312\n",
      "Training Loss:  0.1678986\n",
      "Validation Loss:  0.16309284\n",
      "Epoch:  313\n",
      "Training Loss:  0.16779579\n",
      "Validation Loss:  0.16360189\n",
      "Epoch:  314\n",
      "Training Loss:  0.16840242\n",
      "Validation Loss:  0.16215627\n",
      "Epoch:  315\n",
      "Training Loss:  0.16702911\n",
      "Validation Loss:  0.16734433\n",
      "Epoch:  316\n",
      "Training Loss:  0.1683697\n",
      "Validation Loss:  0.15984808\n",
      "Epoch:  317\n",
      "Training Loss:  0.16597007\n",
      "Validation Loss:  0.16431378\n",
      "Epoch:  318\n",
      "Training Loss:  0.16588877\n",
      "Validation Loss:  0.16267021\n",
      "Epoch:  319\n",
      "Training Loss:  0.16744754\n",
      "Validation Loss:  0.15998885\n",
      "Epoch:  320\n",
      "Training Loss:  0.16599455\n",
      "Validation Loss:  0.16478391\n",
      "Epoch:  321\n",
      "Training Loss:  0.1656655\n",
      "Validation Loss:  0.16038089\n",
      "Epoch:  322\n",
      "Training Loss:  0.16564031\n",
      "Validation Loss:  0.16319145\n",
      "Epoch:  323\n",
      "Training Loss:  0.16646942\n",
      "Validation Loss:  0.16051315\n",
      "Epoch:  324\n",
      "Training Loss:  0.16503216\n",
      "Validation Loss:  0.16255921\n",
      "Epoch:  325\n",
      "Training Loss:  0.16384964\n",
      "Validation Loss:  0.16118486\n",
      "Epoch:  326\n",
      "Training Loss:  0.16337195\n",
      "Validation Loss:  0.16073547\n",
      "Epoch:  327\n",
      "Training Loss:  0.16444735\n",
      "Validation Loss:  0.16075628\n",
      "Epoch:  328\n",
      "Training Loss:  0.16539201\n",
      "Validation Loss:  0.15864898\n",
      "Epoch:  329\n",
      "Training Loss:  0.1642417\n",
      "Validation Loss:  0.1602514\n",
      "Epoch:  330\n",
      "Training Loss:  0.16149898\n",
      "Validation Loss:  0.15680929\n",
      "Epoch:  331\n",
      "Training Loss:  0.16153298\n",
      "Validation Loss:  0.15987356\n",
      "Epoch:  332\n",
      "Training Loss:  0.1614222\n",
      "Validation Loss:  0.15818615\n",
      "Epoch:  333\n",
      "Training Loss:  0.16248131\n",
      "Validation Loss:  0.15890037\n",
      "Epoch:  334\n",
      "Training Loss:  0.16101465\n",
      "Validation Loss:  0.16183433\n",
      "Epoch:  335\n",
      "Training Loss:  0.16028127\n",
      "Validation Loss:  0.15964985\n",
      "Epoch:  336\n",
      "Training Loss:  0.1609079\n",
      "Validation Loss:  0.15953545\n",
      "Epoch:  337\n",
      "Training Loss:  0.15994172\n",
      "Validation Loss:  0.15785289\n",
      "Epoch:  338\n",
      "Training Loss:  0.1624141\n",
      "Validation Loss:  0.1566036\n",
      "Epoch:  339\n",
      "Training Loss:  0.16147074\n",
      "Validation Loss:  0.1564119\n",
      "Epoch:  340\n",
      "Training Loss:  0.1606441\n",
      "Validation Loss:  0.15463667\n",
      "Epoch:  341\n",
      "Training Loss:  0.15997374\n",
      "Validation Loss:  0.15448718\n",
      "Epoch:  342\n",
      "Training Loss:  0.1605109\n",
      "Validation Loss:  0.15865229\n",
      "Epoch:  343\n",
      "Training Loss:  0.15970004\n",
      "Validation Loss:  0.1571601\n",
      "Epoch:  344\n",
      "Training Loss:  0.15875685\n",
      "Validation Loss:  0.15364979\n",
      "Epoch:  345\n",
      "Training Loss:  0.15862183\n",
      "Validation Loss:  0.15618692\n",
      "Epoch:  346\n",
      "Training Loss:  0.15843461\n",
      "Validation Loss:  0.15816237\n",
      "Epoch:  347\n",
      "Training Loss:  0.15649909\n",
      "Validation Loss:  0.15679818\n",
      "Epoch:  348\n",
      "Training Loss:  0.157372\n",
      "Validation Loss:  0.15349783\n",
      "Epoch:  349\n",
      "Training Loss:  0.15764351\n",
      "Validation Loss:  0.15276611\n",
      "Epoch:  350\n",
      "Training Loss:  0.15737814\n",
      "Validation Loss:  0.15443853\n",
      "Epoch:  351\n",
      "Training Loss:  0.15563674\n",
      "Validation Loss:  0.15529694\n",
      "Epoch:  352\n",
      "Training Loss:  0.15811983\n",
      "Validation Loss:  0.15440609\n",
      "Epoch:  353\n",
      "Training Loss:  0.15634416\n",
      "Validation Loss:  0.15180388\n",
      "Epoch:  354\n",
      "Training Loss:  0.15697601\n",
      "Validation Loss:  0.15116456\n",
      "Epoch:  355\n",
      "Training Loss:  0.15668036\n",
      "Validation Loss:  0.14935057\n",
      "Epoch:  356\n",
      "Training Loss:  0.15618251\n",
      "Validation Loss:  0.15921608\n",
      "Epoch:  357\n",
      "Training Loss:  0.15459439\n",
      "Validation Loss:  0.15363888\n",
      "Epoch:  358\n",
      "Training Loss:  0.15576158\n",
      "Validation Loss:  0.14941765\n",
      "Epoch:  359\n",
      "Training Loss:  0.15449676\n",
      "Validation Loss:  0.14655007\n",
      "Epoch:  360\n",
      "Training Loss:  0.15594423\n",
      "Validation Loss:  0.15184939\n",
      "Epoch:  361\n",
      "Training Loss:  0.15412378\n",
      "Validation Loss:  0.14570653\n",
      "Epoch:  362\n",
      "Training Loss:  0.15392661\n",
      "Validation Loss:  0.14893936\n",
      "Epoch:  363\n",
      "Training Loss:  0.15413153\n",
      "Validation Loss:  0.15171795\n",
      "Epoch:  364\n",
      "Training Loss:  0.15437438\n",
      "Validation Loss:  0.14682122\n",
      "Epoch:  365\n",
      "Training Loss:  0.15259878\n",
      "Validation Loss:  0.15354465\n",
      "Epoch:  366\n",
      "Training Loss:  0.15161787\n",
      "Validation Loss:  0.14872871\n",
      "Epoch:  367\n",
      "Training Loss:  0.1514902\n",
      "Validation Loss:  0.14889081\n",
      "Epoch:  368\n",
      "Training Loss:  0.1522263\n",
      "Validation Loss:  0.1497047\n",
      "Epoch:  369\n",
      "Training Loss:  0.1524653\n",
      "Validation Loss:  0.14933398\n",
      "Epoch:  370\n",
      "Training Loss:  0.15218127\n",
      "Validation Loss:  0.14439285\n",
      "Epoch:  371\n",
      "Training Loss:  0.152094\n",
      "Validation Loss:  0.14950667\n",
      "Epoch:  372\n",
      "Training Loss:  0.151715\n",
      "Validation Loss:  0.15308347\n",
      "Epoch:  373\n",
      "Training Loss:  0.15183114\n",
      "Validation Loss:  0.14467673\n",
      "Epoch:  374\n",
      "Training Loss:  0.14962722\n",
      "Validation Loss:  0.14577456\n",
      "Epoch:  375\n",
      "Training Loss:  0.15084419\n",
      "Validation Loss:  0.1472158\n",
      "Epoch:  376\n",
      "Training Loss:  0.15068643\n",
      "Validation Loss:  0.14740522\n",
      "Epoch:  377\n",
      "Training Loss:  0.1512511\n",
      "Validation Loss:  0.1452237\n",
      "Epoch:  378\n",
      "Training Loss:  0.1515311\n",
      "Validation Loss:  0.14751768\n",
      "Epoch:  379\n",
      "Training Loss:  0.15027237\n",
      "Validation Loss:  0.14709283\n",
      "Epoch:  380\n",
      "Training Loss:  0.14827539\n",
      "Validation Loss:  0.1476525\n",
      "Epoch:  381\n",
      "Training Loss:  0.14788897\n",
      "Validation Loss:  0.1445413\n",
      "Epoch:  382\n",
      "Training Loss:  0.14795806\n",
      "Validation Loss:  0.14568372\n",
      "Epoch:  383\n",
      "Training Loss:  0.14619556\n",
      "Validation Loss:  0.14725852\n",
      "Epoch:  384\n",
      "Training Loss:  0.14899811\n",
      "Validation Loss:  0.14808406\n",
      "Epoch:  385\n",
      "Training Loss:  0.14777032\n",
      "Validation Loss:  0.13999005\n",
      "Epoch:  386\n",
      "Training Loss:  0.14723134\n",
      "Validation Loss:  0.14476877\n",
      "Epoch:  387\n",
      "Training Loss:  0.14710914\n",
      "Validation Loss:  0.14301588\n",
      "Epoch:  388\n",
      "Training Loss:  0.14807801\n",
      "Validation Loss:  0.14110751\n",
      "Epoch:  389\n",
      "Training Loss:  0.14528582\n",
      "Validation Loss:  0.141985\n",
      "Epoch:  390\n",
      "Training Loss:  0.14564706\n",
      "Validation Loss:  0.14394028\n",
      "Epoch:  391\n",
      "Training Loss:  0.14634238\n",
      "Validation Loss:  0.14433108\n",
      "Epoch:  392\n",
      "Training Loss:  0.14731655\n",
      "Validation Loss:  0.13910171\n",
      "Epoch:  393\n",
      "Training Loss:  0.14662614\n",
      "Validation Loss:  0.14200489\n",
      "Epoch:  394\n",
      "Training Loss:  0.14463113\n",
      "Validation Loss:  0.1441242\n",
      "Epoch:  395\n",
      "Training Loss:  0.1447314\n",
      "Validation Loss:  0.14164585\n",
      "Epoch:  396\n",
      "Training Loss:  0.14462726\n",
      "Validation Loss:  0.1434527\n",
      "Epoch:  397\n",
      "Training Loss:  0.14591841\n",
      "Validation Loss:  0.13764496\n",
      "Epoch:  398\n",
      "Training Loss:  0.14419033\n",
      "Validation Loss:  0.13964324\n",
      "Epoch:  399\n",
      "Training Loss:  0.14438942\n",
      "Validation Loss:  0.14359854\n",
      "Epoch:  400\n",
      "Training Loss:  0.14359017\n",
      "Validation Loss:  0.13873957\n",
      "Epoch:  401\n",
      "Training Loss:  0.14477728\n",
      "Validation Loss:  0.14343421\n",
      "Epoch:  402\n",
      "Training Loss:  0.14368539\n",
      "Validation Loss:  0.13791554\n",
      "Epoch:  403\n",
      "Training Loss:  0.1447048\n",
      "Validation Loss:  0.14531723\n",
      "Epoch:  404\n",
      "Training Loss:  0.14346059\n",
      "Validation Loss:  0.13881955\n",
      "Epoch:  405\n",
      "Training Loss:  0.14312242\n",
      "Validation Loss:  0.14084493\n",
      "Epoch:  406\n",
      "Training Loss:  0.1429665\n",
      "Validation Loss:  0.14282548\n",
      "Epoch:  407\n",
      "Training Loss:  0.14309391\n",
      "Validation Loss:  0.13975036\n",
      "Epoch:  408\n",
      "Training Loss:  0.14163943\n",
      "Validation Loss:  0.14092714\n",
      "Epoch:  409\n",
      "Training Loss:  0.14174294\n",
      "Validation Loss:  0.13903101\n",
      "Epoch:  410\n",
      "Training Loss:  0.14159553\n",
      "Validation Loss:  0.14072406\n",
      "Epoch:  411\n",
      "Training Loss:  0.14221476\n",
      "Validation Loss:  0.13773465\n",
      "Epoch:  412\n",
      "Training Loss:  0.13980626\n",
      "Validation Loss:  0.13823116\n",
      "Epoch:  413\n",
      "Training Loss:  0.14130728\n",
      "Validation Loss:  0.13711442\n",
      "Epoch:  414\n",
      "Training Loss:  0.1411897\n",
      "Validation Loss:  0.13628747\n",
      "Epoch:  415\n",
      "Training Loss:  0.14116383\n",
      "Validation Loss:  0.13732515\n",
      "Epoch:  416\n",
      "Training Loss:  0.13847686\n",
      "Validation Loss:  0.13356835\n",
      "Epoch:  417\n",
      "Training Loss:  0.13921031\n",
      "Validation Loss:  0.13797985\n",
      "Epoch:  418\n",
      "Training Loss:  0.13939242\n",
      "Validation Loss:  0.1368665\n",
      "Epoch:  419\n",
      "Training Loss:  0.1388624\n",
      "Validation Loss:  0.13943975\n",
      "Epoch:  420\n",
      "Training Loss:  0.13937935\n",
      "Validation Loss:  0.13702123\n",
      "Epoch:  421\n",
      "Training Loss:  0.13899137\n",
      "Validation Loss:  0.1344269\n",
      "Epoch:  422\n",
      "Training Loss:  0.14005451\n",
      "Validation Loss:  0.137689\n",
      "Epoch:  423\n",
      "Training Loss:  0.13707998\n",
      "Validation Loss:  0.1315177\n",
      "Epoch:  424\n",
      "Training Loss:  0.13818981\n",
      "Validation Loss:  0.1355453\n",
      "Epoch:  425\n",
      "Training Loss:  0.13876945\n",
      "Validation Loss:  0.13250344\n",
      "Epoch:  426\n",
      "Training Loss:  0.13730612\n",
      "Validation Loss:  0.13548918\n",
      "Epoch:  427\n",
      "Training Loss:  0.13685837\n",
      "Validation Loss:  0.13342324\n",
      "Epoch:  428\n",
      "Training Loss:  0.13655351\n",
      "Validation Loss:  0.13571483\n",
      "Epoch:  429\n",
      "Training Loss:  0.13651246\n",
      "Validation Loss:  0.13319062\n",
      "Epoch:  430\n",
      "Training Loss:  0.13701196\n",
      "Validation Loss:  0.13209279\n",
      "Epoch:  431\n",
      "Training Loss:  0.13679515\n",
      "Validation Loss:  0.13180102\n",
      "Epoch:  432\n",
      "Training Loss:  0.13666871\n",
      "Validation Loss:  0.13460614\n",
      "Epoch:  433\n",
      "Training Loss:  0.13545786\n",
      "Validation Loss:  0.13205771\n",
      "Epoch:  434\n",
      "Training Loss:  0.13431528\n",
      "Validation Loss:  0.13568072\n",
      "Epoch:  435\n",
      "Training Loss:  0.13540997\n",
      "Validation Loss:  0.13647665\n",
      "Epoch:  436\n",
      "Training Loss:  0.13539766\n",
      "Validation Loss:  0.13004757\n",
      "Epoch:  437\n",
      "Training Loss:  0.13486856\n",
      "Validation Loss:  0.13371813\n",
      "Epoch:  438\n",
      "Training Loss:  0.13503757\n",
      "Validation Loss:  0.13218081\n",
      "Epoch:  439\n",
      "Training Loss:  0.13226005\n",
      "Validation Loss:  0.12940247\n",
      "Epoch:  440\n",
      "Training Loss:  0.13323197\n",
      "Validation Loss:  0.12931311\n",
      "Epoch:  441\n",
      "Training Loss:  0.13430515\n",
      "Validation Loss:  0.13157453\n",
      "Epoch:  442\n",
      "Training Loss:  0.13140629\n",
      "Validation Loss:  0.12729333\n",
      "Epoch:  443\n",
      "Training Loss:  0.13242108\n",
      "Validation Loss:  0.13285899\n",
      "Epoch:  444\n",
      "Training Loss:  0.13338588\n",
      "Validation Loss:  0.12735914\n",
      "Epoch:  445\n",
      "Training Loss:  0.13362059\n",
      "Validation Loss:  0.12738405\n",
      "Epoch:  446\n",
      "Training Loss:  0.13414228\n",
      "Validation Loss:  0.12983176\n",
      "Epoch:  447\n",
      "Training Loss:  0.13253132\n",
      "Validation Loss:  0.12646787\n",
      "Epoch:  448\n",
      "Training Loss:  0.13159905\n",
      "Validation Loss:  0.13000526\n",
      "Epoch:  449\n",
      "Training Loss:  0.13359918\n",
      "Validation Loss:  0.12786056\n",
      "Epoch:  450\n",
      "Training Loss:  0.1306252\n",
      "Validation Loss:  0.12821844\n",
      "Epoch:  451\n",
      "Training Loss:  0.13165343\n",
      "Validation Loss:  0.12870729\n",
      "Epoch:  452\n",
      "Training Loss:  0.13116218\n",
      "Validation Loss:  0.13050942\n",
      "Epoch:  453\n",
      "Training Loss:  0.13321194\n",
      "Validation Loss:  0.12979645\n",
      "Epoch:  454\n",
      "Training Loss:  0.13072534\n",
      "Validation Loss:  0.12489737\n",
      "Epoch:  455\n",
      "Training Loss:  0.12970224\n",
      "Validation Loss:  0.13019456\n",
      "Epoch:  456\n",
      "Training Loss:  0.13098674\n",
      "Validation Loss:  0.12779723\n",
      "Epoch:  457\n",
      "Training Loss:  0.1301629\n",
      "Validation Loss:  0.13243978\n",
      "Epoch:  458\n",
      "Training Loss:  0.13052131\n",
      "Validation Loss:  0.1247948\n",
      "Epoch:  459\n",
      "Training Loss:  0.12834299\n",
      "Validation Loss:  0.1272179\n",
      "Epoch:  460\n",
      "Training Loss:  0.13069987\n",
      "Validation Loss:  0.12658973\n",
      "Epoch:  461\n",
      "Training Loss:  0.13065612\n",
      "Validation Loss:  0.12649746\n",
      "Epoch:  462\n",
      "Training Loss:  0.12970008\n",
      "Validation Loss:  0.12418259\n",
      "Epoch:  463\n",
      "Training Loss:  0.12813209\n",
      "Validation Loss:  0.1270648\n",
      "Epoch:  464\n",
      "Training Loss:  0.12761845\n",
      "Validation Loss:  0.122908026\n",
      "Epoch:  465\n",
      "Training Loss:  0.1258491\n",
      "Validation Loss:  0.12604746\n",
      "Epoch:  466\n",
      "Training Loss:  0.12812163\n",
      "Validation Loss:  0.12374995\n",
      "Epoch:  467\n",
      "Training Loss:  0.12835097\n",
      "Validation Loss:  0.12253509\n",
      "Epoch:  468\n",
      "Training Loss:  0.1269867\n",
      "Validation Loss:  0.12670112\n",
      "Epoch:  469\n",
      "Training Loss:  0.12828374\n",
      "Validation Loss:  0.12273521\n",
      "Epoch:  470\n",
      "Training Loss:  0.12771454\n",
      "Validation Loss:  0.12017525\n",
      "Epoch:  471\n",
      "Training Loss:  0.125786\n",
      "Validation Loss:  0.12127987\n",
      "Epoch:  472\n",
      "Training Loss:  0.12567031\n",
      "Validation Loss:  0.12652288\n",
      "Epoch:  473\n",
      "Training Loss:  0.12646961\n",
      "Validation Loss:  0.12391458\n",
      "Epoch:  474\n",
      "Training Loss:  0.12767254\n",
      "Validation Loss:  0.1230208\n",
      "Epoch:  475\n",
      "Training Loss:  0.12531081\n",
      "Validation Loss:  0.12329504\n",
      "Epoch:  476\n",
      "Training Loss:  0.12527955\n",
      "Validation Loss:  0.11769146\n",
      "Epoch:  477\n",
      "Training Loss:  0.12558678\n",
      "Validation Loss:  0.122208215\n",
      "Epoch:  478\n",
      "Training Loss:  0.1252068\n",
      "Validation Loss:  0.11830617\n",
      "Epoch:  479\n",
      "Training Loss:  0.12459444\n",
      "Validation Loss:  0.12124447\n",
      "Epoch:  480\n",
      "Training Loss:  0.1252228\n",
      "Validation Loss:  0.12131115\n",
      "Epoch:  481\n",
      "Training Loss:  0.124318145\n",
      "Validation Loss:  0.119365595\n",
      "Epoch:  482\n",
      "Training Loss:  0.123746075\n",
      "Validation Loss:  0.12018115\n",
      "Epoch:  483\n",
      "Training Loss:  0.12456284\n",
      "Validation Loss:  0.1218457\n",
      "Epoch:  484\n",
      "Training Loss:  0.122385874\n",
      "Validation Loss:  0.12253583\n",
      "Epoch:  485\n",
      "Training Loss:  0.12500171\n",
      "Validation Loss:  0.119288184\n",
      "Epoch:  486\n",
      "Training Loss:  0.12477679\n",
      "Validation Loss:  0.1225808\n",
      "Epoch:  487\n",
      "Training Loss:  0.123977475\n",
      "Validation Loss:  0.12299868\n",
      "Epoch:  488\n",
      "Training Loss:  0.121609524\n",
      "Validation Loss:  0.122367255\n",
      "Epoch:  489\n",
      "Training Loss:  0.1223904\n",
      "Validation Loss:  0.1192435\n",
      "Epoch:  490\n",
      "Training Loss:  0.12333173\n",
      "Validation Loss:  0.12337101\n",
      "Epoch:  491\n",
      "Training Loss:  0.12280141\n",
      "Validation Loss:  0.12518522\n",
      "Epoch:  492\n",
      "Training Loss:  0.12201542\n",
      "Validation Loss:  0.11521641\n",
      "Epoch:  493\n",
      "Training Loss:  0.123503074\n",
      "Validation Loss:  0.121054746\n",
      "Epoch:  494\n",
      "Training Loss:  0.12014208\n",
      "Validation Loss:  0.11740718\n",
      "Epoch:  495\n",
      "Training Loss:  0.12130907\n",
      "Validation Loss:  0.11676175\n",
      "Epoch:  496\n",
      "Training Loss:  0.12059132\n",
      "Validation Loss:  0.11837181\n",
      "Epoch:  497\n",
      "Training Loss:  0.123134844\n",
      "Validation Loss:  0.11782346\n",
      "Epoch:  498\n",
      "Training Loss:  0.12162587\n",
      "Validation Loss:  0.11962443\n",
      "Epoch:  499\n",
      "Training Loss:  0.121381804\n",
      "Validation Loss:  0.11803544\n",
      "Epoch:  500\n",
      "Training Loss:  0.12009405\n",
      "Validation Loss:  0.11570033\n",
      "Epoch:  501\n",
      "Training Loss:  0.118289806\n",
      "Validation Loss:  0.115260385\n",
      "Epoch:  502\n",
      "Training Loss:  0.120129004\n",
      "Validation Loss:  0.11538539\n",
      "Epoch:  503\n",
      "Training Loss:  0.12152044\n",
      "Validation Loss:  0.11657888\n",
      "Epoch:  504\n",
      "Training Loss:  0.119507894\n",
      "Validation Loss:  0.117111005\n",
      "Epoch:  505\n",
      "Training Loss:  0.120033555\n",
      "Validation Loss:  0.11203662\n",
      "Epoch:  506\n",
      "Training Loss:  0.11806036\n",
      "Validation Loss:  0.114927374\n",
      "Epoch:  507\n",
      "Training Loss:  0.118853115\n",
      "Validation Loss:  0.11527767\n",
      "Epoch:  508\n",
      "Training Loss:  0.11737329\n",
      "Validation Loss:  0.11542162\n",
      "Epoch:  509\n",
      "Training Loss:  0.11721634\n",
      "Validation Loss:  0.11332708\n",
      "Epoch:  510\n",
      "Training Loss:  0.11859159\n",
      "Validation Loss:  0.11191643\n",
      "Epoch:  511\n",
      "Training Loss:  0.11855169\n",
      "Validation Loss:  0.113226525\n",
      "Epoch:  512\n",
      "Training Loss:  0.11673361\n",
      "Validation Loss:  0.11165192\n",
      "Epoch:  513\n",
      "Training Loss:  0.11805911\n",
      "Validation Loss:  0.118530326\n",
      "Epoch:  514\n",
      "Training Loss:  0.11726852\n",
      "Validation Loss:  0.11451015\n",
      "Epoch:  515\n",
      "Training Loss:  0.116730206\n",
      "Validation Loss:  0.1139297\n",
      "Epoch:  516\n",
      "Training Loss:  0.117943846\n",
      "Validation Loss:  0.11239725\n",
      "Epoch:  517\n",
      "Training Loss:  0.11719595\n",
      "Validation Loss:  0.11173412\n",
      "Epoch:  518\n",
      "Training Loss:  0.11714644\n",
      "Validation Loss:  0.11538588\n",
      "Epoch:  519\n",
      "Training Loss:  0.114747524\n",
      "Validation Loss:  0.11432732\n",
      "Epoch:  520\n",
      "Training Loss:  0.117000535\n",
      "Validation Loss:  0.111862935\n",
      "Epoch:  521\n",
      "Training Loss:  0.1153593\n",
      "Validation Loss:  0.11241291\n",
      "Epoch:  522\n",
      "Training Loss:  0.11571636\n",
      "Validation Loss:  0.11031487\n",
      "Epoch:  523\n",
      "Training Loss:  0.11433466\n",
      "Validation Loss:  0.10938033\n",
      "Epoch:  524\n",
      "Training Loss:  0.11560316\n",
      "Validation Loss:  0.108938806\n",
      "Epoch:  525\n",
      "Training Loss:  0.115142204\n",
      "Validation Loss:  0.109602354\n",
      "Epoch:  526\n",
      "Training Loss:  0.113567755\n",
      "Validation Loss:  0.11243976\n",
      "Epoch:  527\n",
      "Training Loss:  0.11388304\n",
      "Validation Loss:  0.11069831\n",
      "Epoch:  528\n",
      "Training Loss:  0.11471693\n",
      "Validation Loss:  0.10959404\n",
      "Epoch:  529\n",
      "Training Loss:  0.113641955\n",
      "Validation Loss:  0.1104712\n",
      "Epoch:  530\n",
      "Training Loss:  0.11415876\n",
      "Validation Loss:  0.11105061\n",
      "Epoch:  531\n",
      "Training Loss:  0.11491758\n",
      "Validation Loss:  0.11178347\n",
      "Epoch:  532\n",
      "Training Loss:  0.114022896\n",
      "Validation Loss:  0.11221382\n",
      "Epoch:  533\n",
      "Training Loss:  0.11238676\n",
      "Validation Loss:  0.106286906\n",
      "Epoch:  534\n",
      "Training Loss:  0.113027595\n",
      "Validation Loss:  0.10795627\n",
      "Epoch:  535\n",
      "Training Loss:  0.112929285\n",
      "Validation Loss:  0.110461324\n",
      "Epoch:  536\n",
      "Training Loss:  0.112941824\n",
      "Validation Loss:  0.110624306\n",
      "Epoch:  537\n",
      "Training Loss:  0.112530656\n",
      "Validation Loss:  0.10672551\n",
      "Epoch:  538\n",
      "Training Loss:  0.11106767\n",
      "Validation Loss:  0.107295446\n",
      "Epoch:  539\n",
      "Training Loss:  0.1127072\n",
      "Validation Loss:  0.107216835\n",
      "Epoch:  540\n",
      "Training Loss:  0.11189942\n",
      "Validation Loss:  0.11165061\n",
      "Epoch:  541\n",
      "Training Loss:  0.111212306\n",
      "Validation Loss:  0.109650314\n",
      "Epoch:  542\n",
      "Training Loss:  0.111854106\n",
      "Validation Loss:  0.10791257\n",
      "Epoch:  543\n",
      "Training Loss:  0.110801935\n",
      "Validation Loss:  0.10971424\n",
      "Epoch:  544\n",
      "Training Loss:  0.110784695\n",
      "Validation Loss:  0.10806423\n",
      "Epoch:  545\n",
      "Training Loss:  0.112355806\n",
      "Validation Loss:  0.10663196\n",
      "Epoch:  546\n",
      "Training Loss:  0.110695705\n",
      "Validation Loss:  0.10605052\n",
      "Epoch:  547\n",
      "Training Loss:  0.11042724\n",
      "Validation Loss:  0.10939237\n",
      "Epoch:  548\n",
      "Training Loss:  0.11008107\n",
      "Validation Loss:  0.10488006\n",
      "Epoch:  549\n",
      "Training Loss:  0.10946689\n",
      "Validation Loss:  0.109820485\n",
      "Epoch:  550\n",
      "Training Loss:  0.10845299\n",
      "Validation Loss:  0.10764003\n",
      "Epoch:  551\n",
      "Training Loss:  0.110405676\n",
      "Validation Loss:  0.10442669\n",
      "Epoch:  552\n",
      "Training Loss:  0.108044416\n",
      "Validation Loss:  0.10494941\n",
      "Epoch:  553\n",
      "Training Loss:  0.10845489\n",
      "Validation Loss:  0.10546196\n",
      "Epoch:  554\n",
      "Training Loss:  0.10880955\n",
      "Validation Loss:  0.10899785\n",
      "Epoch:  555\n",
      "Training Loss:  0.10727706\n",
      "Validation Loss:  0.10354763\n",
      "Epoch:  556\n",
      "Training Loss:  0.1081944\n",
      "Validation Loss:  0.107895285\n",
      "Epoch:  557\n",
      "Training Loss:  0.10837756\n",
      "Validation Loss:  0.10739363\n",
      "Epoch:  558\n",
      "Training Loss:  0.10811891\n",
      "Validation Loss:  0.10503977\n",
      "Epoch:  559\n",
      "Training Loss:  0.10776125\n",
      "Validation Loss:  0.10407493\n",
      "Epoch:  560\n",
      "Training Loss:  0.109678276\n",
      "Validation Loss:  0.10214922\n",
      "Epoch:  561\n",
      "Training Loss:  0.106497265\n",
      "Validation Loss:  0.10442529\n",
      "Epoch:  562\n",
      "Training Loss:  0.106006466\n",
      "Validation Loss:  0.10441638\n",
      "Epoch:  563\n",
      "Training Loss:  0.10746008\n",
      "Validation Loss:  0.10928831\n",
      "Epoch:  564\n",
      "Training Loss:  0.10601762\n",
      "Validation Loss:  0.10591403\n",
      "Epoch:  565\n",
      "Training Loss:  0.107055485\n",
      "Validation Loss:  0.10236102\n",
      "Epoch:  566\n",
      "Training Loss:  0.10695569\n",
      "Validation Loss:  0.101763725\n",
      "Epoch:  567\n",
      "Training Loss:  0.10600447\n",
      "Validation Loss:  0.10529151\n",
      "Epoch:  568\n",
      "Training Loss:  0.105083816\n",
      "Validation Loss:  0.104499616\n",
      "Epoch:  569\n",
      "Training Loss:  0.10720337\n",
      "Validation Loss:  0.10655827\n",
      "Epoch:  570\n",
      "Training Loss:  0.10642004\n",
      "Validation Loss:  0.10582914\n",
      "Epoch:  571\n",
      "Training Loss:  0.10640743\n",
      "Validation Loss:  0.10433488\n",
      "Epoch:  572\n",
      "Training Loss:  0.105867006\n",
      "Validation Loss:  0.10210226\n",
      "Epoch:  573\n",
      "Training Loss:  0.10401683\n",
      "Validation Loss:  0.09967808\n",
      "Epoch:  574\n",
      "Training Loss:  0.105161\n",
      "Validation Loss:  0.09975588\n",
      "Epoch:  575\n",
      "Training Loss:  0.10463098\n",
      "Validation Loss:  0.100557566\n",
      "Epoch:  576\n",
      "Training Loss:  0.103536524\n",
      "Validation Loss:  0.110459946\n",
      "Epoch:  577\n",
      "Training Loss:  0.10431343\n",
      "Validation Loss:  0.10116923\n",
      "Epoch:  578\n",
      "Training Loss:  0.10191104\n",
      "Validation Loss:  0.10089165\n",
      "Epoch:  579\n",
      "Training Loss:  0.10340446\n",
      "Validation Loss:  0.10066783\n",
      "Epoch:  580\n",
      "Training Loss:  0.10540827\n",
      "Validation Loss:  0.10225143\n",
      "Epoch:  581\n",
      "Training Loss:  0.10312187\n",
      "Validation Loss:  0.10220473\n",
      "Epoch:  582\n",
      "Training Loss:  0.10433269\n",
      "Validation Loss:  0.1016512\n",
      "Epoch:  583\n",
      "Training Loss:  0.10206485\n",
      "Validation Loss:  0.097039126\n",
      "Epoch:  584\n",
      "Training Loss:  0.10124039\n",
      "Validation Loss:  0.10033811\n",
      "Epoch:  585\n",
      "Training Loss:  0.10245409\n",
      "Validation Loss:  0.10206946\n",
      "Epoch:  586\n",
      "Training Loss:  0.10272489\n",
      "Validation Loss:  0.10154442\n",
      "Epoch:  587\n",
      "Training Loss:  0.1027639\n",
      "Validation Loss:  0.097730756\n",
      "Epoch:  588\n",
      "Training Loss:  0.10098206\n",
      "Validation Loss:  0.09618434\n",
      "Epoch:  589\n",
      "Training Loss:  0.10109458\n",
      "Validation Loss:  0.10178018\n",
      "Epoch:  590\n",
      "Training Loss:  0.102193736\n",
      "Validation Loss:  0.096425325\n",
      "Epoch:  591\n",
      "Training Loss:  0.10073794\n",
      "Validation Loss:  0.09539271\n",
      "Epoch:  592\n",
      "Training Loss:  0.10132822\n",
      "Validation Loss:  0.09896503\n",
      "Epoch:  593\n",
      "Training Loss:  0.10116837\n",
      "Validation Loss:  0.09734639\n",
      "Epoch:  594\n",
      "Training Loss:  0.10099276\n",
      "Validation Loss:  0.09299847\n",
      "Epoch:  595\n",
      "Training Loss:  0.099542916\n",
      "Validation Loss:  0.096414365\n",
      "Epoch:  596\n",
      "Training Loss:  0.10065597\n",
      "Validation Loss:  0.101365924\n",
      "Epoch:  597\n",
      "Training Loss:  0.09892386\n",
      "Validation Loss:  0.09683605\n",
      "Epoch:  598\n",
      "Training Loss:  0.10171373\n",
      "Validation Loss:  0.098080866\n",
      "Epoch:  599\n",
      "Training Loss:  0.10045658\n",
      "Validation Loss:  0.09755361\n",
      "Epoch:  600\n",
      "Training Loss:  0.099282525\n",
      "Validation Loss:  0.09790552\n",
      "Epoch:  601\n",
      "Training Loss:  0.10072704\n",
      "Validation Loss:  0.09872908\n",
      "Epoch:  602\n",
      "Training Loss:  0.09797373\n",
      "Validation Loss:  0.09738943\n",
      "Epoch:  603\n",
      "Training Loss:  0.09910118\n",
      "Validation Loss:  0.09499084\n",
      "Epoch:  604\n",
      "Training Loss:  0.099888094\n",
      "Validation Loss:  0.09682703\n",
      "Epoch:  605\n",
      "Training Loss:  0.09924595\n",
      "Validation Loss:  0.09495605\n",
      "Epoch:  606\n",
      "Training Loss:  0.099779904\n",
      "Validation Loss:  0.09568581\n",
      "Epoch:  607\n",
      "Training Loss:  0.09919771\n",
      "Validation Loss:  0.09686923\n",
      "Epoch:  608\n",
      "Training Loss:  0.099611074\n",
      "Validation Loss:  0.094559394\n",
      "Epoch:  609\n",
      "Training Loss:  0.0977074\n",
      "Validation Loss:  0.0959138\n",
      "Epoch:  610\n",
      "Training Loss:  0.09823367\n",
      "Validation Loss:  0.09268213\n",
      "Epoch:  611\n",
      "Training Loss:  0.09810363\n",
      "Validation Loss:  0.0955424\n",
      "Epoch:  612\n",
      "Training Loss:  0.09762766\n",
      "Validation Loss:  0.09374821\n",
      "Epoch:  613\n",
      "Training Loss:  0.09887709\n",
      "Validation Loss:  0.097066276\n",
      "Epoch:  614\n",
      "Training Loss:  0.09854031\n",
      "Validation Loss:  0.095808856\n",
      "Epoch:  615\n",
      "Training Loss:  0.09721308\n",
      "Validation Loss:  0.09366622\n",
      "Epoch:  616\n",
      "Training Loss:  0.096459754\n",
      "Validation Loss:  0.089586996\n",
      "Epoch:  617\n",
      "Training Loss:  0.0956419\n",
      "Validation Loss:  0.09183851\n",
      "Epoch:  618\n",
      "Training Loss:  0.09639782\n",
      "Validation Loss:  0.09282094\n",
      "Epoch:  619\n",
      "Training Loss:  0.09635963\n",
      "Validation Loss:  0.09229669\n",
      "Epoch:  620\n",
      "Training Loss:  0.09628425\n",
      "Validation Loss:  0.09557816\n",
      "Epoch:  621\n",
      "Training Loss:  0.097091176\n",
      "Validation Loss:  0.093838654\n",
      "Epoch:  622\n",
      "Training Loss:  0.09662314\n",
      "Validation Loss:  0.09730065\n",
      "Epoch:  623\n",
      "Training Loss:  0.09636892\n",
      "Validation Loss:  0.09688035\n",
      "Epoch:  624\n",
      "Training Loss:  0.09532383\n",
      "Validation Loss:  0.092146195\n",
      "Epoch:  625\n",
      "Training Loss:  0.09489869\n",
      "Validation Loss:  0.094270326\n",
      "Epoch:  626\n",
      "Training Loss:  0.09423752\n",
      "Validation Loss:  0.09684967\n",
      "Epoch:  627\n",
      "Training Loss:  0.09468675\n",
      "Validation Loss:  0.09354815\n",
      "Epoch:  628\n",
      "Training Loss:  0.09486411\n",
      "Validation Loss:  0.09421236\n",
      "Epoch:  629\n",
      "Training Loss:  0.09554219\n",
      "Validation Loss:  0.09016038\n",
      "Epoch:  630\n",
      "Training Loss:  0.093844116\n",
      "Validation Loss:  0.09299449\n",
      "Epoch:  631\n",
      "Training Loss:  0.09416517\n",
      "Validation Loss:  0.09264245\n",
      "Epoch:  632\n",
      "Training Loss:  0.094299525\n",
      "Validation Loss:  0.09315393\n",
      "Epoch:  633\n",
      "Training Loss:  0.09324279\n",
      "Validation Loss:  0.08901692\n",
      "Epoch:  634\n",
      "Training Loss:  0.09376126\n",
      "Validation Loss:  0.09129637\n",
      "Epoch:  635\n",
      "Training Loss:  0.09339035\n",
      "Validation Loss:  0.09014543\n",
      "Epoch:  636\n",
      "Training Loss:  0.09337164\n",
      "Validation Loss:  0.092907675\n",
      "Epoch:  637\n",
      "Training Loss:  0.09092206\n",
      "Validation Loss:  0.087122835\n",
      "Epoch:  638\n",
      "Training Loss:  0.093820415\n",
      "Validation Loss:  0.09095172\n",
      "Epoch:  639\n",
      "Training Loss:  0.09273677\n",
      "Validation Loss:  0.097170584\n",
      "Epoch:  640\n",
      "Training Loss:  0.09278231\n",
      "Validation Loss:  0.09231443\n",
      "Epoch:  641\n",
      "Training Loss:  0.09344984\n",
      "Validation Loss:  0.087213315\n",
      "Epoch:  642\n",
      "Training Loss:  0.09393983\n",
      "Validation Loss:  0.09048244\n",
      "Epoch:  643\n",
      "Training Loss:  0.092723906\n",
      "Validation Loss:  0.087619536\n",
      "Epoch:  644\n",
      "Training Loss:  0.09345415\n",
      "Validation Loss:  0.08872036\n",
      "Epoch:  645\n",
      "Training Loss:  0.09050023\n",
      "Validation Loss:  0.0886546\n",
      "Epoch:  646\n",
      "Training Loss:  0.09048928\n",
      "Validation Loss:  0.0879909\n",
      "Epoch:  647\n",
      "Training Loss:  0.09172732\n",
      "Validation Loss:  0.0895828\n",
      "Epoch:  648\n",
      "Training Loss:  0.092491485\n",
      "Validation Loss:  0.090224855\n",
      "Epoch:  649\n",
      "Training Loss:  0.09260831\n",
      "Validation Loss:  0.08989817\n",
      "Epoch:  650\n",
      "Training Loss:  0.090195954\n",
      "Validation Loss:  0.0919017\n",
      "Epoch:  651\n",
      "Training Loss:  0.09219472\n",
      "Validation Loss:  0.09035238\n",
      "Epoch:  652\n",
      "Training Loss:  0.090981595\n",
      "Validation Loss:  0.087548435\n",
      "Epoch:  653\n",
      "Training Loss:  0.08949974\n",
      "Validation Loss:  0.0899703\n",
      "Epoch:  654\n",
      "Training Loss:  0.089357644\n",
      "Validation Loss:  0.08661506\n",
      "Epoch:  655\n",
      "Training Loss:  0.089790605\n",
      "Validation Loss:  0.09032624\n",
      "Epoch:  656\n",
      "Training Loss:  0.08965956\n",
      "Validation Loss:  0.09088757\n",
      "Epoch:  657\n",
      "Training Loss:  0.09038663\n",
      "Validation Loss:  0.091292955\n",
      "Epoch:  658\n",
      "Training Loss:  0.08863651\n",
      "Validation Loss:  0.095386915\n",
      "Epoch:  659\n",
      "Training Loss:  0.08874492\n",
      "Validation Loss:  0.08827785\n",
      "Epoch:  660\n",
      "Training Loss:  0.08887868\n",
      "Validation Loss:  0.08980415\n",
      "Epoch:  661\n",
      "Training Loss:  0.088763334\n",
      "Validation Loss:  0.08583322\n",
      "Epoch:  662\n",
      "Training Loss:  0.089584745\n",
      "Validation Loss:  0.08507981\n",
      "Epoch:  663\n",
      "Training Loss:  0.088834025\n",
      "Validation Loss:  0.08683175\n",
      "Epoch:  664\n",
      "Training Loss:  0.08756025\n",
      "Validation Loss:  0.08186687\n",
      "Epoch:  665\n",
      "Training Loss:  0.08893925\n",
      "Validation Loss:  0.085879266\n",
      "Epoch:  666\n",
      "Training Loss:  0.089020275\n",
      "Validation Loss:  0.08564905\n",
      "Epoch:  667\n",
      "Training Loss:  0.089252576\n",
      "Validation Loss:  0.08779392\n",
      "Epoch:  668\n",
      "Training Loss:  0.08944078\n",
      "Validation Loss:  0.08382217\n",
      "Epoch:  669\n",
      "Training Loss:  0.087377466\n",
      "Validation Loss:  0.085689135\n",
      "Epoch:  670\n",
      "Training Loss:  0.08734396\n",
      "Validation Loss:  0.08580872\n",
      "Epoch:  671\n",
      "Training Loss:  0.087216355\n",
      "Validation Loss:  0.08557385\n",
      "Epoch:  672\n",
      "Training Loss:  0.087725446\n",
      "Validation Loss:  0.084784664\n",
      "Epoch:  673\n",
      "Training Loss:  0.0871093\n",
      "Validation Loss:  0.08623999\n",
      "Epoch:  674\n",
      "Training Loss:  0.08718684\n",
      "Validation Loss:  0.09008437\n",
      "Epoch:  675\n",
      "Training Loss:  0.086721346\n",
      "Validation Loss:  0.08515817\n",
      "Epoch:  676\n",
      "Training Loss:  0.085404254\n",
      "Validation Loss:  0.08212291\n",
      "Epoch:  677\n",
      "Training Loss:  0.08646232\n",
      "Validation Loss:  0.08622855\n",
      "Epoch:  678\n",
      "Training Loss:  0.08656203\n",
      "Validation Loss:  0.0856139\n",
      "Epoch:  679\n",
      "Training Loss:  0.08649979\n",
      "Validation Loss:  0.08319289\n",
      "Epoch:  680\n",
      "Training Loss:  0.08599747\n",
      "Validation Loss:  0.08272843\n",
      "Epoch:  681\n",
      "Training Loss:  0.08663938\n",
      "Validation Loss:  0.08154752\n",
      "Epoch:  682\n",
      "Training Loss:  0.08599322\n",
      "Validation Loss:  0.081943505\n",
      "Epoch:  683\n",
      "Training Loss:  0.086339206\n",
      "Validation Loss:  0.082314126\n",
      "Epoch:  684\n",
      "Training Loss:  0.086610176\n",
      "Validation Loss:  0.08713605\n",
      "Epoch:  685\n",
      "Training Loss:  0.08542939\n",
      "Validation Loss:  0.08192582\n",
      "Epoch:  686\n",
      "Training Loss:  0.085505426\n",
      "Validation Loss:  0.08010583\n",
      "Epoch:  687\n",
      "Training Loss:  0.08592881\n",
      "Validation Loss:  0.0800686\n",
      "Epoch:  688\n",
      "Training Loss:  0.084281065\n",
      "Validation Loss:  0.07787656\n",
      "Epoch:  689\n",
      "Training Loss:  0.08447396\n",
      "Validation Loss:  0.07849341\n",
      "Epoch:  690\n",
      "Training Loss:  0.084109806\n",
      "Validation Loss:  0.08287612\n",
      "Epoch:  691\n",
      "Training Loss:  0.084382504\n",
      "Validation Loss:  0.08423141\n",
      "Epoch:  692\n",
      "Training Loss:  0.0827169\n",
      "Validation Loss:  0.082310505\n",
      "Epoch:  693\n",
      "Training Loss:  0.08333325\n",
      "Validation Loss:  0.07888114\n",
      "Epoch:  694\n",
      "Training Loss:  0.08370988\n",
      "Validation Loss:  0.082080334\n",
      "Epoch:  695\n",
      "Training Loss:  0.083004385\n",
      "Validation Loss:  0.0814688\n",
      "Epoch:  696\n",
      "Training Loss:  0.084710926\n",
      "Validation Loss:  0.083061524\n",
      "Epoch:  697\n",
      "Training Loss:  0.08413304\n",
      "Validation Loss:  0.07947933\n",
      "Epoch:  698\n",
      "Training Loss:  0.08426056\n",
      "Validation Loss:  0.08406887\n",
      "Epoch:  699\n",
      "Training Loss:  0.08352883\n",
      "Validation Loss:  0.079016306\n",
      "Epoch:  700\n",
      "Training Loss:  0.083527915\n",
      "Validation Loss:  0.07477743\n",
      "Epoch:  701\n",
      "Training Loss:  0.08307799\n",
      "Validation Loss:  0.077534534\n",
      "Epoch:  702\n",
      "Training Loss:  0.082251646\n",
      "Validation Loss:  0.07607377\n",
      "Epoch:  703\n",
      "Training Loss:  0.08265668\n",
      "Validation Loss:  0.08141804\n",
      "Epoch:  704\n",
      "Training Loss:  0.08160906\n",
      "Validation Loss:  0.07837729\n",
      "Epoch:  705\n",
      "Training Loss:  0.0808134\n",
      "Validation Loss:  0.08173679\n",
      "Epoch:  706\n",
      "Training Loss:  0.082660474\n",
      "Validation Loss:  0.07572257\n",
      "Epoch:  707\n",
      "Training Loss:  0.08176203\n",
      "Validation Loss:  0.077982806\n",
      "Epoch:  708\n",
      "Training Loss:  0.08153467\n",
      "Validation Loss:  0.07947085\n",
      "Epoch:  709\n",
      "Training Loss:  0.082883805\n",
      "Validation Loss:  0.0799671\n",
      "Epoch:  710\n",
      "Training Loss:  0.08040436\n",
      "Validation Loss:  0.079396844\n",
      "Epoch:  711\n",
      "Training Loss:  0.08127406\n",
      "Validation Loss:  0.07987077\n",
      "Epoch:  712\n",
      "Training Loss:  0.08066108\n",
      "Validation Loss:  0.07819089\n",
      "Epoch:  713\n",
      "Training Loss:  0.08132312\n",
      "Validation Loss:  0.078641675\n",
      "Epoch:  714\n",
      "Training Loss:  0.08065699\n",
      "Validation Loss:  0.07485246\n",
      "Epoch:  715\n",
      "Training Loss:  0.07931441\n",
      "Validation Loss:  0.08070388\n",
      "Epoch:  716\n",
      "Training Loss:  0.080635\n",
      "Validation Loss:  0.0759607\n",
      "Epoch:  717\n",
      "Training Loss:  0.079978056\n",
      "Validation Loss:  0.074394815\n",
      "Epoch:  718\n",
      "Training Loss:  0.080249324\n",
      "Validation Loss:  0.07873205\n",
      "Epoch:  719\n",
      "Training Loss:  0.07964365\n",
      "Validation Loss:  0.07743364\n",
      "Epoch:  720\n",
      "Training Loss:  0.0803026\n",
      "Validation Loss:  0.07702715\n",
      "Epoch:  721\n",
      "Training Loss:  0.07967782\n",
      "Validation Loss:  0.07770311\n",
      "Epoch:  722\n",
      "Training Loss:  0.07994941\n",
      "Validation Loss:  0.07593908\n",
      "Epoch:  723\n",
      "Training Loss:  0.07994539\n",
      "Validation Loss:  0.07654133\n",
      "Epoch:  724\n",
      "Training Loss:  0.07906343\n",
      "Validation Loss:  0.07589122\n",
      "Epoch:  725\n",
      "Training Loss:  0.07958873\n",
      "Validation Loss:  0.07802399\n",
      "Epoch:  726\n",
      "Training Loss:  0.08044846\n",
      "Validation Loss:  0.07256287\n",
      "Epoch:  727\n",
      "Training Loss:  0.079904936\n",
      "Validation Loss:  0.077865444\n",
      "Epoch:  728\n",
      "Training Loss:  0.07954586\n",
      "Validation Loss:  0.07249587\n",
      "Epoch:  729\n",
      "Training Loss:  0.07885887\n",
      "Validation Loss:  0.07908297\n",
      "Epoch:  730\n",
      "Training Loss:  0.07873268\n",
      "Validation Loss:  0.07436057\n",
      "Epoch:  731\n",
      "Training Loss:  0.07846521\n",
      "Validation Loss:  0.08122267\n",
      "Epoch:  732\n",
      "Training Loss:  0.07749576\n",
      "Validation Loss:  0.07413606\n",
      "Epoch:  733\n",
      "Training Loss:  0.07744885\n",
      "Validation Loss:  0.07334896\n",
      "Epoch:  734\n",
      "Training Loss:  0.077079594\n",
      "Validation Loss:  0.075882405\n",
      "Epoch:  735\n",
      "Training Loss:  0.077692054\n",
      "Validation Loss:  0.0756749\n",
      "Epoch:  736\n",
      "Training Loss:  0.07790709\n",
      "Validation Loss:  0.07678982\n",
      "Epoch:  737\n",
      "Training Loss:  0.077291034\n",
      "Validation Loss:  0.074395455\n",
      "Epoch:  738\n",
      "Training Loss:  0.077600926\n",
      "Validation Loss:  0.07781851\n",
      "Epoch:  739\n",
      "Training Loss:  0.07834847\n",
      "Validation Loss:  0.07778494\n",
      "Epoch:  740\n",
      "Training Loss:  0.07684115\n",
      "Validation Loss:  0.07337002\n",
      "Epoch:  741\n",
      "Training Loss:  0.075557604\n",
      "Validation Loss:  0.07620276\n",
      "Epoch:  742\n",
      "Training Loss:  0.07600213\n",
      "Validation Loss:  0.07325385\n",
      "Epoch:  743\n",
      "Training Loss:  0.07593047\n",
      "Validation Loss:  0.07538157\n",
      "Epoch:  744\n",
      "Training Loss:  0.07851344\n",
      "Validation Loss:  0.07481688\n",
      "Epoch:  745\n",
      "Training Loss:  0.07662042\n",
      "Validation Loss:  0.07084868\n",
      "Epoch:  746\n",
      "Training Loss:  0.07528041\n",
      "Validation Loss:  0.078318305\n",
      "Epoch:  747\n",
      "Training Loss:  0.07643648\n",
      "Validation Loss:  0.074563794\n",
      "Epoch:  748\n",
      "Training Loss:  0.076013625\n",
      "Validation Loss:  0.07879545\n",
      "Epoch:  749\n",
      "Training Loss:  0.07428753\n",
      "Validation Loss:  0.07428011\n",
      "Epoch:  750\n",
      "Training Loss:  0.076126635\n",
      "Validation Loss:  0.07310443\n",
      "Epoch:  751\n",
      "Training Loss:  0.07447512\n",
      "Validation Loss:  0.073443815\n",
      "Epoch:  752\n",
      "Training Loss:  0.07502317\n",
      "Validation Loss:  0.068503134\n",
      "Epoch:  753\n",
      "Training Loss:  0.07388661\n",
      "Validation Loss:  0.07094536\n",
      "Epoch:  754\n",
      "Training Loss:  0.07607927\n",
      "Validation Loss:  0.07508928\n",
      "Epoch:  755\n",
      "Training Loss:  0.07470004\n",
      "Validation Loss:  0.070206456\n",
      "Epoch:  756\n",
      "Training Loss:  0.07383853\n",
      "Validation Loss:  0.07362912\n",
      "Epoch:  757\n",
      "Training Loss:  0.07407452\n",
      "Validation Loss:  0.078076385\n",
      "Epoch:  758\n",
      "Training Loss:  0.07479944\n",
      "Validation Loss:  0.07014524\n",
      "Epoch:  759\n",
      "Training Loss:  0.074016996\n",
      "Validation Loss:  0.07279537\n",
      "Epoch:  760\n",
      "Training Loss:  0.07449854\n",
      "Validation Loss:  0.07164781\n",
      "Epoch:  761\n",
      "Training Loss:  0.07450061\n",
      "Validation Loss:  0.071961746\n",
      "Epoch:  762\n",
      "Training Loss:  0.073767506\n",
      "Validation Loss:  0.07255294\n",
      "Epoch:  763\n",
      "Training Loss:  0.07436099\n",
      "Validation Loss:  0.073018745\n",
      "Epoch:  764\n",
      "Training Loss:  0.07294792\n",
      "Validation Loss:  0.07114146\n",
      "Epoch:  765\n",
      "Training Loss:  0.072505176\n",
      "Validation Loss:  0.07031574\n",
      "Epoch:  766\n",
      "Training Loss:  0.073690355\n",
      "Validation Loss:  0.06807209\n",
      "Epoch:  767\n",
      "Training Loss:  0.07392071\n",
      "Validation Loss:  0.07052097\n",
      "Epoch:  768\n",
      "Training Loss:  0.07393731\n",
      "Validation Loss:  0.07199725\n",
      "Epoch:  769\n",
      "Training Loss:  0.072939694\n",
      "Validation Loss:  0.07404758\n",
      "Epoch:  770\n",
      "Training Loss:  0.072364256\n",
      "Validation Loss:  0.06686168\n",
      "Epoch:  771\n",
      "Training Loss:  0.07422707\n",
      "Validation Loss:  0.06906515\n",
      "Epoch:  772\n",
      "Training Loss:  0.0730926\n",
      "Validation Loss:  0.06794806\n",
      "Epoch:  773\n",
      "Training Loss:  0.072501555\n",
      "Validation Loss:  0.07419615\n",
      "Epoch:  774\n",
      "Training Loss:  0.0731368\n",
      "Validation Loss:  0.06809741\n",
      "Epoch:  775\n",
      "Training Loss:  0.0710638\n",
      "Validation Loss:  0.06921735\n",
      "Epoch:  776\n",
      "Training Loss:  0.07201317\n",
      "Validation Loss:  0.072795935\n",
      "Epoch:  777\n",
      "Training Loss:  0.07319664\n",
      "Validation Loss:  0.06647435\n",
      "Epoch:  778\n",
      "Training Loss:  0.07250469\n",
      "Validation Loss:  0.0725629\n",
      "Epoch:  779\n",
      "Training Loss:  0.07153567\n",
      "Validation Loss:  0.07136737\n",
      "Epoch:  780\n",
      "Training Loss:  0.072926715\n",
      "Validation Loss:  0.070455715\n",
      "Epoch:  781\n",
      "Training Loss:  0.07096584\n",
      "Validation Loss:  0.068579845\n",
      "Epoch:  782\n",
      "Training Loss:  0.07155521\n",
      "Validation Loss:  0.066316284\n",
      "Epoch:  783\n",
      "Training Loss:  0.07022288\n",
      "Validation Loss:  0.070450805\n",
      "Epoch:  784\n",
      "Training Loss:  0.07083303\n",
      "Validation Loss:  0.07074213\n",
      "Epoch:  785\n",
      "Training Loss:  0.071857795\n",
      "Validation Loss:  0.068210594\n",
      "Epoch:  786\n",
      "Training Loss:  0.07125927\n",
      "Validation Loss:  0.069932394\n",
      "Epoch:  787\n",
      "Training Loss:  0.07088507\n",
      "Validation Loss:  0.063181676\n",
      "Epoch:  788\n",
      "Training Loss:  0.0701086\n",
      "Validation Loss:  0.06813202\n",
      "Epoch:  789\n",
      "Training Loss:  0.06893145\n",
      "Validation Loss:  0.06834309\n",
      "Epoch:  790\n",
      "Training Loss:  0.07074793\n",
      "Validation Loss:  0.06666697\n",
      "Epoch:  791\n",
      "Training Loss:  0.071032636\n",
      "Validation Loss:  0.067680284\n",
      "Epoch:  792\n",
      "Training Loss:  0.07016199\n",
      "Validation Loss:  0.071709014\n",
      "Epoch:  793\n",
      "Training Loss:  0.06948699\n",
      "Validation Loss:  0.06578546\n",
      "Epoch:  794\n",
      "Training Loss:  0.06977127\n",
      "Validation Loss:  0.06981557\n",
      "Epoch:  795\n",
      "Training Loss:  0.06861233\n",
      "Validation Loss:  0.066863716\n",
      "Epoch:  796\n",
      "Training Loss:  0.06908738\n",
      "Validation Loss:  0.06662928\n",
      "Epoch:  797\n",
      "Training Loss:  0.06891384\n",
      "Validation Loss:  0.06354267\n",
      "Epoch:  798\n",
      "Training Loss:  0.069210455\n",
      "Validation Loss:  0.06815574\n",
      "Epoch:  799\n",
      "Training Loss:  0.069061734\n",
      "Validation Loss:  0.06334794\n",
      "Epoch:  800\n",
      "Training Loss:  0.068418786\n",
      "Validation Loss:  0.06502644\n",
      "Epoch:  801\n",
      "Training Loss:  0.067925155\n",
      "Validation Loss:  0.0665667\n",
      "Epoch:  802\n",
      "Training Loss:  0.06859385\n",
      "Validation Loss:  0.06688107\n",
      "Epoch:  803\n",
      "Training Loss:  0.06860494\n",
      "Validation Loss:  0.06354329\n",
      "Epoch:  804\n",
      "Training Loss:  0.06891205\n",
      "Validation Loss:  0.06510054\n",
      "Epoch:  805\n",
      "Training Loss:  0.06813643\n",
      "Validation Loss:  0.06332494\n",
      "Epoch:  806\n",
      "Training Loss:  0.0684347\n",
      "Validation Loss:  0.0669064\n",
      "Epoch:  807\n",
      "Training Loss:  0.067884386\n",
      "Validation Loss:  0.06591493\n",
      "Epoch:  808\n",
      "Training Loss:  0.06767861\n",
      "Validation Loss:  0.06351411\n",
      "Epoch:  809\n",
      "Training Loss:  0.06820694\n",
      "Validation Loss:  0.06669589\n",
      "Epoch:  810\n",
      "Training Loss:  0.06772458\n",
      "Validation Loss:  0.06858405\n",
      "Epoch:  811\n",
      "Training Loss:  0.06814497\n",
      "Validation Loss:  0.06446226\n",
      "Epoch:  812\n",
      "Training Loss:  0.06661647\n",
      "Validation Loss:  0.06836846\n",
      "Epoch:  813\n",
      "Training Loss:  0.0668097\n",
      "Validation Loss:  0.065103374\n",
      "Epoch:  814\n",
      "Training Loss:  0.067510985\n",
      "Validation Loss:  0.066627644\n",
      "Epoch:  815\n",
      "Training Loss:  0.06680196\n",
      "Validation Loss:  0.06401264\n",
      "Epoch:  816\n",
      "Training Loss:  0.06793108\n",
      "Validation Loss:  0.06379134\n",
      "Epoch:  817\n",
      "Training Loss:  0.0665653\n",
      "Validation Loss:  0.062988915\n",
      "Epoch:  818\n",
      "Training Loss:  0.0664431\n",
      "Validation Loss:  0.06367137\n",
      "Epoch:  819\n",
      "Training Loss:  0.06634221\n",
      "Validation Loss:  0.0643265\n",
      "Epoch:  820\n",
      "Training Loss:  0.06618724\n",
      "Validation Loss:  0.06408858\n",
      "Epoch:  821\n",
      "Training Loss:  0.06703354\n",
      "Validation Loss:  0.06312532\n",
      "Epoch:  822\n",
      "Training Loss:  0.065073445\n",
      "Validation Loss:  0.06500515\n",
      "Epoch:  823\n",
      "Training Loss:  0.06624558\n",
      "Validation Loss:  0.06270111\n",
      "Epoch:  824\n",
      "Training Loss:  0.06592861\n",
      "Validation Loss:  0.06532639\n",
      "Epoch:  825\n",
      "Training Loss:  0.06643785\n",
      "Validation Loss:  0.061248045\n",
      "Epoch:  826\n",
      "Training Loss:  0.06539529\n",
      "Validation Loss:  0.061125025\n",
      "Epoch:  827\n",
      "Training Loss:  0.06690447\n",
      "Validation Loss:  0.06661774\n",
      "Epoch:  828\n",
      "Training Loss:  0.06558798\n",
      "Validation Loss:  0.061609745\n",
      "Epoch:  829\n",
      "Training Loss:  0.06556187\n",
      "Validation Loss:  0.06799603\n",
      "Epoch:  830\n",
      "Training Loss:  0.06590397\n",
      "Validation Loss:  0.06096704\n",
      "Epoch:  831\n",
      "Training Loss:  0.066067964\n",
      "Validation Loss:  0.063369475\n",
      "Epoch:  832\n",
      "Training Loss:  0.06509597\n",
      "Validation Loss:  0.0645515\n",
      "Epoch:  833\n",
      "Training Loss:  0.06477033\n",
      "Validation Loss:  0.06527794\n",
      "Epoch:  834\n",
      "Training Loss:  0.06508095\n",
      "Validation Loss:  0.058941226\n",
      "Epoch:  835\n",
      "Training Loss:  0.06529422\n",
      "Validation Loss:  0.062157538\n",
      "Epoch:  836\n",
      "Training Loss:  0.06342492\n",
      "Validation Loss:  0.064549655\n",
      "Epoch:  837\n",
      "Training Loss:  0.06596961\n",
      "Validation Loss:  0.060959507\n",
      "Epoch:  838\n",
      "Training Loss:  0.06406969\n",
      "Validation Loss:  0.05940981\n",
      "Epoch:  839\n",
      "Training Loss:  0.06344157\n",
      "Validation Loss:  0.061552793\n",
      "Epoch:  840\n",
      "Training Loss:  0.06371583\n",
      "Validation Loss:  0.0594447\n",
      "Epoch:  841\n",
      "Training Loss:  0.063557036\n",
      "Validation Loss:  0.061952073\n",
      "Epoch:  842\n",
      "Training Loss:  0.06483763\n",
      "Validation Loss:  0.06158419\n",
      "Epoch:  843\n",
      "Training Loss:  0.06478884\n",
      "Validation Loss:  0.06085876\n",
      "Epoch:  844\n",
      "Training Loss:  0.06461282\n",
      "Validation Loss:  0.060709506\n",
      "Epoch:  845\n",
      "Training Loss:  0.06321549\n",
      "Validation Loss:  0.05962449\n",
      "Epoch:  846\n",
      "Training Loss:  0.06310461\n",
      "Validation Loss:  0.059517235\n",
      "Epoch:  847\n",
      "Training Loss:  0.0638175\n",
      "Validation Loss:  0.06049304\n",
      "Epoch:  848\n",
      "Training Loss:  0.06344453\n",
      "Validation Loss:  0.06367067\n",
      "Epoch:  849\n",
      "Training Loss:  0.06454856\n",
      "Validation Loss:  0.06574503\n",
      "Epoch:  850\n",
      "Training Loss:  0.06354803\n",
      "Validation Loss:  0.06261518\n",
      "Epoch:  851\n",
      "Training Loss:  0.06329998\n",
      "Validation Loss:  0.059098784\n",
      "Epoch:  852\n",
      "Training Loss:  0.0622257\n",
      "Validation Loss:  0.06332957\n",
      "Epoch:  853\n",
      "Training Loss:  0.06293187\n",
      "Validation Loss:  0.056390118\n",
      "Epoch:  854\n",
      "Training Loss:  0.062536485\n",
      "Validation Loss:  0.057387367\n",
      "Epoch:  855\n",
      "Training Loss:  0.0627051\n",
      "Validation Loss:  0.05992763\n",
      "Epoch:  856\n",
      "Training Loss:  0.061853174\n",
      "Validation Loss:  0.058197226\n",
      "Epoch:  857\n",
      "Training Loss:  0.061484147\n",
      "Validation Loss:  0.06223117\n",
      "Epoch:  858\n",
      "Training Loss:  0.062307976\n",
      "Validation Loss:  0.059750125\n",
      "Epoch:  859\n",
      "Training Loss:  0.06169494\n",
      "Validation Loss:  0.056621943\n",
      "Epoch:  860\n",
      "Training Loss:  0.06201022\n",
      "Validation Loss:  0.05733922\n",
      "Epoch:  861\n",
      "Training Loss:  0.061707154\n",
      "Validation Loss:  0.055000376\n",
      "Epoch:  862\n",
      "Training Loss:  0.061836384\n",
      "Validation Loss:  0.058244508\n",
      "Epoch:  863\n",
      "Training Loss:  0.0621106\n",
      "Validation Loss:  0.05683032\n",
      "Epoch:  864\n",
      "Training Loss:  0.062117215\n",
      "Validation Loss:  0.05901886\n",
      "Epoch:  865\n",
      "Training Loss:  0.061412532\n",
      "Validation Loss:  0.05818574\n",
      "Epoch:  866\n",
      "Training Loss:  0.0615317\n",
      "Validation Loss:  0.063043706\n",
      "Epoch:  867\n",
      "Training Loss:  0.06165723\n",
      "Validation Loss:  0.060687184\n",
      "Epoch:  868\n",
      "Training Loss:  0.06138342\n",
      "Validation Loss:  0.061979163\n",
      "Epoch:  869\n",
      "Training Loss:  0.061033275\n",
      "Validation Loss:  0.059959847\n",
      "Epoch:  870\n",
      "Training Loss:  0.059417807\n",
      "Validation Loss:  0.060483653\n",
      "Epoch:  871\n",
      "Training Loss:  0.05959375\n",
      "Validation Loss:  0.061644245\n",
      "Epoch:  872\n",
      "Training Loss:  0.06099591\n",
      "Validation Loss:  0.055324826\n",
      "Epoch:  873\n",
      "Training Loss:  0.062077455\n",
      "Validation Loss:  0.05767216\n",
      "Epoch:  874\n",
      "Training Loss:  0.060392868\n",
      "Validation Loss:  0.05894314\n",
      "Epoch:  875\n",
      "Training Loss:  0.06135782\n",
      "Validation Loss:  0.05569288\n",
      "Epoch:  876\n",
      "Training Loss:  0.060103536\n",
      "Validation Loss:  0.0579081\n",
      "Epoch:  877\n",
      "Training Loss:  0.060071856\n",
      "Validation Loss:  0.054755975\n",
      "Epoch:  878\n",
      "Training Loss:  0.060988825\n",
      "Validation Loss:  0.05986627\n",
      "Epoch:  879\n",
      "Training Loss:  0.060180757\n",
      "Validation Loss:  0.056415424\n",
      "Epoch:  880\n",
      "Training Loss:  0.060355335\n",
      "Validation Loss:  0.057914045\n",
      "Epoch:  881\n",
      "Training Loss:  0.058454618\n",
      "Validation Loss:  0.055256303\n",
      "Epoch:  882\n",
      "Training Loss:  0.060206294\n",
      "Validation Loss:  0.06472954\n",
      "Epoch:  883\n",
      "Training Loss:  0.0592567\n",
      "Validation Loss:  0.05826613\n",
      "Epoch:  884\n",
      "Training Loss:  0.060044304\n",
      "Validation Loss:  0.062084388\n",
      "Epoch:  885\n",
      "Training Loss:  0.05783877\n",
      "Validation Loss:  0.055729117\n",
      "Epoch:  886\n",
      "Training Loss:  0.058715977\n",
      "Validation Loss:  0.055694547\n",
      "Epoch:  887\n",
      "Training Loss:  0.059786238\n",
      "Validation Loss:  0.054978818\n",
      "Epoch:  888\n",
      "Training Loss:  0.059412573\n",
      "Validation Loss:  0.057502612\n",
      "Epoch:  889\n",
      "Training Loss:  0.058317266\n",
      "Validation Loss:  0.053756382\n",
      "Epoch:  890\n",
      "Training Loss:  0.059889577\n",
      "Validation Loss:  0.058462083\n",
      "Epoch:  891\n",
      "Training Loss:  0.05982871\n",
      "Validation Loss:  0.06240742\n",
      "Epoch:  892\n",
      "Training Loss:  0.06008538\n",
      "Validation Loss:  0.057438705\n",
      "Epoch:  893\n",
      "Training Loss:  0.05777386\n",
      "Validation Loss:  0.058768082\n",
      "Epoch:  894\n",
      "Training Loss:  0.056576885\n",
      "Validation Loss:  0.054249972\n",
      "Epoch:  895\n",
      "Training Loss:  0.058121856\n",
      "Validation Loss:  0.053975593\n",
      "Epoch:  896\n",
      "Training Loss:  0.057543844\n",
      "Validation Loss:  0.055306192\n",
      "Epoch:  897\n",
      "Training Loss:  0.0583924\n",
      "Validation Loss:  0.05592193\n",
      "Epoch:  898\n",
      "Training Loss:  0.057418358\n",
      "Validation Loss:  0.053026143\n",
      "Epoch:  899\n",
      "Training Loss:  0.058886673\n",
      "Validation Loss:  0.055402532\n",
      "Epoch:  900\n",
      "Training Loss:  0.057170045\n",
      "Validation Loss:  0.051468294\n",
      "Epoch:  901\n",
      "Training Loss:  0.056398522\n",
      "Validation Loss:  0.054516952\n",
      "Epoch:  902\n",
      "Training Loss:  0.058309883\n",
      "Validation Loss:  0.050870497\n",
      "Epoch:  903\n",
      "Training Loss:  0.05779779\n",
      "Validation Loss:  0.062563345\n",
      "Epoch:  904\n",
      "Training Loss:  0.05744996\n",
      "Validation Loss:  0.05800042\n",
      "Epoch:  905\n",
      "Training Loss:  0.056093562\n",
      "Validation Loss:  0.0550686\n",
      "Epoch:  906\n",
      "Training Loss:  0.057228357\n",
      "Validation Loss:  0.056394428\n",
      "Epoch:  907\n",
      "Training Loss:  0.057329655\n",
      "Validation Loss:  0.056903433\n",
      "Epoch:  908\n",
      "Training Loss:  0.057886798\n",
      "Validation Loss:  0.05284831\n",
      "Epoch:  909\n",
      "Training Loss:  0.056887046\n",
      "Validation Loss:  0.054099064\n",
      "Epoch:  910\n",
      "Training Loss:  0.05752427\n",
      "Validation Loss:  0.055327088\n",
      "Epoch:  911\n",
      "Training Loss:  0.05720822\n",
      "Validation Loss:  0.053388353\n",
      "Epoch:  912\n",
      "Training Loss:  0.05609952\n",
      "Validation Loss:  0.051936585\n",
      "Epoch:  913\n",
      "Training Loss:  0.05710736\n",
      "Validation Loss:  0.05008267\n",
      "Epoch:  914\n",
      "Training Loss:  0.056201037\n",
      "Validation Loss:  0.055132877\n",
      "Epoch:  915\n",
      "Training Loss:  0.055861376\n",
      "Validation Loss:  0.05211528\n",
      "Epoch:  916\n",
      "Training Loss:  0.056010656\n",
      "Validation Loss:  0.053006645\n",
      "Epoch:  917\n",
      "Training Loss:  0.05646768\n",
      "Validation Loss:  0.051018026\n",
      "Epoch:  918\n",
      "Training Loss:  0.05575935\n",
      "Validation Loss:  0.05197161\n",
      "Epoch:  919\n",
      "Training Loss:  0.0564237\n",
      "Validation Loss:  0.049831044\n",
      "Epoch:  920\n",
      "Training Loss:  0.055791613\n",
      "Validation Loss:  0.055329014\n",
      "Epoch:  921\n",
      "Training Loss:  0.055017885\n",
      "Validation Loss:  0.054195825\n",
      "Epoch:  922\n",
      "Training Loss:  0.05499971\n",
      "Validation Loss:  0.050731182\n",
      "Epoch:  923\n",
      "Training Loss:  0.056608982\n",
      "Validation Loss:  0.053829208\n",
      "Epoch:  924\n",
      "Training Loss:  0.056707844\n",
      "Validation Loss:  0.0507919\n",
      "Epoch:  925\n",
      "Training Loss:  0.055241134\n",
      "Validation Loss:  0.053512797\n",
      "Epoch:  926\n",
      "Training Loss:  0.055383734\n",
      "Validation Loss:  0.050673056\n",
      "Epoch:  927\n",
      "Training Loss:  0.055506777\n",
      "Validation Loss:  0.050891902\n",
      "Epoch:  928\n",
      "Training Loss:  0.055286065\n",
      "Validation Loss:  0.051737607\n",
      "Epoch:  929\n",
      "Training Loss:  0.054055136\n",
      "Validation Loss:  0.053799193\n",
      "Epoch:  930\n",
      "Training Loss:  0.05523642\n",
      "Validation Loss:  0.052526493\n",
      "Epoch:  931\n",
      "Training Loss:  0.05558598\n",
      "Validation Loss:  0.050582487\n",
      "Epoch:  932\n",
      "Training Loss:  0.05509979\n",
      "Validation Loss:  0.05017486\n",
      "Epoch:  933\n",
      "Training Loss:  0.05520885\n",
      "Validation Loss:  0.051743153\n",
      "Epoch:  934\n",
      "Training Loss:  0.055303585\n",
      "Validation Loss:  0.05367419\n",
      "Epoch:  935\n",
      "Training Loss:  0.05449357\n",
      "Validation Loss:  0.05022328\n",
      "Epoch:  936\n",
      "Training Loss:  0.052503087\n",
      "Validation Loss:  0.05951831\n",
      "Epoch:  937\n",
      "Training Loss:  0.054265168\n",
      "Validation Loss:  0.051199898\n",
      "Epoch:  938\n",
      "Training Loss:  0.05388739\n",
      "Validation Loss:  0.050336864\n",
      "Epoch:  939\n",
      "Training Loss:  0.05226718\n",
      "Validation Loss:  0.054573495\n",
      "Epoch:  940\n",
      "Training Loss:  0.05396346\n",
      "Validation Loss:  0.055069506\n",
      "Epoch:  941\n",
      "Training Loss:  0.053763855\n",
      "Validation Loss:  0.050000634\n",
      "Epoch:  942\n",
      "Training Loss:  0.05293703\n",
      "Validation Loss:  0.050815154\n",
      "Epoch:  943\n",
      "Training Loss:  0.052850097\n",
      "Validation Loss:  0.05141984\n",
      "Epoch:  944\n",
      "Training Loss:  0.053729255\n",
      "Validation Loss:  0.05119181\n",
      "Epoch:  945\n",
      "Training Loss:  0.053425323\n",
      "Validation Loss:  0.054997683\n",
      "Epoch:  946\n",
      "Training Loss:  0.051939134\n",
      "Validation Loss:  0.0527081\n",
      "Epoch:  947\n",
      "Training Loss:  0.053268887\n",
      "Validation Loss:  0.04898566\n",
      "Epoch:  948\n",
      "Training Loss:  0.05124565\n",
      "Validation Loss:  0.05068085\n",
      "Epoch:  949\n",
      "Training Loss:  0.053515907\n",
      "Validation Loss:  0.051030878\n",
      "Epoch:  950\n",
      "Training Loss:  0.051719494\n",
      "Validation Loss:  0.051371705\n",
      "Epoch:  951\n",
      "Training Loss:  0.05356105\n",
      "Validation Loss:  0.04975823\n",
      "Epoch:  952\n",
      "Training Loss:  0.051949352\n",
      "Validation Loss:  0.05110714\n",
      "Epoch:  953\n",
      "Training Loss:  0.05221994\n",
      "Validation Loss:  0.05025047\n",
      "Epoch:  954\n",
      "Training Loss:  0.052086193\n",
      "Validation Loss:  0.051735688\n",
      "Epoch:  955\n",
      "Training Loss:  0.05390075\n",
      "Validation Loss:  0.04962338\n",
      "Epoch:  956\n",
      "Training Loss:  0.05268031\n",
      "Validation Loss:  0.053608876\n",
      "Epoch:  957\n",
      "Training Loss:  0.052389026\n",
      "Validation Loss:  0.049024522\n",
      "Epoch:  958\n",
      "Training Loss:  0.053435512\n",
      "Validation Loss:  0.050828103\n",
      "Epoch:  959\n",
      "Training Loss:  0.052694242\n",
      "Validation Loss:  0.04794388\n",
      "Epoch:  960\n",
      "Training Loss:  0.050360903\n",
      "Validation Loss:  0.051191565\n",
      "Epoch:  961\n",
      "Training Loss:  0.05017792\n",
      "Validation Loss:  0.05319396\n",
      "Epoch:  962\n",
      "Training Loss:  0.05062846\n",
      "Validation Loss:  0.05039977\n",
      "Epoch:  963\n",
      "Training Loss:  0.050561167\n",
      "Validation Loss:  0.048782915\n",
      "Epoch:  964\n",
      "Training Loss:  0.051401787\n",
      "Validation Loss:  0.050415367\n",
      "Epoch:  965\n",
      "Training Loss:  0.052886423\n",
      "Validation Loss:  0.04948021\n",
      "Epoch:  966\n",
      "Training Loss:  0.051466107\n",
      "Validation Loss:  0.05395673\n",
      "Epoch:  967\n",
      "Training Loss:  0.0525902\n",
      "Validation Loss:  0.04855125\n",
      "Epoch:  968\n",
      "Training Loss:  0.050353263\n",
      "Validation Loss:  0.047516663\n",
      "Epoch:  969\n",
      "Training Loss:  0.052319914\n",
      "Validation Loss:  0.054686695\n",
      "Epoch:  970\n",
      "Training Loss:  0.050832286\n",
      "Validation Loss:  0.046074387\n",
      "Epoch:  971\n",
      "Training Loss:  0.050971\n",
      "Validation Loss:  0.04996453\n",
      "Epoch:  972\n",
      "Training Loss:  0.05066127\n",
      "Validation Loss:  0.05179459\n",
      "Epoch:  973\n",
      "Training Loss:  0.049925756\n",
      "Validation Loss:  0.04705007\n",
      "Epoch:  974\n",
      "Training Loss:  0.0508225\n",
      "Validation Loss:  0.04926421\n",
      "Epoch:  975\n",
      "Training Loss:  0.05175669\n",
      "Validation Loss:  0.046585113\n",
      "Epoch:  976\n",
      "Training Loss:  0.0509007\n",
      "Validation Loss:  0.04417728\n",
      "Epoch:  977\n",
      "Training Loss:  0.05077116\n",
      "Validation Loss:  0.049652636\n",
      "Epoch:  978\n",
      "Training Loss:  0.051116228\n",
      "Validation Loss:  0.047133774\n",
      "Epoch:  979\n",
      "Training Loss:  0.049700297\n",
      "Validation Loss:  0.048841137\n",
      "Epoch:  980\n",
      "Training Loss:  0.049395192\n",
      "Validation Loss:  0.054274037\n",
      "Epoch:  981\n",
      "Training Loss:  0.050092686\n",
      "Validation Loss:  0.05014132\n",
      "Epoch:  982\n",
      "Training Loss:  0.049819063\n",
      "Validation Loss:  0.04807456\n",
      "Epoch:  983\n",
      "Training Loss:  0.04990069\n",
      "Validation Loss:  0.04776871\n",
      "Epoch:  984\n",
      "Training Loss:  0.050789822\n",
      "Validation Loss:  0.05258353\n",
      "Epoch:  985\n",
      "Training Loss:  0.05085675\n",
      "Validation Loss:  0.045962427\n",
      "Epoch:  986\n",
      "Training Loss:  0.050100908\n",
      "Validation Loss:  0.055484604\n",
      "Epoch:  987\n",
      "Training Loss:  0.04913765\n",
      "Validation Loss:  0.048607018\n",
      "Epoch:  988\n",
      "Training Loss:  0.049353108\n",
      "Validation Loss:  0.047790796\n",
      "Epoch:  989\n",
      "Training Loss:  0.05065339\n",
      "Validation Loss:  0.04566619\n",
      "Epoch:  990\n",
      "Training Loss:  0.049733303\n",
      "Validation Loss:  0.04354554\n",
      "Epoch:  991\n",
      "Training Loss:  0.048074555\n",
      "Validation Loss:  0.045359965\n",
      "Epoch:  992\n",
      "Training Loss:  0.049212724\n",
      "Validation Loss:  0.04428492\n",
      "Epoch:  993\n",
      "Training Loss:  0.049597267\n",
      "Validation Loss:  0.046977907\n",
      "Epoch:  994\n",
      "Training Loss:  0.049647752\n",
      "Validation Loss:  0.045428734\n",
      "Epoch:  995\n",
      "Training Loss:  0.048444618\n",
      "Validation Loss:  0.04608852\n",
      "Epoch:  996\n",
      "Training Loss:  0.04980711\n",
      "Validation Loss:  0.047467485\n",
      "Epoch:  997\n",
      "Training Loss:  0.048757512\n",
      "Validation Loss:  0.04446664\n",
      "Epoch:  998\n",
      "Training Loss:  0.047514368\n",
      "Validation Loss:  0.04557441\n",
      "Epoch:  999\n",
      "Training Loss:  0.048590977\n",
      "Validation Loss:  0.0437981\n",
      "Epoch:  1000\n",
      "Training Loss:  0.04702535\n",
      "Validation Loss:  0.048470017\n",
      "Epoch:  1001\n",
      "Training Loss:  0.049218178\n",
      "Validation Loss:  0.049871802\n",
      "Epoch:  1002\n",
      "Training Loss:  0.048122898\n",
      "Validation Loss:  0.047194716\n",
      "Epoch:  1003\n",
      "Training Loss:  0.04676698\n",
      "Validation Loss:  0.048496217\n",
      "Epoch:  1004\n",
      "Training Loss:  0.0473366\n",
      "Validation Loss:  0.04964378\n",
      "Epoch:  1005\n",
      "Training Loss:  0.048298016\n",
      "Validation Loss:  0.045652833\n",
      "Epoch:  1006\n",
      "Training Loss:  0.04895369\n",
      "Validation Loss:  0.045400694\n",
      "Epoch:  1007\n",
      "Training Loss:  0.049397666\n",
      "Validation Loss:  0.044401083\n",
      "Epoch:  1008\n",
      "Training Loss:  0.04738951\n",
      "Validation Loss:  0.04679406\n",
      "Epoch:  1009\n",
      "Training Loss:  0.04796169\n",
      "Validation Loss:  0.047218636\n",
      "Epoch:  1010\n",
      "Training Loss:  0.046782438\n",
      "Validation Loss:  0.04725611\n",
      "Epoch:  1011\n",
      "Training Loss:  0.04757354\n",
      "Validation Loss:  0.04492266\n",
      "Epoch:  1012\n",
      "Training Loss:  0.04788168\n",
      "Validation Loss:  0.050157484\n",
      "Epoch:  1013\n",
      "Training Loss:  0.047874592\n",
      "Validation Loss:  0.043895174\n",
      "Epoch:  1014\n",
      "Training Loss:  0.047562085\n",
      "Validation Loss:  0.04327078\n",
      "Epoch:  1015\n",
      "Training Loss:  0.048193708\n",
      "Validation Loss:  0.04894702\n",
      "Epoch:  1016\n",
      "Training Loss:  0.046414085\n",
      "Validation Loss:  0.042666223\n",
      "Epoch:  1017\n",
      "Training Loss:  0.048335537\n",
      "Validation Loss:  0.04539132\n",
      "Epoch:  1018\n",
      "Training Loss:  0.047907986\n",
      "Validation Loss:  0.048579138\n",
      "Epoch:  1019\n",
      "Training Loss:  0.048934646\n",
      "Validation Loss:  0.042127784\n",
      "Epoch:  1020\n",
      "Training Loss:  0.047483243\n",
      "Validation Loss:  0.045060065\n",
      "Epoch:  1021\n",
      "Training Loss:  0.047036175\n",
      "Validation Loss:  0.049287442\n",
      "Epoch:  1022\n",
      "Training Loss:  0.046722066\n",
      "Validation Loss:  0.042370256\n",
      "Epoch:  1023\n",
      "Training Loss:  0.04696663\n",
      "Validation Loss:  0.042069647\n",
      "Epoch:  1024\n",
      "Training Loss:  0.045809917\n",
      "Validation Loss:  0.045511033\n",
      "Epoch:  1025\n",
      "Training Loss:  0.046703614\n",
      "Validation Loss:  0.042183395\n",
      "Epoch:  1026\n",
      "Training Loss:  0.046293527\n",
      "Validation Loss:  0.043438826\n",
      "Epoch:  1027\n",
      "Training Loss:  0.045842122\n",
      "Validation Loss:  0.04063631\n",
      "Epoch:  1028\n",
      "Training Loss:  0.04652597\n",
      "Validation Loss:  0.043565523\n",
      "Epoch:  1029\n",
      "Training Loss:  0.045721915\n",
      "Validation Loss:  0.056575578\n",
      "Epoch:  1030\n",
      "Training Loss:  0.04717448\n",
      "Validation Loss:  0.044163454\n",
      "Epoch:  1031\n",
      "Training Loss:  0.045657698\n",
      "Validation Loss:  0.043492705\n",
      "Epoch:  1032\n",
      "Training Loss:  0.045555495\n",
      "Validation Loss:  0.050786708\n",
      "Epoch:  1033\n",
      "Training Loss:  0.046382338\n",
      "Validation Loss:  0.04410882\n",
      "Epoch:  1034\n",
      "Training Loss:  0.045749318\n",
      "Validation Loss:  0.04402414\n",
      "Epoch:  1035\n",
      "Training Loss:  0.047081806\n",
      "Validation Loss:  0.042739462\n",
      "Epoch:  1036\n",
      "Training Loss:  0.045367952\n",
      "Validation Loss:  0.041870445\n",
      "Epoch:  1037\n",
      "Training Loss:  0.045382448\n",
      "Validation Loss:  0.04192244\n",
      "Epoch:  1038\n",
      "Training Loss:  0.046656054\n",
      "Validation Loss:  0.040784832\n",
      "Epoch:  1039\n",
      "Training Loss:  0.047118925\n",
      "Validation Loss:  0.042198002\n",
      "Epoch:  1040\n",
      "Training Loss:  0.045705214\n",
      "Validation Loss:  0.04669683\n",
      "Epoch:  1041\n",
      "Training Loss:  0.04477171\n",
      "Validation Loss:  0.043057233\n",
      "Epoch:  1042\n",
      "Training Loss:  0.046587683\n",
      "Validation Loss:  0.045502875\n",
      "Epoch:  1043\n",
      "Training Loss:  0.04629278\n",
      "Validation Loss:  0.043135688\n",
      "Epoch:  1044\n",
      "Training Loss:  0.044525094\n",
      "Validation Loss:  0.042259708\n",
      "Epoch:  1045\n",
      "Training Loss:  0.044574846\n",
      "Validation Loss:  0.048219685\n",
      "Epoch:  1046\n",
      "Training Loss:  0.044754993\n",
      "Validation Loss:  0.040176127\n",
      "Epoch:  1047\n",
      "Training Loss:  0.04441084\n",
      "Validation Loss:  0.045580104\n",
      "Epoch:  1048\n",
      "Training Loss:  0.045230415\n",
      "Validation Loss:  0.042300444\n",
      "Epoch:  1049\n",
      "Training Loss:  0.04432184\n",
      "Validation Loss:  0.043497737\n",
      "Epoch:  1050\n",
      "Training Loss:  0.044066757\n",
      "Validation Loss:  0.041013815\n",
      "Epoch:  1051\n",
      "Training Loss:  0.044814043\n",
      "Validation Loss:  0.04176608\n",
      "Epoch:  1052\n",
      "Training Loss:  0.04403983\n",
      "Validation Loss:  0.039385945\n",
      "Epoch:  1053\n",
      "Training Loss:  0.045016434\n",
      "Validation Loss:  0.04350862\n",
      "Epoch:  1054\n",
      "Training Loss:  0.04339451\n",
      "Validation Loss:  0.04081263\n",
      "Epoch:  1055\n",
      "Training Loss:  0.04369646\n",
      "Validation Loss:  0.047072697\n",
      "Epoch:  1056\n",
      "Training Loss:  0.045258056\n",
      "Validation Loss:  0.044217657\n",
      "Epoch:  1057\n",
      "Training Loss:  0.043946713\n",
      "Validation Loss:  0.040526245\n",
      "Epoch:  1058\n",
      "Training Loss:  0.043560594\n",
      "Validation Loss:  0.041029572\n",
      "Epoch:  1059\n",
      "Training Loss:  0.044793602\n",
      "Validation Loss:  0.040810328\n",
      "Epoch:  1060\n",
      "Training Loss:  0.043767493\n",
      "Validation Loss:  0.04308628\n",
      "Epoch:  1061\n",
      "Training Loss:  0.04422945\n",
      "Validation Loss:  0.040861607\n",
      "Epoch:  1062\n",
      "Training Loss:  0.04405756\n",
      "Validation Loss:  0.045252074\n",
      "Epoch:  1063\n",
      "Training Loss:  0.043923687\n",
      "Validation Loss:  0.038668294\n",
      "Epoch:  1064\n",
      "Training Loss:  0.044199612\n",
      "Validation Loss:  0.04004173\n",
      "Epoch:  1065\n",
      "Training Loss:  0.044662014\n",
      "Validation Loss:  0.038691305\n",
      "Epoch:  1066\n",
      "Training Loss:  0.04353102\n",
      "Validation Loss:  0.039786946\n",
      "Epoch:  1067\n",
      "Training Loss:  0.042713247\n",
      "Validation Loss:  0.04196925\n",
      "Epoch:  1068\n",
      "Training Loss:  0.043999895\n",
      "Validation Loss:  0.041240875\n",
      "Epoch:  1069\n",
      "Training Loss:  0.043749243\n",
      "Validation Loss:  0.042112425\n",
      "Epoch:  1070\n",
      "Training Loss:  0.043285575\n",
      "Validation Loss:  0.040051688\n",
      "Epoch:  1071\n",
      "Training Loss:  0.04283043\n",
      "Validation Loss:  0.039669607\n",
      "Epoch:  1072\n",
      "Training Loss:  0.042665575\n",
      "Validation Loss:  0.03802676\n",
      "Epoch:  1073\n",
      "Training Loss:  0.043006413\n",
      "Validation Loss:  0.039826233\n",
      "Epoch:  1074\n",
      "Training Loss:  0.043799635\n",
      "Validation Loss:  0.039644904\n",
      "Epoch:  1075\n",
      "Training Loss:  0.04206109\n",
      "Validation Loss:  0.040524025\n",
      "Epoch:  1076\n",
      "Training Loss:  0.042657465\n",
      "Validation Loss:  0.041120533\n",
      "Epoch:  1077\n",
      "Training Loss:  0.043296564\n",
      "Validation Loss:  0.042890485\n",
      "Epoch:  1078\n",
      "Training Loss:  0.04242494\n",
      "Validation Loss:  0.03968716\n",
      "Epoch:  1079\n",
      "Training Loss:  0.042018477\n",
      "Validation Loss:  0.038916707\n",
      "Epoch:  1080\n",
      "Training Loss:  0.043059364\n",
      "Validation Loss:  0.04149457\n",
      "Epoch:  1081\n",
      "Training Loss:  0.042805195\n",
      "Validation Loss:  0.03964072\n",
      "Epoch:  1082\n",
      "Training Loss:  0.04241169\n",
      "Validation Loss:  0.047890473\n",
      "Epoch:  1083\n",
      "Training Loss:  0.042875823\n",
      "Validation Loss:  0.039074954\n",
      "Epoch:  1084\n",
      "Training Loss:  0.042234167\n",
      "Validation Loss:  0.038662132\n",
      "Epoch:  1085\n",
      "Training Loss:  0.04350822\n",
      "Validation Loss:  0.04039477\n",
      "Epoch:  1086\n",
      "Training Loss:  0.042773258\n",
      "Validation Loss:  0.043405402\n",
      "Epoch:  1087\n",
      "Training Loss:  0.0429922\n",
      "Validation Loss:  0.03976052\n",
      "Epoch:  1088\n",
      "Training Loss:  0.041918397\n",
      "Validation Loss:  0.038182873\n",
      "Epoch:  1089\n",
      "Training Loss:  0.0424033\n",
      "Validation Loss:  0.04019145\n",
      "Epoch:  1090\n",
      "Training Loss:  0.04294098\n",
      "Validation Loss:  0.041305345\n",
      "Epoch:  1091\n",
      "Training Loss:  0.041185077\n",
      "Validation Loss:  0.040033888\n",
      "Epoch:  1092\n",
      "Training Loss:  0.04245925\n",
      "Validation Loss:  0.037222978\n",
      "Epoch:  1093\n",
      "Training Loss:  0.042222492\n",
      "Validation Loss:  0.042404223\n",
      "Epoch:  1094\n",
      "Training Loss:  0.041528147\n",
      "Validation Loss:  0.038696423\n",
      "Epoch:  1095\n",
      "Training Loss:  0.0420329\n",
      "Validation Loss:  0.038488496\n",
      "Epoch:  1096\n",
      "Training Loss:  0.040554084\n",
      "Validation Loss:  0.041192036\n",
      "Epoch:  1097\n",
      "Training Loss:  0.042822\n",
      "Validation Loss:  0.03976129\n",
      "Epoch:  1098\n",
      "Training Loss:  0.04076486\n",
      "Validation Loss:  0.049427\n",
      "Epoch:  1099\n",
      "Training Loss:  0.041756447\n",
      "Validation Loss:  0.037785586\n",
      "Epoch:  1100\n",
      "Training Loss:  0.041407175\n",
      "Validation Loss:  0.04641358\n",
      "Epoch:  1101\n",
      "Training Loss:  0.040965162\n",
      "Validation Loss:  0.036103286\n",
      "Epoch:  1102\n",
      "Training Loss:  0.04124053\n",
      "Validation Loss:  0.036911022\n",
      "Epoch:  1103\n",
      "Training Loss:  0.040649\n",
      "Validation Loss:  0.039800834\n",
      "Epoch:  1104\n",
      "Training Loss:  0.040905952\n",
      "Validation Loss:  0.043607835\n",
      "Epoch:  1105\n",
      "Training Loss:  0.041285962\n",
      "Validation Loss:  0.037512932\n",
      "Epoch:  1106\n",
      "Training Loss:  0.04013378\n",
      "Validation Loss:  0.036614925\n",
      "Epoch:  1107\n",
      "Training Loss:  0.041849583\n",
      "Validation Loss:  0.037025664\n",
      "Epoch:  1108\n",
      "Training Loss:  0.04135129\n",
      "Validation Loss:  0.037801486\n",
      "Epoch:  1109\n",
      "Training Loss:  0.041201346\n",
      "Validation Loss:  0.037002746\n",
      "Epoch:  1110\n",
      "Training Loss:  0.040087763\n",
      "Validation Loss:  0.040164102\n",
      "Epoch:  1111\n",
      "Training Loss:  0.04096213\n",
      "Validation Loss:  0.035433646\n",
      "Epoch:  1112\n",
      "Training Loss:  0.04133773\n",
      "Validation Loss:  0.037572477\n",
      "Epoch:  1113\n",
      "Training Loss:  0.04049173\n",
      "Validation Loss:  0.03672458\n",
      "Epoch:  1114\n",
      "Training Loss:  0.039871167\n",
      "Validation Loss:  0.041081008\n",
      "Epoch:  1115\n",
      "Training Loss:  0.040280696\n",
      "Validation Loss:  0.03760426\n",
      "Epoch:  1116\n",
      "Training Loss:  0.04081564\n",
      "Validation Loss:  0.040660337\n",
      "Epoch:  1117\n",
      "Training Loss:  0.04099525\n",
      "Validation Loss:  0.037035435\n",
      "Epoch:  1118\n",
      "Training Loss:  0.040234637\n",
      "Validation Loss:  0.03567899\n",
      "Epoch:  1119\n",
      "Training Loss:  0.038985226\n",
      "Validation Loss:  0.034655046\n",
      "Epoch:  1120\n",
      "Training Loss:  0.040139414\n",
      "Validation Loss:  0.036786556\n",
      "Epoch:  1121\n",
      "Training Loss:  0.04077217\n",
      "Validation Loss:  0.03561507\n",
      "Epoch:  1122\n",
      "Training Loss:  0.04075012\n",
      "Validation Loss:  0.03592511\n",
      "Epoch:  1123\n",
      "Training Loss:  0.038866546\n",
      "Validation Loss:  0.036299273\n",
      "Epoch:  1124\n",
      "Training Loss:  0.039349154\n",
      "Validation Loss:  0.036164116\n",
      "Epoch:  1125\n",
      "Training Loss:  0.03925181\n",
      "Validation Loss:  0.039168164\n",
      "Epoch:  1126\n",
      "Training Loss:  0.039938223\n",
      "Validation Loss:  0.038345914\n",
      "Epoch:  1127\n",
      "Training Loss:  0.039762557\n",
      "Validation Loss:  0.038384303\n",
      "Epoch:  1128\n",
      "Training Loss:  0.03955704\n",
      "Validation Loss:  0.03684871\n",
      "Epoch:  1129\n",
      "Training Loss:  0.040005058\n",
      "Validation Loss:  0.041780125\n",
      "Epoch:  1130\n",
      "Training Loss:  0.040333454\n",
      "Validation Loss:  0.03588364\n",
      "Epoch:  1131\n",
      "Training Loss:  0.039509118\n",
      "Validation Loss:  0.037198815\n",
      "Epoch:  1132\n",
      "Training Loss:  0.0400971\n",
      "Validation Loss:  0.036230553\n",
      "Epoch:  1133\n",
      "Training Loss:  0.039794583\n",
      "Validation Loss:  0.04098935\n",
      "Epoch:  1134\n",
      "Training Loss:  0.039463043\n",
      "Validation Loss:  0.037368942\n",
      "Epoch:  1135\n",
      "Training Loss:  0.03926797\n",
      "Validation Loss:  0.03456734\n",
      "Epoch:  1136\n",
      "Training Loss:  0.03948614\n",
      "Validation Loss:  0.036244504\n",
      "Epoch:  1137\n",
      "Training Loss:  0.039559446\n",
      "Validation Loss:  0.03562714\n",
      "Epoch:  1138\n",
      "Training Loss:  0.03972029\n",
      "Validation Loss:  0.038000584\n",
      "Epoch:  1139\n",
      "Training Loss:  0.038486756\n",
      "Validation Loss:  0.034923155\n",
      "Epoch:  1140\n",
      "Training Loss:  0.039454218\n",
      "Validation Loss:  0.034699388\n",
      "Epoch:  1141\n",
      "Training Loss:  0.039648462\n",
      "Validation Loss:  0.034493472\n",
      "Epoch:  1142\n",
      "Training Loss:  0.038600612\n",
      "Validation Loss:  0.03795523\n",
      "Epoch:  1143\n",
      "Training Loss:  0.039195623\n",
      "Validation Loss:  0.039224014\n",
      "Epoch:  1144\n",
      "Training Loss:  0.038948596\n",
      "Validation Loss:  0.035918355\n",
      "Epoch:  1145\n",
      "Training Loss:  0.040164713\n",
      "Validation Loss:  0.035573255\n",
      "Epoch:  1146\n",
      "Training Loss:  0.03867823\n",
      "Validation Loss:  0.038069192\n",
      "Epoch:  1147\n",
      "Training Loss:  0.038735066\n",
      "Validation Loss:  0.0360224\n",
      "Epoch:  1148\n",
      "Training Loss:  0.039057136\n",
      "Validation Loss:  0.03758427\n",
      "Epoch:  1149\n",
      "Training Loss:  0.03790593\n",
      "Validation Loss:  0.03465625\n",
      "Epoch:  1150\n",
      "Training Loss:  0.037401758\n",
      "Validation Loss:  0.0365145\n",
      "Epoch:  1151\n",
      "Training Loss:  0.03739903\n",
      "Validation Loss:  0.03531487\n",
      "Epoch:  1152\n",
      "Training Loss:  0.037884682\n",
      "Validation Loss:  0.033825938\n",
      "Epoch:  1153\n",
      "Training Loss:  0.03859963\n",
      "Validation Loss:  0.039516237\n",
      "Epoch:  1154\n",
      "Training Loss:  0.038510527\n",
      "Validation Loss:  0.03794599\n",
      "Epoch:  1155\n",
      "Training Loss:  0.037978187\n",
      "Validation Loss:  0.03494171\n",
      "Epoch:  1156\n",
      "Training Loss:  0.038343657\n",
      "Validation Loss:  0.039625965\n",
      "Epoch:  1157\n",
      "Training Loss:  0.038846478\n",
      "Validation Loss:  0.03525465\n",
      "Epoch:  1158\n",
      "Training Loss:  0.039555356\n",
      "Validation Loss:  0.03490034\n",
      "Epoch:  1159\n",
      "Training Loss:  0.037541408\n",
      "Validation Loss:  0.034073953\n",
      "Epoch:  1160\n",
      "Training Loss:  0.037813872\n",
      "Validation Loss:  0.033395056\n",
      "Epoch:  1161\n",
      "Training Loss:  0.0378479\n",
      "Validation Loss:  0.035508644\n",
      "Epoch:  1162\n",
      "Training Loss:  0.03767647\n",
      "Validation Loss:  0.04158004\n",
      "Epoch:  1163\n",
      "Training Loss:  0.03895249\n",
      "Validation Loss:  0.03794879\n",
      "Epoch:  1164\n",
      "Training Loss:  0.03739776\n",
      "Validation Loss:  0.03498668\n",
      "Epoch:  1165\n",
      "Training Loss:  0.037847582\n",
      "Validation Loss:  0.035684682\n",
      "Epoch:  1166\n",
      "Training Loss:  0.03874396\n",
      "Validation Loss:  0.036662642\n",
      "Epoch:  1167\n",
      "Training Loss:  0.038171362\n",
      "Validation Loss:  0.035225626\n",
      "Epoch:  1168\n",
      "Training Loss:  0.038204852\n",
      "Validation Loss:  0.036108505\n",
      "Epoch:  1169\n",
      "Training Loss:  0.03821015\n",
      "Validation Loss:  0.03350437\n",
      "Epoch:  1170\n",
      "Training Loss:  0.038948085\n",
      "Validation Loss:  0.03455324\n",
      "Epoch:  1171\n",
      "Training Loss:  0.037382815\n",
      "Validation Loss:  0.033764787\n",
      "Epoch:  1172\n",
      "Training Loss:  0.037772432\n",
      "Validation Loss:  0.034092847\n",
      "Epoch:  1173\n",
      "Training Loss:  0.037506703\n",
      "Validation Loss:  0.034577757\n",
      "Epoch:  1174\n",
      "Training Loss:  0.035966564\n",
      "Validation Loss:  0.03521849\n",
      "Epoch:  1175\n",
      "Training Loss:  0.037153758\n",
      "Validation Loss:  0.034739137\n",
      "Epoch:  1176\n",
      "Training Loss:  0.037279185\n",
      "Validation Loss:  0.033310886\n",
      "Epoch:  1177\n",
      "Training Loss:  0.036935456\n",
      "Validation Loss:  0.03489842\n",
      "Epoch:  1178\n",
      "Training Loss:  0.036420237\n",
      "Validation Loss:  0.03747653\n",
      "Epoch:  1179\n",
      "Training Loss:  0.037871204\n",
      "Validation Loss:  0.033780042\n",
      "Epoch:  1180\n",
      "Training Loss:  0.03767898\n",
      "Validation Loss:  0.033434603\n",
      "Epoch:  1181\n",
      "Training Loss:  0.036511835\n",
      "Validation Loss:  0.035732385\n",
      "Epoch:  1182\n",
      "Training Loss:  0.03663423\n",
      "Validation Loss:  0.03445656\n",
      "Epoch:  1183\n",
      "Training Loss:  0.036948636\n",
      "Validation Loss:  0.038005367\n",
      "Epoch:  1184\n",
      "Training Loss:  0.037523724\n",
      "Validation Loss:  0.035392378\n",
      "Epoch:  1185\n",
      "Training Loss:  0.036407664\n",
      "Validation Loss:  0.034734264\n",
      "Epoch:  1186\n",
      "Training Loss:  0.03730929\n",
      "Validation Loss:  0.037495684\n",
      "Epoch:  1187\n",
      "Training Loss:  0.0368789\n",
      "Validation Loss:  0.03650438\n",
      "Epoch:  1188\n",
      "Training Loss:  0.0369064\n",
      "Validation Loss:  0.03380834\n",
      "Epoch:  1189\n",
      "Training Loss:  0.036873903\n",
      "Validation Loss:  0.033020567\n",
      "Epoch:  1190\n",
      "Training Loss:  0.0368833\n",
      "Validation Loss:  0.035644982\n",
      "Epoch:  1191\n",
      "Training Loss:  0.035837125\n",
      "Validation Loss:  0.03418244\n",
      "Epoch:  1192\n",
      "Training Loss:  0.036252357\n",
      "Validation Loss:  0.032237794\n",
      "Epoch:  1193\n",
      "Training Loss:  0.03616376\n",
      "Validation Loss:  0.035376918\n",
      "Epoch:  1194\n",
      "Training Loss:  0.035411943\n",
      "Validation Loss:  0.035779174\n",
      "Epoch:  1195\n",
      "Training Loss:  0.03577034\n",
      "Validation Loss:  0.036091395\n",
      "Epoch:  1196\n",
      "Training Loss:  0.036164377\n",
      "Validation Loss:  0.0328107\n",
      "Epoch:  1197\n",
      "Training Loss:  0.037251305\n",
      "Validation Loss:  0.031902317\n",
      "Epoch:  1198\n",
      "Training Loss:  0.035396505\n",
      "Validation Loss:  0.034906555\n",
      "Epoch:  1199\n",
      "Training Loss:  0.03582075\n",
      "Validation Loss:  0.034810755\n",
      "Epoch:  1200\n",
      "Training Loss:  0.03605956\n",
      "Validation Loss:  0.034748584\n",
      "Epoch:  1201\n",
      "Training Loss:  0.035770983\n",
      "Validation Loss:  0.030018082\n",
      "Epoch:  1202\n",
      "Training Loss:  0.03586181\n",
      "Validation Loss:  0.031032613\n",
      "Epoch:  1203\n",
      "Training Loss:  0.03511015\n",
      "Validation Loss:  0.033356253\n",
      "Epoch:  1204\n",
      "Training Loss:  0.03549345\n",
      "Validation Loss:  0.03162947\n",
      "Epoch:  1205\n",
      "Training Loss:  0.035374243\n",
      "Validation Loss:  0.03759128\n",
      "Epoch:  1206\n",
      "Training Loss:  0.036067206\n",
      "Validation Loss:  0.03303266\n",
      "Epoch:  1207\n",
      "Training Loss:  0.03479621\n",
      "Validation Loss:  0.032612164\n",
      "Epoch:  1208\n",
      "Training Loss:  0.03546831\n",
      "Validation Loss:  0.038095947\n",
      "Epoch:  1209\n",
      "Training Loss:  0.03452425\n",
      "Validation Loss:  0.033794466\n",
      "Epoch:  1210\n",
      "Training Loss:  0.03617221\n",
      "Validation Loss:  0.030896625\n",
      "Epoch:  1211\n",
      "Training Loss:  0.035675537\n",
      "Validation Loss:  0.030165447\n",
      "Epoch:  1212\n",
      "Training Loss:  0.035043083\n",
      "Validation Loss:  0.031611685\n",
      "Epoch:  1213\n",
      "Training Loss:  0.035490282\n",
      "Validation Loss:  0.032595742\n",
      "Epoch:  1214\n",
      "Training Loss:  0.03486571\n",
      "Validation Loss:  0.031499807\n",
      "Epoch:  1215\n",
      "Training Loss:  0.03432992\n",
      "Validation Loss:  0.03232507\n",
      "Epoch:  1216\n",
      "Training Loss:  0.03491542\n",
      "Validation Loss:  0.03310467\n",
      "Epoch:  1217\n",
      "Training Loss:  0.03475602\n",
      "Validation Loss:  0.032541413\n",
      "Epoch:  1218\n",
      "Training Loss:  0.03541547\n",
      "Validation Loss:  0.032596882\n",
      "Epoch:  1219\n",
      "Training Loss:  0.034473356\n",
      "Validation Loss:  0.03533486\n",
      "Epoch:  1220\n",
      "Training Loss:  0.03450864\n",
      "Validation Loss:  0.030594656\n",
      "Epoch:  1221\n",
      "Training Loss:  0.035174664\n",
      "Validation Loss:  0.03446544\n",
      "Epoch:  1222\n",
      "Training Loss:  0.03458085\n",
      "Validation Loss:  0.03306352\n",
      "Epoch:  1223\n",
      "Training Loss:  0.035526995\n",
      "Validation Loss:  0.033818338\n",
      "Epoch:  1224\n",
      "Training Loss:  0.034768432\n",
      "Validation Loss:  0.030261718\n",
      "Epoch:  1225\n",
      "Training Loss:  0.035044547\n",
      "Validation Loss:  0.03295072\n",
      "Epoch:  1226\n",
      "Training Loss:  0.034936536\n",
      "Validation Loss:  0.03247756\n",
      "Epoch:  1227\n",
      "Training Loss:  0.0344818\n",
      "Validation Loss:  0.029453823\n",
      "Epoch:  1228\n",
      "Training Loss:  0.034584228\n",
      "Validation Loss:  0.030836603\n",
      "Epoch:  1229\n",
      "Training Loss:  0.034009844\n",
      "Validation Loss:  0.036984142\n",
      "Epoch:  1230\n",
      "Training Loss:  0.033991147\n",
      "Validation Loss:  0.032315936\n",
      "Epoch:  1231\n",
      "Training Loss:  0.035271425\n",
      "Validation Loss:  0.033414412\n",
      "Epoch:  1232\n",
      "Training Loss:  0.03438394\n",
      "Validation Loss:  0.030844284\n",
      "Epoch:  1233\n",
      "Training Loss:  0.035509072\n",
      "Validation Loss:  0.031473313\n",
      "Epoch:  1234\n",
      "Training Loss:  0.034347653\n",
      "Validation Loss:  0.03600706\n",
      "Epoch:  1235\n",
      "Training Loss:  0.03309425\n",
      "Validation Loss:  0.030939633\n",
      "Epoch:  1236\n",
      "Training Loss:  0.034357075\n",
      "Validation Loss:  0.0319443\n",
      "Epoch:  1237\n",
      "Training Loss:  0.03331161\n",
      "Validation Loss:  0.03176081\n",
      "Epoch:  1238\n",
      "Training Loss:  0.03351396\n",
      "Validation Loss:  0.03346019\n",
      "Epoch:  1239\n",
      "Training Loss:  0.034205653\n",
      "Validation Loss:  0.030671842\n",
      "Epoch:  1240\n",
      "Training Loss:  0.03366891\n",
      "Validation Loss:  0.034298446\n",
      "Epoch:  1241\n",
      "Training Loss:  0.034375187\n",
      "Validation Loss:  0.030437937\n",
      "Epoch:  1242\n",
      "Training Loss:  0.033196934\n",
      "Validation Loss:  0.030770985\n",
      "Epoch:  1243\n",
      "Training Loss:  0.03530038\n",
      "Validation Loss:  0.034432523\n",
      "Epoch:  1244\n",
      "Training Loss:  0.03458312\n",
      "Validation Loss:  0.028130464\n",
      "Epoch:  1245\n",
      "Training Loss:  0.034639277\n",
      "Validation Loss:  0.03017026\n",
      "Epoch:  1246\n",
      "Training Loss:  0.03475622\n",
      "Validation Loss:  0.03412718\n",
      "Epoch:  1247\n",
      "Training Loss:  0.033483356\n",
      "Validation Loss:  0.035689827\n",
      "Epoch:  1248\n",
      "Training Loss:  0.03306962\n",
      "Validation Loss:  0.028571693\n",
      "Epoch:  1249\n",
      "Training Loss:  0.033791535\n",
      "Validation Loss:  0.030194126\n",
      "Epoch:  1250\n",
      "Training Loss:  0.033867177\n",
      "Validation Loss:  0.02902474\n",
      "Epoch:  1251\n",
      "Training Loss:  0.033603836\n",
      "Validation Loss:  0.031036474\n",
      "Epoch:  1252\n",
      "Training Loss:  0.034253757\n",
      "Validation Loss:  0.029593674\n",
      "Epoch:  1253\n",
      "Training Loss:  0.03386217\n",
      "Validation Loss:  0.031095477\n",
      "Epoch:  1254\n",
      "Training Loss:  0.033804208\n",
      "Validation Loss:  0.02792289\n",
      "Epoch:  1255\n",
      "Training Loss:  0.032688357\n",
      "Validation Loss:  0.02945675\n",
      "Epoch:  1256\n",
      "Training Loss:  0.03390545\n",
      "Validation Loss:  0.02998955\n",
      "Epoch:  1257\n",
      "Training Loss:  0.033984333\n",
      "Validation Loss:  0.032051098\n",
      "Epoch:  1258\n",
      "Training Loss:  0.033834606\n",
      "Validation Loss:  0.0352315\n",
      "Epoch:  1259\n",
      "Training Loss:  0.033562876\n",
      "Validation Loss:  0.031661935\n",
      "Epoch:  1260\n",
      "Training Loss:  0.03406564\n",
      "Validation Loss:  0.031364348\n",
      "Epoch:  1261\n",
      "Training Loss:  0.033551216\n",
      "Validation Loss:  0.02998852\n",
      "Epoch:  1262\n",
      "Training Loss:  0.03357404\n",
      "Validation Loss:  0.0324266\n",
      "Epoch:  1263\n",
      "Training Loss:  0.0328676\n",
      "Validation Loss:  0.031900223\n",
      "Epoch:  1264\n",
      "Training Loss:  0.033063833\n",
      "Validation Loss:  0.029071843\n",
      "Epoch:  1265\n",
      "Training Loss:  0.033934552\n",
      "Validation Loss:  0.031087317\n",
      "Epoch:  1266\n",
      "Training Loss:  0.03270301\n",
      "Validation Loss:  0.03735002\n",
      "Epoch:  1267\n",
      "Training Loss:  0.03304389\n",
      "Validation Loss:  0.028273096\n",
      "Epoch:  1268\n",
      "Training Loss:  0.03365904\n",
      "Validation Loss:  0.036631737\n",
      "Epoch:  1269\n",
      "Training Loss:  0.03182845\n",
      "Validation Loss:  0.032276504\n",
      "Epoch:  1270\n",
      "Training Loss:  0.032687217\n",
      "Validation Loss:  0.03181222\n",
      "Epoch:  1271\n",
      "Training Loss:  0.03233507\n",
      "Validation Loss:  0.029292973\n",
      "Epoch:  1272\n",
      "Training Loss:  0.033125844\n",
      "Validation Loss:  0.035028014\n",
      "Epoch:  1273\n",
      "Training Loss:  0.033168435\n",
      "Validation Loss:  0.030584956\n",
      "Epoch:  1274\n",
      "Training Loss:  0.033036437\n",
      "Validation Loss:  0.028170861\n",
      "Epoch:  1275\n",
      "Training Loss:  0.03327731\n",
      "Validation Loss:  0.0308317\n",
      "Epoch:  1276\n",
      "Training Loss:  0.03346729\n",
      "Validation Loss:  0.028505793\n",
      "Epoch:  1277\n",
      "Training Loss:  0.032072082\n",
      "Validation Loss:  0.03080678\n",
      "Epoch:  1278\n",
      "Training Loss:  0.032068774\n",
      "Validation Loss:  0.029895777\n",
      "Epoch:  1279\n",
      "Training Loss:  0.03326463\n",
      "Validation Loss:  0.035294686\n",
      "Epoch:  1280\n",
      "Training Loss:  0.03278499\n",
      "Validation Loss:  0.032249246\n",
      "Epoch:  1281\n",
      "Training Loss:  0.032528915\n",
      "Validation Loss:  0.026115974\n",
      "Epoch:  1282\n",
      "Training Loss:  0.033165798\n",
      "Validation Loss:  0.02831021\n",
      "Epoch:  1283\n",
      "Training Loss:  0.03195121\n",
      "Validation Loss:  0.027315492\n",
      "Epoch:  1284\n",
      "Training Loss:  0.031865064\n",
      "Validation Loss:  0.027076444\n",
      "Epoch:  1285\n",
      "Training Loss:  0.032142732\n",
      "Validation Loss:  0.029609382\n",
      "Epoch:  1286\n",
      "Training Loss:  0.0328927\n",
      "Validation Loss:  0.033635885\n",
      "Epoch:  1287\n",
      "Training Loss:  0.032305147\n",
      "Validation Loss:  0.027116401\n",
      "Epoch:  1288\n",
      "Training Loss:  0.032431174\n",
      "Validation Loss:  0.031165645\n",
      "Epoch:  1289\n",
      "Training Loss:  0.03161102\n",
      "Validation Loss:  0.02660235\n",
      "Epoch:  1290\n",
      "Training Loss:  0.03133204\n",
      "Validation Loss:  0.033986796\n",
      "Epoch:  1291\n",
      "Training Loss:  0.031596173\n",
      "Validation Loss:  0.030518934\n",
      "Epoch:  1292\n",
      "Training Loss:  0.03213407\n",
      "Validation Loss:  0.027631395\n",
      "Epoch:  1293\n",
      "Training Loss:  0.032132033\n",
      "Validation Loss:  0.028490016\n",
      "Epoch:  1294\n",
      "Training Loss:  0.030717531\n",
      "Validation Loss:  0.027325787\n",
      "Epoch:  1295\n",
      "Training Loss:  0.032008685\n",
      "Validation Loss:  0.031073863\n",
      "Epoch:  1296\n",
      "Training Loss:  0.030692494\n",
      "Validation Loss:  0.028093867\n",
      "Epoch:  1297\n",
      "Training Loss:  0.032157604\n",
      "Validation Loss:  0.03134447\n",
      "Epoch:  1298\n",
      "Training Loss:  0.03197453\n",
      "Validation Loss:  0.031428926\n",
      "Epoch:  1299\n",
      "Training Loss:  0.03160445\n",
      "Validation Loss:  0.026933536\n",
      "Epoch:  1300\n",
      "Training Loss:  0.032554537\n",
      "Validation Loss:  0.027302181\n",
      "Epoch:  1301\n",
      "Training Loss:  0.032436367\n",
      "Validation Loss:  0.026627207\n",
      "Epoch:  1302\n",
      "Training Loss:  0.03163977\n",
      "Validation Loss:  0.029867977\n",
      "Epoch:  1303\n",
      "Training Loss:  0.03075825\n",
      "Validation Loss:  0.026862832\n",
      "Epoch:  1304\n",
      "Training Loss:  0.031684846\n",
      "Validation Loss:  0.030959085\n",
      "Epoch:  1305\n",
      "Training Loss:  0.030889045\n",
      "Validation Loss:  0.031419456\n",
      "Epoch:  1306\n",
      "Training Loss:  0.030952005\n",
      "Validation Loss:  0.02803535\n",
      "Epoch:  1307\n",
      "Training Loss:  0.0312356\n",
      "Validation Loss:  0.02634997\n",
      "Epoch:  1308\n",
      "Training Loss:  0.030660199\n",
      "Validation Loss:  0.02692589\n",
      "Epoch:  1309\n",
      "Training Loss:  0.031129392\n",
      "Validation Loss:  0.030065095\n",
      "Epoch:  1310\n",
      "Training Loss:  0.03076948\n",
      "Validation Loss:  0.028176107\n",
      "Epoch:  1311\n",
      "Training Loss:  0.031736247\n",
      "Validation Loss:  0.030125255\n",
      "Epoch:  1312\n",
      "Training Loss:  0.030818809\n",
      "Validation Loss:  0.027153552\n",
      "Epoch:  1313\n",
      "Training Loss:  0.03158099\n",
      "Validation Loss:  0.0273637\n",
      "Epoch:  1314\n",
      "Training Loss:  0.031086564\n",
      "Validation Loss:  0.029301003\n",
      "Epoch:  1315\n",
      "Training Loss:  0.030743472\n",
      "Validation Loss:  0.028652139\n",
      "Epoch:  1316\n",
      "Training Loss:  0.031163651\n",
      "Validation Loss:  0.028306447\n",
      "Epoch:  1317\n",
      "Training Loss:  0.03025719\n",
      "Validation Loss:  0.027670344\n",
      "Epoch:  1318\n",
      "Training Loss:  0.03103119\n",
      "Validation Loss:  0.027761562\n",
      "Epoch:  1319\n",
      "Training Loss:  0.030261833\n",
      "Validation Loss:  0.027892636\n",
      "Epoch:  1320\n",
      "Training Loss:  0.030873625\n",
      "Validation Loss:  0.029788056\n",
      "Epoch:  1321\n",
      "Training Loss:  0.03129836\n",
      "Validation Loss:  0.029135972\n",
      "Epoch:  1322\n",
      "Training Loss:  0.03081527\n",
      "Validation Loss:  0.027682796\n",
      "Epoch:  1323\n",
      "Training Loss:  0.029554479\n",
      "Validation Loss:  0.026932271\n",
      "Epoch:  1324\n",
      "Training Loss:  0.029929511\n",
      "Validation Loss:  0.029223733\n",
      "Epoch:  1325\n",
      "Training Loss:  0.030488128\n",
      "Validation Loss:  0.02954867\n",
      "Epoch:  1326\n",
      "Training Loss:  0.03149584\n",
      "Validation Loss:  0.02842541\n",
      "Epoch:  1327\n",
      "Training Loss:  0.030830197\n",
      "Validation Loss:  0.028249012\n",
      "Epoch:  1328\n",
      "Training Loss:  0.030509636\n",
      "Validation Loss:  0.028889202\n",
      "Epoch:  1329\n",
      "Training Loss:  0.030950585\n",
      "Validation Loss:  0.03237732\n",
      "Epoch:  1330\n",
      "Training Loss:  0.03126154\n",
      "Validation Loss:  0.027066553\n",
      "Epoch:  1331\n",
      "Training Loss:  0.029322712\n",
      "Validation Loss:  0.027479395\n",
      "Epoch:  1332\n",
      "Training Loss:  0.030889884\n",
      "Validation Loss:  0.028279342\n",
      "Epoch:  1333\n",
      "Training Loss:  0.029931692\n",
      "Validation Loss:  0.029221417\n",
      "Epoch:  1334\n",
      "Training Loss:  0.030365372\n",
      "Validation Loss:  0.026162148\n",
      "Epoch:  1335\n",
      "Training Loss:  0.029779758\n",
      "Validation Loss:  0.026859893\n",
      "Epoch:  1336\n",
      "Training Loss:  0.03036782\n",
      "Validation Loss:  0.02822868\n",
      "Epoch:  1337\n",
      "Training Loss:  0.029117221\n",
      "Validation Loss:  0.027455658\n",
      "Epoch:  1338\n",
      "Training Loss:  0.0294657\n",
      "Validation Loss:  0.03337008\n",
      "Epoch:  1339\n",
      "Training Loss:  0.029870128\n",
      "Validation Loss:  0.025591597\n",
      "Epoch:  1340\n",
      "Training Loss:  0.03058455\n",
      "Validation Loss:  0.026064573\n",
      "Epoch:  1341\n",
      "Training Loss:  0.030850979\n",
      "Validation Loss:  0.026416412\n",
      "Epoch:  1342\n",
      "Training Loss:  0.029872194\n",
      "Validation Loss:  0.02767124\n",
      "Epoch:  1343\n",
      "Training Loss:  0.029893426\n",
      "Validation Loss:  0.02849553\n",
      "Epoch:  1344\n",
      "Training Loss:  0.030849112\n",
      "Validation Loss:  0.02926089\n",
      "Epoch:  1345\n",
      "Training Loss:  0.030325627\n",
      "Validation Loss:  0.025882287\n",
      "Epoch:  1346\n",
      "Training Loss:  0.029173924\n",
      "Validation Loss:  0.026378652\n",
      "Epoch:  1347\n",
      "Training Loss:  0.029620672\n",
      "Validation Loss:  0.028087072\n",
      "Epoch:  1348\n",
      "Training Loss:  0.030333925\n",
      "Validation Loss:  0.032971177\n",
      "Epoch:  1349\n",
      "Training Loss:  0.030105876\n",
      "Validation Loss:  0.02602789\n",
      "Epoch:  1350\n",
      "Training Loss:  0.029182998\n",
      "Validation Loss:  0.030499367\n",
      "Epoch:  1351\n",
      "Training Loss:  0.029788846\n",
      "Validation Loss:  0.025762083\n",
      "Epoch:  1352\n",
      "Training Loss:  0.029981228\n",
      "Validation Loss:  0.026105694\n",
      "Epoch:  1353\n",
      "Training Loss:  0.028690472\n",
      "Validation Loss:  0.03070262\n",
      "Epoch:  1354\n",
      "Training Loss:  0.02947137\n",
      "Validation Loss:  0.026414106\n",
      "Epoch:  1355\n",
      "Training Loss:  0.030393492\n",
      "Validation Loss:  0.025401367\n",
      "Epoch:  1356\n",
      "Training Loss:  0.028547328\n",
      "Validation Loss:  0.027227348\n",
      "Epoch:  1357\n",
      "Training Loss:  0.029651947\n",
      "Validation Loss:  0.035306852\n",
      "Epoch:  1358\n",
      "Training Loss:  0.03006358\n",
      "Validation Loss:  0.027289592\n",
      "Epoch:  1359\n",
      "Training Loss:  0.029784998\n",
      "Validation Loss:  0.026287382\n",
      "Epoch:  1360\n",
      "Training Loss:  0.029843464\n",
      "Validation Loss:  0.032947514\n",
      "Epoch:  1361\n",
      "Training Loss:  0.029156825\n",
      "Validation Loss:  0.02448485\n",
      "Epoch:  1362\n",
      "Training Loss:  0.028481528\n",
      "Validation Loss:  0.02843698\n",
      "Epoch:  1363\n",
      "Training Loss:  0.029742269\n",
      "Validation Loss:  0.027562222\n",
      "Epoch:  1364\n",
      "Training Loss:  0.029602155\n",
      "Validation Loss:  0.029780189\n",
      "Epoch:  1365\n",
      "Training Loss:  0.028864713\n",
      "Validation Loss:  0.02589366\n",
      "Epoch:  1366\n",
      "Training Loss:  0.028071934\n",
      "Validation Loss:  0.024410868\n",
      "Epoch:  1367\n",
      "Training Loss:  0.02950746\n",
      "Validation Loss:  0.025776668\n",
      "Epoch:  1368\n",
      "Training Loss:  0.029489566\n",
      "Validation Loss:  0.025789179\n",
      "Epoch:  1369\n",
      "Training Loss:  0.029564673\n",
      "Validation Loss:  0.026507704\n",
      "Epoch:  1370\n",
      "Training Loss:  0.029342955\n",
      "Validation Loss:  0.024721963\n",
      "Epoch:  1371\n",
      "Training Loss:  0.028559964\n",
      "Validation Loss:  0.025668861\n",
      "Epoch:  1372\n",
      "Training Loss:  0.028392168\n",
      "Validation Loss:  0.02883014\n",
      "Epoch:  1373\n",
      "Training Loss:  0.028201979\n",
      "Validation Loss:  0.028196841\n",
      "Epoch:  1374\n",
      "Training Loss:  0.028904274\n",
      "Validation Loss:  0.03247866\n",
      "Epoch:  1375\n",
      "Training Loss:  0.02859658\n",
      "Validation Loss:  0.027799511\n",
      "Epoch:  1376\n",
      "Training Loss:  0.030134885\n",
      "Validation Loss:  0.026405431\n",
      "Epoch:  1377\n",
      "Training Loss:  0.028582847\n",
      "Validation Loss:  0.024899058\n",
      "Epoch:  1378\n",
      "Training Loss:  0.029079406\n",
      "Validation Loss:  0.026260624\n",
      "Epoch:  1379\n",
      "Training Loss:  0.028786268\n",
      "Validation Loss:  0.027919315\n",
      "Epoch:  1380\n",
      "Training Loss:  0.028719358\n",
      "Validation Loss:  0.026604773\n",
      "Epoch:  1381\n",
      "Training Loss:  0.02961711\n",
      "Validation Loss:  0.030489976\n",
      "Epoch:  1382\n",
      "Training Loss:  0.028311515\n",
      "Validation Loss:  0.034281816\n",
      "Epoch:  1383\n",
      "Training Loss:  0.027837431\n",
      "Validation Loss:  0.02616568\n",
      "Epoch:  1384\n",
      "Training Loss:  0.028190793\n",
      "Validation Loss:  0.026081996\n",
      "Epoch:  1385\n",
      "Training Loss:  0.027807098\n",
      "Validation Loss:  0.029566757\n",
      "Epoch:  1386\n",
      "Training Loss:  0.028520836\n",
      "Validation Loss:  0.031370852\n",
      "Epoch:  1387\n",
      "Training Loss:  0.028489437\n",
      "Validation Loss:  0.028967971\n",
      "Epoch:  1388\n",
      "Training Loss:  0.029070681\n",
      "Validation Loss:  0.025968736\n",
      "Epoch:  1389\n",
      "Training Loss:  0.027932875\n",
      "Validation Loss:  0.026874788\n",
      "Epoch:  1390\n",
      "Training Loss:  0.028900603\n",
      "Validation Loss:  0.024123393\n",
      "Epoch:  1391\n",
      "Training Loss:  0.027982922\n",
      "Validation Loss:  0.024253504\n",
      "Epoch:  1392\n",
      "Training Loss:  0.029075544\n",
      "Validation Loss:  0.025871724\n",
      "Epoch:  1393\n",
      "Training Loss:  0.029805044\n",
      "Validation Loss:  0.034243662\n",
      "Epoch:  1394\n",
      "Training Loss:  0.027662886\n",
      "Validation Loss:  0.02431606\n",
      "Epoch:  1395\n",
      "Training Loss:  0.028739234\n",
      "Validation Loss:  0.03123542\n",
      "Epoch:  1396\n",
      "Training Loss:  0.029227162\n",
      "Validation Loss:  0.024791935\n",
      "Epoch:  1397\n",
      "Training Loss:  0.02918205\n",
      "Validation Loss:  0.022211403\n",
      "Epoch:  1398\n",
      "Training Loss:  0.028088601\n",
      "Validation Loss:  0.023196004\n",
      "Epoch:  1399\n",
      "Training Loss:  0.028543934\n",
      "Validation Loss:  0.022780063\n",
      "Epoch:  1400\n",
      "Training Loss:  0.02814118\n",
      "Validation Loss:  0.025584506\n",
      "Epoch:  1401\n",
      "Training Loss:  0.029673252\n",
      "Validation Loss:  0.023599848\n",
      "Epoch:  1402\n",
      "Training Loss:  0.028392598\n",
      "Validation Loss:  0.024503106\n",
      "Epoch:  1403\n",
      "Training Loss:  0.027554719\n",
      "Validation Loss:  0.024479209\n",
      "Epoch:  1404\n",
      "Training Loss:  0.028048266\n",
      "Validation Loss:  0.02501686\n",
      "Epoch:  1405\n",
      "Training Loss:  0.027626242\n",
      "Validation Loss:  0.026490578\n",
      "Epoch:  1406\n",
      "Training Loss:  0.028378539\n",
      "Validation Loss:  0.025589583\n",
      "Epoch:  1407\n",
      "Training Loss:  0.027897742\n",
      "Validation Loss:  0.022945391\n",
      "Epoch:  1408\n",
      "Training Loss:  0.027951991\n",
      "Validation Loss:  0.025004575\n",
      "Epoch:  1409\n",
      "Training Loss:  0.027022526\n",
      "Validation Loss:  0.029637577\n",
      "Epoch:  1410\n",
      "Training Loss:  0.029656475\n",
      "Validation Loss:  0.023594106\n",
      "Epoch:  1411\n",
      "Training Loss:  0.027794864\n",
      "Validation Loss:  0.02257095\n",
      "Epoch:  1412\n",
      "Training Loss:  0.027636053\n",
      "Validation Loss:  0.024938703\n",
      "Epoch:  1413\n",
      "Training Loss:  0.02819578\n",
      "Validation Loss:  0.025224788\n",
      "Epoch:  1414\n",
      "Training Loss:  0.026418759\n",
      "Validation Loss:  0.02591978\n",
      "Epoch:  1415\n",
      "Training Loss:  0.027317088\n",
      "Validation Loss:  0.025052948\n",
      "Epoch:  1416\n",
      "Training Loss:  0.0268807\n",
      "Validation Loss:  0.026341476\n",
      "Epoch:  1417\n",
      "Training Loss:  0.026825415\n",
      "Validation Loss:  0.025129369\n",
      "Epoch:  1418\n",
      "Training Loss:  0.028138962\n",
      "Validation Loss:  0.033062417\n",
      "Epoch:  1419\n",
      "Training Loss:  0.02773312\n",
      "Validation Loss:  0.023988778\n",
      "Epoch:  1420\n",
      "Training Loss:  0.028109645\n",
      "Validation Loss:  0.022516543\n",
      "Epoch:  1421\n",
      "Training Loss:  0.027935205\n",
      "Validation Loss:  0.025231123\n",
      "Epoch:  1422\n",
      "Training Loss:  0.027394693\n",
      "Validation Loss:  0.023617132\n",
      "Epoch:  1423\n",
      "Training Loss:  0.027203873\n",
      "Validation Loss:  0.025647255\n",
      "Epoch:  1424\n",
      "Training Loss:  0.027864786\n",
      "Validation Loss:  0.02296777\n",
      "Epoch:  1425\n",
      "Training Loss:  0.028633328\n",
      "Validation Loss:  0.030875796\n",
      "Epoch:  1426\n",
      "Training Loss:  0.027547017\n",
      "Validation Loss:  0.025901534\n",
      "Epoch:  1427\n",
      "Training Loss:  0.028049601\n",
      "Validation Loss:  0.024628947\n",
      "Epoch:  1428\n",
      "Training Loss:  0.027158763\n",
      "Validation Loss:  0.022002583\n",
      "Epoch:  1429\n",
      "Training Loss:  0.02664419\n",
      "Validation Loss:  0.02364731\n",
      "Epoch:  1430\n",
      "Training Loss:  0.027430069\n",
      "Validation Loss:  0.0238145\n",
      "Epoch:  1431\n",
      "Training Loss:  0.025716033\n",
      "Validation Loss:  0.023673745\n",
      "Epoch:  1432\n",
      "Training Loss:  0.027522331\n",
      "Validation Loss:  0.023645341\n",
      "Epoch:  1433\n",
      "Training Loss:  0.027029065\n",
      "Validation Loss:  0.02722657\n",
      "Epoch:  1434\n",
      "Training Loss:  0.02732946\n",
      "Validation Loss:  0.025322368\n",
      "Epoch:  1435\n",
      "Training Loss:  0.02636541\n",
      "Validation Loss:  0.02604565\n",
      "Epoch:  1436\n",
      "Training Loss:  0.027603045\n",
      "Validation Loss:  0.024615211\n",
      "Epoch:  1437\n",
      "Training Loss:  0.027600957\n",
      "Validation Loss:  0.024507271\n",
      "Epoch:  1438\n",
      "Training Loss:  0.027055867\n",
      "Validation Loss:  0.021858\n",
      "Epoch:  1439\n",
      "Training Loss:  0.0267411\n",
      "Validation Loss:  0.02344209\n",
      "Epoch:  1440\n",
      "Training Loss:  0.02762895\n",
      "Validation Loss:  0.028924525\n",
      "Epoch:  1441\n",
      "Training Loss:  0.027185943\n",
      "Validation Loss:  0.023409234\n",
      "Epoch:  1442\n",
      "Training Loss:  0.026438642\n",
      "Validation Loss:  0.024059482\n",
      "Epoch:  1443\n",
      "Training Loss:  0.026029414\n",
      "Validation Loss:  0.025848618\n",
      "Epoch:  1444\n",
      "Training Loss:  0.026374267\n",
      "Validation Loss:  0.024774583\n",
      "Epoch:  1445\n",
      "Training Loss:  0.027813684\n",
      "Validation Loss:  0.02277073\n",
      "Epoch:  1446\n",
      "Training Loss:  0.027970845\n",
      "Validation Loss:  0.02295813\n",
      "Epoch:  1447\n",
      "Training Loss:  0.025960175\n",
      "Validation Loss:  0.024832083\n",
      "Epoch:  1448\n",
      "Training Loss:  0.02695161\n",
      "Validation Loss:  0.022560187\n",
      "Epoch:  1449\n",
      "Training Loss:  0.026565686\n",
      "Validation Loss:  0.02431853\n",
      "Epoch:  1450\n",
      "Training Loss:  0.026238967\n",
      "Validation Loss:  0.025430739\n",
      "Epoch:  1451\n",
      "Training Loss:  0.02629715\n",
      "Validation Loss:  0.023651868\n",
      "Epoch:  1452\n",
      "Training Loss:  0.026765766\n",
      "Validation Loss:  0.022546673\n",
      "Epoch:  1453\n",
      "Training Loss:  0.026830481\n",
      "Validation Loss:  0.021202357\n",
      "Epoch:  1454\n",
      "Training Loss:  0.025552774\n",
      "Validation Loss:  0.02549155\n",
      "Epoch:  1455\n",
      "Training Loss:  0.026665965\n",
      "Validation Loss:  0.02403293\n",
      "Epoch:  1456\n",
      "Training Loss:  0.026377227\n",
      "Validation Loss:  0.021710208\n",
      "Epoch:  1457\n",
      "Training Loss:  0.026613228\n",
      "Validation Loss:  0.026080651\n",
      "Epoch:  1458\n",
      "Training Loss:  0.02688624\n",
      "Validation Loss:  0.028018504\n",
      "Epoch:  1459\n",
      "Training Loss:  0.026916638\n",
      "Validation Loss:  0.021774746\n",
      "Epoch:  1460\n",
      "Training Loss:  0.027406167\n",
      "Validation Loss:  0.024245575\n",
      "Epoch:  1461\n",
      "Training Loss:  0.025434112\n",
      "Validation Loss:  0.023677967\n",
      "Epoch:  1462\n",
      "Training Loss:  0.026459849\n",
      "Validation Loss:  0.022552231\n",
      "Epoch:  1463\n",
      "Training Loss:  0.026507914\n",
      "Validation Loss:  0.024445139\n",
      "Epoch:  1464\n",
      "Training Loss:  0.026721513\n",
      "Validation Loss:  0.02644124\n",
      "Epoch:  1465\n",
      "Training Loss:  0.026105303\n",
      "Validation Loss:  0.025241219\n",
      "Epoch:  1466\n",
      "Training Loss:  0.025559757\n",
      "Validation Loss:  0.022878213\n",
      "Epoch:  1467\n",
      "Training Loss:  0.026294531\n",
      "Validation Loss:  0.022833033\n",
      "Epoch:  1468\n",
      "Training Loss:  0.026283411\n",
      "Validation Loss:  0.026749918\n",
      "Epoch:  1469\n",
      "Training Loss:  0.025441945\n",
      "Validation Loss:  0.023350706\n",
      "Epoch:  1470\n",
      "Training Loss:  0.025634877\n",
      "Validation Loss:  0.023998147\n",
      "Epoch:  1471\n",
      "Training Loss:  0.02616301\n",
      "Validation Loss:  0.029949619\n",
      "Epoch:  1472\n",
      "Training Loss:  0.025628025\n",
      "Validation Loss:  0.023866015\n",
      "Epoch:  1473\n",
      "Training Loss:  0.025963392\n",
      "Validation Loss:  0.02145735\n",
      "Epoch:  1474\n",
      "Training Loss:  0.025721464\n",
      "Validation Loss:  0.023588067\n",
      "Epoch:  1475\n",
      "Training Loss:  0.025498595\n",
      "Validation Loss:  0.025493296\n",
      "Epoch:  1476\n",
      "Training Loss:  0.026703691\n",
      "Validation Loss:  0.022663152\n",
      "Epoch:  1477\n",
      "Training Loss:  0.026634516\n",
      "Validation Loss:  0.021645686\n",
      "Epoch:  1478\n",
      "Training Loss:  0.026068425\n",
      "Validation Loss:  0.020828925\n",
      "Epoch:  1479\n",
      "Training Loss:  0.025502244\n",
      "Validation Loss:  0.02755252\n",
      "Epoch:  1480\n",
      "Training Loss:  0.026366318\n",
      "Validation Loss:  0.021108076\n",
      "Epoch:  1481\n",
      "Training Loss:  0.026466124\n",
      "Validation Loss:  0.025884701\n",
      "Epoch:  1482\n",
      "Training Loss:  0.02552169\n",
      "Validation Loss:  0.029122785\n",
      "Epoch:  1483\n",
      "Training Loss:  0.026065357\n",
      "Validation Loss:  0.022392219\n",
      "Epoch:  1484\n",
      "Training Loss:  0.026249917\n",
      "Validation Loss:  0.0215036\n",
      "Epoch:  1485\n",
      "Training Loss:  0.026205461\n",
      "Validation Loss:  0.02482246\n",
      "Epoch:  1486\n",
      "Training Loss:  0.025671067\n",
      "Validation Loss:  0.022574803\n",
      "Epoch:  1487\n",
      "Training Loss:  0.025793528\n",
      "Validation Loss:  0.022651382\n",
      "Epoch:  1488\n",
      "Training Loss:  0.026330737\n",
      "Validation Loss:  0.022862986\n",
      "Epoch:  1489\n",
      "Training Loss:  0.025608031\n",
      "Validation Loss:  0.022591792\n",
      "Epoch:  1490\n",
      "Training Loss:  0.026006982\n",
      "Validation Loss:  0.02283641\n",
      "Epoch:  1491\n",
      "Training Loss:  0.026687752\n",
      "Validation Loss:  0.031153135\n",
      "Epoch:  1492\n",
      "Training Loss:  0.026884591\n",
      "Validation Loss:  0.022139115\n",
      "Epoch:  1493\n",
      "Training Loss:  0.02633859\n",
      "Validation Loss:  0.02277665\n",
      "Epoch:  1494\n",
      "Training Loss:  0.026193878\n",
      "Validation Loss:  0.022581829\n",
      "Epoch:  1495\n",
      "Training Loss:  0.025474323\n",
      "Validation Loss:  0.022529513\n",
      "Epoch:  1496\n",
      "Training Loss:  0.024830883\n",
      "Validation Loss:  0.0225522\n",
      "Epoch:  1497\n",
      "Training Loss:  0.025370028\n",
      "Validation Loss:  0.03042295\n",
      "Epoch:  1498\n",
      "Training Loss:  0.025314927\n",
      "Validation Loss:  0.026713952\n",
      "Epoch:  1499\n",
      "Training Loss:  0.025324648\n",
      "Validation Loss:  0.02222277\n",
      "Epoch:  1500\n",
      "Training Loss:  0.026149273\n",
      "Validation Loss:  0.021480957\n",
      "Epoch:  1501\n",
      "Training Loss:  0.025491033\n",
      "Validation Loss:  0.020431368\n",
      "Epoch:  1502\n",
      "Training Loss:  0.025779633\n",
      "Validation Loss:  0.023664325\n",
      "Epoch:  1503\n",
      "Training Loss:  0.024352664\n",
      "Validation Loss:  0.019817097\n",
      "Epoch:  1504\n",
      "Training Loss:  0.025456939\n",
      "Validation Loss:  0.024111575\n",
      "Epoch:  1505\n",
      "Training Loss:  0.025007505\n",
      "Validation Loss:  0.022327967\n",
      "Epoch:  1506\n",
      "Training Loss:  0.025643198\n",
      "Validation Loss:  0.02242153\n",
      "Epoch:  1507\n",
      "Training Loss:  0.025192704\n",
      "Validation Loss:  0.02330639\n",
      "Epoch:  1508\n",
      "Training Loss:  0.025615856\n",
      "Validation Loss:  0.02215338\n",
      "Epoch:  1509\n",
      "Training Loss:  0.024731336\n",
      "Validation Loss:  0.02146338\n",
      "Epoch:  1510\n",
      "Training Loss:  0.025555698\n",
      "Validation Loss:  0.02074545\n",
      "Epoch:  1511\n",
      "Training Loss:  0.02648337\n",
      "Validation Loss:  0.02046181\n",
      "Epoch:  1512\n",
      "Training Loss:  0.025552666\n",
      "Validation Loss:  0.022673069\n",
      "Epoch:  1513\n",
      "Training Loss:  0.02569361\n",
      "Validation Loss:  0.021418994\n",
      "Epoch:  1514\n",
      "Training Loss:  0.02490771\n",
      "Validation Loss:  0.024673538\n",
      "Epoch:  1515\n",
      "Training Loss:  0.025065368\n",
      "Validation Loss:  0.028149115\n",
      "Epoch:  1516\n",
      "Training Loss:  0.025776612\n",
      "Validation Loss:  0.021048566\n",
      "Epoch:  1517\n",
      "Training Loss:  0.025561543\n",
      "Validation Loss:  0.02981328\n",
      "Epoch:  1518\n",
      "Training Loss:  0.023855012\n",
      "Validation Loss:  0.022409169\n",
      "Epoch:  1519\n",
      "Training Loss:  0.024861543\n",
      "Validation Loss:  0.023274608\n",
      "Epoch:  1520\n",
      "Training Loss:  0.025215058\n",
      "Validation Loss:  0.021619156\n",
      "Epoch:  1521\n",
      "Training Loss:  0.024637215\n",
      "Validation Loss:  0.023067536\n",
      "Epoch:  1522\n",
      "Training Loss:  0.024811309\n",
      "Validation Loss:  0.022808671\n",
      "Epoch:  1523\n",
      "Training Loss:  0.024664091\n",
      "Validation Loss:  0.023836305\n",
      "Epoch:  1524\n",
      "Training Loss:  0.025438903\n",
      "Validation Loss:  0.021693217\n",
      "Epoch:  1525\n",
      "Training Loss:  0.025226608\n",
      "Validation Loss:  0.020477759\n",
      "Epoch:  1526\n",
      "Training Loss:  0.024429759\n",
      "Validation Loss:  0.02640137\n",
      "Epoch:  1527\n",
      "Training Loss:  0.02537143\n",
      "Validation Loss:  0.02329413\n",
      "Epoch:  1528\n",
      "Training Loss:  0.024184812\n",
      "Validation Loss:  0.027019588\n",
      "Epoch:  1529\n",
      "Training Loss:  0.024938757\n",
      "Validation Loss:  0.020471262\n",
      "Epoch:  1530\n",
      "Training Loss:  0.024852615\n",
      "Validation Loss:  0.02118762\n",
      "Epoch:  1531\n",
      "Training Loss:  0.024145724\n",
      "Validation Loss:  0.019533629\n",
      "Epoch:  1532\n",
      "Training Loss:  0.023308177\n",
      "Validation Loss:  0.029232627\n",
      "Epoch:  1533\n",
      "Training Loss:  0.024939578\n",
      "Validation Loss:  0.028597062\n",
      "Epoch:  1534\n",
      "Training Loss:  0.024532244\n",
      "Validation Loss:  0.022467306\n",
      "Epoch:  1535\n",
      "Training Loss:  0.023883784\n",
      "Validation Loss:  0.022066606\n",
      "Epoch:  1536\n",
      "Training Loss:  0.024307057\n",
      "Validation Loss:  0.021790473\n",
      "Epoch:  1537\n",
      "Training Loss:  0.025088973\n",
      "Validation Loss:  0.021482123\n",
      "Epoch:  1538\n",
      "Training Loss:  0.023411958\n",
      "Validation Loss:  0.023427708\n",
      "Epoch:  1539\n",
      "Training Loss:  0.024835939\n",
      "Validation Loss:  0.021676635\n",
      "Epoch:  1540\n",
      "Training Loss:  0.024231773\n",
      "Validation Loss:  0.02046605\n",
      "Epoch:  1541\n",
      "Training Loss:  0.025290031\n",
      "Validation Loss:  0.027822636\n",
      "Epoch:  1542\n",
      "Training Loss:  0.023763597\n",
      "Validation Loss:  0.022346413\n",
      "Epoch:  1543\n",
      "Training Loss:  0.024437122\n",
      "Validation Loss:  0.020070387\n",
      "Epoch:  1544\n",
      "Training Loss:  0.025203764\n",
      "Validation Loss:  0.021854043\n",
      "Epoch:  1545\n",
      "Training Loss:  0.025284285\n",
      "Validation Loss:  0.02332896\n",
      "Epoch:  1546\n",
      "Training Loss:  0.02413429\n",
      "Validation Loss:  0.022556072\n",
      "Epoch:  1547\n",
      "Training Loss:  0.023637228\n",
      "Validation Loss:  0.020094896\n",
      "Epoch:  1548\n",
      "Training Loss:  0.024462845\n",
      "Validation Loss:  0.02135036\n",
      "Epoch:  1549\n",
      "Training Loss:  0.024648065\n",
      "Validation Loss:  0.020336114\n",
      "Epoch:  1550\n",
      "Training Loss:  0.023312226\n",
      "Validation Loss:  0.021607054\n",
      "Epoch:  1551\n",
      "Training Loss:  0.024054673\n",
      "Validation Loss:  0.020263622\n",
      "Epoch:  1552\n",
      "Training Loss:  0.023679579\n",
      "Validation Loss:  0.02123444\n",
      "Epoch:  1553\n",
      "Training Loss:  0.023256276\n",
      "Validation Loss:  0.025117794\n",
      "Epoch:  1554\n",
      "Training Loss:  0.025477514\n",
      "Validation Loss:  0.02091497\n",
      "Epoch:  1555\n",
      "Training Loss:  0.024898842\n",
      "Validation Loss:  0.02612414\n",
      "Epoch:  1556\n",
      "Training Loss:  0.024136353\n",
      "Validation Loss:  0.019822622\n",
      "Epoch:  1557\n",
      "Training Loss:  0.024733782\n",
      "Validation Loss:  0.019638086\n",
      "Epoch:  1558\n",
      "Training Loss:  0.024185816\n",
      "Validation Loss:  0.021395147\n",
      "Epoch:  1559\n",
      "Training Loss:  0.024020154\n",
      "Validation Loss:  0.021590026\n",
      "Epoch:  1560\n",
      "Training Loss:  0.025660044\n",
      "Validation Loss:  0.020995313\n",
      "Epoch:  1561\n",
      "Training Loss:  0.024872104\n",
      "Validation Loss:  0.026786068\n",
      "Epoch:  1562\n",
      "Training Loss:  0.024337681\n",
      "Validation Loss:  0.024579013\n",
      "Epoch:  1563\n",
      "Training Loss:  0.023240373\n",
      "Validation Loss:  0.02090498\n",
      "Epoch:  1564\n",
      "Training Loss:  0.023872897\n",
      "Validation Loss:  0.019695207\n",
      "Epoch:  1565\n",
      "Training Loss:  0.023570301\n",
      "Validation Loss:  0.01948908\n",
      "Epoch:  1566\n",
      "Training Loss:  0.024575392\n",
      "Validation Loss:  0.02171743\n",
      "Epoch:  1567\n",
      "Training Loss:  0.024473133\n",
      "Validation Loss:  0.02740491\n",
      "Epoch:  1568\n",
      "Training Loss:  0.023063282\n",
      "Validation Loss:  0.027674844\n",
      "Epoch:  1569\n",
      "Training Loss:  0.02376006\n",
      "Validation Loss:  0.02617299\n",
      "Epoch:  1570\n",
      "Training Loss:  0.023253214\n",
      "Validation Loss:  0.02041847\n",
      "Epoch:  1571\n",
      "Training Loss:  0.022623418\n",
      "Validation Loss:  0.0213746\n",
      "Epoch:  1572\n",
      "Training Loss:  0.024634624\n",
      "Validation Loss:  0.028137423\n",
      "Epoch:  1573\n",
      "Training Loss:  0.023703905\n",
      "Validation Loss:  0.021410018\n",
      "Epoch:  1574\n",
      "Training Loss:  0.02455147\n",
      "Validation Loss:  0.021969272\n",
      "Epoch:  1575\n",
      "Training Loss:  0.024423786\n",
      "Validation Loss:  0.026414579\n",
      "Epoch:  1576\n",
      "Training Loss:  0.024238514\n",
      "Validation Loss:  0.021100938\n",
      "Epoch:  1577\n",
      "Training Loss:  0.023590855\n",
      "Validation Loss:  0.020139704\n",
      "Epoch:  1578\n",
      "Training Loss:  0.024703754\n",
      "Validation Loss:  0.019254917\n",
      "Epoch:  1579\n",
      "Training Loss:  0.02365032\n",
      "Validation Loss:  0.020570533\n",
      "Epoch:  1580\n",
      "Training Loss:  0.023963526\n",
      "Validation Loss:  0.018633442\n",
      "Epoch:  1581\n",
      "Training Loss:  0.02500868\n",
      "Validation Loss:  0.02121441\n",
      "Epoch:  1582\n",
      "Training Loss:  0.023560723\n",
      "Validation Loss:  0.019921241\n",
      "Epoch:  1583\n",
      "Training Loss:  0.023323867\n",
      "Validation Loss:  0.027328314\n",
      "Epoch:  1584\n",
      "Training Loss:  0.024096036\n",
      "Validation Loss:  0.019984232\n",
      "Epoch:  1585\n",
      "Training Loss:  0.022953708\n",
      "Validation Loss:  0.01938197\n",
      "Epoch:  1586\n",
      "Training Loss:  0.023680648\n",
      "Validation Loss:  0.020462856\n",
      "Epoch:  1587\n",
      "Training Loss:  0.024252037\n",
      "Validation Loss:  0.021506758\n",
      "Epoch:  1588\n",
      "Training Loss:  0.024648197\n",
      "Validation Loss:  0.019869326\n",
      "Epoch:  1589\n",
      "Training Loss:  0.023076952\n",
      "Validation Loss:  0.024192674\n",
      "Epoch:  1590\n",
      "Training Loss:  0.024000928\n",
      "Validation Loss:  0.022315526\n",
      "Epoch:  1591\n",
      "Training Loss:  0.023412725\n",
      "Validation Loss:  0.019626101\n",
      "Epoch:  1592\n",
      "Training Loss:  0.023572795\n",
      "Validation Loss:  0.023317382\n",
      "Epoch:  1593\n",
      "Training Loss:  0.024779769\n",
      "Validation Loss:  0.02082319\n",
      "Epoch:  1594\n",
      "Training Loss:  0.022721127\n",
      "Validation Loss:  0.019325916\n",
      "Epoch:  1595\n",
      "Training Loss:  0.023027182\n",
      "Validation Loss:  0.019764766\n",
      "Epoch:  1596\n",
      "Training Loss:  0.025226003\n",
      "Validation Loss:  0.020009251\n",
      "Epoch:  1597\n",
      "Training Loss:  0.023570016\n",
      "Validation Loss:  0.02048575\n",
      "Epoch:  1598\n",
      "Training Loss:  0.022749199\n",
      "Validation Loss:  0.020809887\n",
      "Epoch:  1599\n",
      "Training Loss:  0.023467552\n",
      "Validation Loss:  0.019305699\n",
      "Epoch:  1600\n",
      "Training Loss:  0.023309654\n",
      "Validation Loss:  0.020786703\n",
      "Epoch:  1601\n",
      "Training Loss:  0.02283019\n",
      "Validation Loss:  0.022588884\n",
      "Epoch:  1602\n",
      "Training Loss:  0.02421634\n",
      "Validation Loss:  0.019417798\n",
      "Epoch:  1603\n",
      "Training Loss:  0.022849055\n",
      "Validation Loss:  0.020508787\n",
      "Epoch:  1604\n",
      "Training Loss:  0.024083698\n",
      "Validation Loss:  0.020624978\n",
      "Epoch:  1605\n",
      "Training Loss:  0.023636986\n",
      "Validation Loss:  0.020487675\n",
      "Epoch:  1606\n",
      "Training Loss:  0.022654807\n",
      "Validation Loss:  0.021827064\n",
      "Epoch:  1607\n",
      "Training Loss:  0.023188388\n",
      "Validation Loss:  0.018365143\n",
      "Epoch:  1608\n",
      "Training Loss:  0.022729635\n",
      "Validation Loss:  0.018664433\n",
      "Epoch:  1609\n",
      "Training Loss:  0.023936981\n",
      "Validation Loss:  0.0197144\n",
      "Epoch:  1610\n",
      "Training Loss:  0.023600394\n",
      "Validation Loss:  0.020540448\n",
      "Epoch:  1611\n",
      "Training Loss:  0.022463653\n",
      "Validation Loss:  0.025845105\n",
      "Epoch:  1612\n",
      "Training Loss:  0.022834726\n",
      "Validation Loss:  0.01869467\n",
      "Epoch:  1613\n",
      "Training Loss:  0.02304307\n",
      "Validation Loss:  0.021077454\n",
      "Epoch:  1614\n",
      "Training Loss:  0.023049891\n",
      "Validation Loss:  0.021427035\n",
      "Epoch:  1615\n",
      "Training Loss:  0.022971522\n",
      "Validation Loss:  0.019826258\n",
      "Epoch:  1616\n",
      "Training Loss:  0.022833081\n",
      "Validation Loss:  0.021406844\n",
      "Epoch:  1617\n",
      "Training Loss:  0.023669215\n",
      "Validation Loss:  0.019367566\n",
      "Epoch:  1618\n",
      "Training Loss:  0.022975113\n",
      "Validation Loss:  0.018750517\n",
      "Epoch:  1619\n",
      "Training Loss:  0.022242395\n",
      "Validation Loss:  0.018518118\n",
      "Epoch:  1620\n",
      "Training Loss:  0.023062019\n",
      "Validation Loss:  0.02366887\n",
      "Epoch:  1621\n",
      "Training Loss:  0.02268733\n",
      "Validation Loss:  0.018794278\n",
      "Epoch:  1622\n",
      "Training Loss:  0.021917753\n",
      "Validation Loss:  0.020963294\n",
      "Epoch:  1623\n",
      "Training Loss:  0.023824984\n",
      "Validation Loss:  0.019034704\n",
      "Epoch:  1624\n",
      "Training Loss:  0.022344688\n",
      "Validation Loss:  0.022224518\n",
      "Epoch:  1625\n",
      "Training Loss:  0.02344182\n",
      "Validation Loss:  0.018518047\n",
      "Epoch:  1626\n",
      "Training Loss:  0.021384718\n",
      "Validation Loss:  0.02050715\n",
      "Epoch:  1627\n",
      "Training Loss:  0.022626912\n",
      "Validation Loss:  0.021184787\n",
      "Epoch:  1628\n",
      "Training Loss:  0.02202126\n",
      "Validation Loss:  0.01847974\n",
      "Epoch:  1629\n",
      "Training Loss:  0.022322536\n",
      "Validation Loss:  0.021348732\n",
      "Epoch:  1630\n",
      "Training Loss:  0.023523543\n",
      "Validation Loss:  0.023151288\n",
      "Epoch:  1631\n",
      "Training Loss:  0.02297889\n",
      "Validation Loss:  0.019941725\n",
      "Epoch:  1632\n",
      "Training Loss:  0.022548629\n",
      "Validation Loss:  0.025428781\n",
      "Epoch:  1633\n",
      "Training Loss:  0.022117741\n",
      "Validation Loss:  0.017366951\n",
      "Epoch:  1634\n",
      "Training Loss:  0.023170102\n",
      "Validation Loss:  0.019840246\n",
      "Epoch:  1635\n",
      "Training Loss:  0.023500621\n",
      "Validation Loss:  0.019016404\n",
      "Epoch:  1636\n",
      "Training Loss:  0.022623293\n",
      "Validation Loss:  0.018368496\n",
      "Epoch:  1637\n",
      "Training Loss:  0.021936202\n",
      "Validation Loss:  0.019495355\n",
      "Epoch:  1638\n",
      "Training Loss:  0.021920383\n",
      "Validation Loss:  0.019183824\n",
      "Epoch:  1639\n",
      "Training Loss:  0.023445453\n",
      "Validation Loss:  0.027712129\n",
      "Epoch:  1640\n",
      "Training Loss:  0.022777451\n",
      "Validation Loss:  0.025696531\n",
      "Epoch:  1641\n",
      "Training Loss:  0.022519292\n",
      "Validation Loss:  0.019832347\n",
      "Epoch:  1642\n",
      "Training Loss:  0.023426546\n",
      "Validation Loss:  0.019469181\n",
      "Epoch:  1643\n",
      "Training Loss:  0.023201311\n",
      "Validation Loss:  0.019315163\n",
      "Epoch:  1644\n",
      "Training Loss:  0.022068374\n",
      "Validation Loss:  0.023262957\n",
      "Epoch:  1645\n",
      "Training Loss:  0.022541754\n",
      "Validation Loss:  0.018818468\n",
      "Epoch:  1646\n",
      "Training Loss:  0.022521371\n",
      "Validation Loss:  0.0179665\n",
      "Epoch:  1647\n",
      "Training Loss:  0.022613844\n",
      "Validation Loss:  0.01921868\n",
      "Epoch:  1648\n",
      "Training Loss:  0.022479547\n",
      "Validation Loss:  0.019753428\n",
      "Epoch:  1649\n",
      "Training Loss:  0.022113284\n",
      "Validation Loss:  0.018225228\n",
      "Epoch:  1650\n",
      "Training Loss:  0.022127131\n",
      "Validation Loss:  0.021455595\n",
      "Epoch:  1651\n",
      "Training Loss:  0.022862269\n",
      "Validation Loss:  0.019364107\n",
      "Epoch:  1652\n",
      "Training Loss:  0.02165723\n",
      "Validation Loss:  0.01867641\n",
      "Epoch:  1653\n",
      "Training Loss:  0.022577828\n",
      "Validation Loss:  0.017949412\n",
      "Epoch:  1654\n",
      "Training Loss:  0.022233713\n",
      "Validation Loss:  0.018162722\n",
      "Epoch:  1655\n",
      "Training Loss:  0.023171589\n",
      "Validation Loss:  0.024865678\n",
      "Epoch:  1656\n",
      "Training Loss:  0.02285564\n",
      "Validation Loss:  0.021846553\n",
      "Epoch:  1657\n",
      "Training Loss:  0.0230582\n",
      "Validation Loss:  0.01839812\n",
      "Epoch:  1658\n",
      "Training Loss:  0.022091217\n",
      "Validation Loss:  0.020752227\n",
      "Epoch:  1659\n",
      "Training Loss:  0.02232301\n",
      "Validation Loss:  0.019517181\n",
      "Epoch:  1660\n",
      "Training Loss:  0.022061767\n",
      "Validation Loss:  0.020352853\n",
      "Epoch:  1661\n",
      "Training Loss:  0.022154463\n",
      "Validation Loss:  0.02113998\n",
      "Epoch:  1662\n",
      "Training Loss:  0.022416957\n",
      "Validation Loss:  0.018779261\n",
      "Epoch:  1663\n",
      "Training Loss:  0.023513908\n",
      "Validation Loss:  0.017735986\n",
      "Epoch:  1664\n",
      "Training Loss:  0.022829374\n",
      "Validation Loss:  0.019333573\n",
      "Epoch:  1665\n",
      "Training Loss:  0.022196524\n",
      "Validation Loss:  0.021058133\n",
      "Epoch:  1666\n",
      "Training Loss:  0.022181744\n",
      "Validation Loss:  0.021317763\n",
      "Epoch:  1667\n",
      "Training Loss:  0.022845913\n",
      "Validation Loss:  0.017336182\n",
      "Epoch:  1668\n",
      "Training Loss:  0.021454925\n",
      "Validation Loss:  0.018126832\n",
      "Epoch:  1669\n",
      "Training Loss:  0.021918986\n",
      "Validation Loss:  0.020547764\n",
      "Epoch:  1670\n",
      "Training Loss:  0.022084234\n",
      "Validation Loss:  0.024161702\n",
      "Epoch:  1671\n",
      "Training Loss:  0.020706072\n",
      "Validation Loss:  0.018458528\n",
      "Epoch:  1672\n",
      "Training Loss:  0.022452798\n",
      "Validation Loss:  0.0179755\n",
      "Epoch:  1673\n",
      "Training Loss:  0.022309747\n",
      "Validation Loss:  0.019229848\n",
      "Epoch:  1674\n",
      "Training Loss:  0.022290317\n",
      "Validation Loss:  0.02519157\n",
      "Epoch:  1675\n",
      "Training Loss:  0.021457197\n",
      "Validation Loss:  0.018203558\n",
      "Epoch:  1676\n",
      "Training Loss:  0.021872526\n",
      "Validation Loss:  0.020198839\n",
      "Epoch:  1677\n",
      "Training Loss:  0.022054274\n",
      "Validation Loss:  0.018938906\n",
      "Epoch:  1678\n",
      "Training Loss:  0.02149873\n",
      "Validation Loss:  0.017453391\n",
      "Epoch:  1679\n",
      "Training Loss:  0.022029053\n",
      "Validation Loss:  0.022194305\n",
      "Epoch:  1680\n",
      "Training Loss:  0.021913761\n",
      "Validation Loss:  0.026069725\n",
      "Epoch:  1681\n",
      "Training Loss:  0.022792505\n",
      "Validation Loss:  0.022727618\n",
      "Epoch:  1682\n",
      "Training Loss:  0.02307062\n",
      "Validation Loss:  0.018707177\n",
      "Epoch:  1683\n",
      "Training Loss:  0.02179916\n",
      "Validation Loss:  0.018408695\n",
      "Epoch:  1684\n",
      "Training Loss:  0.022046335\n",
      "Validation Loss:  0.01823831\n",
      "Epoch:  1685\n",
      "Training Loss:  0.021829462\n",
      "Validation Loss:  0.024506986\n",
      "Epoch:  1686\n",
      "Training Loss:  0.021455308\n",
      "Validation Loss:  0.01818524\n",
      "Epoch:  1687\n",
      "Training Loss:  0.021262312\n",
      "Validation Loss:  0.0202045\n",
      "Epoch:  1688\n",
      "Training Loss:  0.02199767\n",
      "Validation Loss:  0.01953417\n",
      "Epoch:  1689\n",
      "Training Loss:  0.02260993\n",
      "Validation Loss:  0.018309105\n",
      "Epoch:  1690\n",
      "Training Loss:  0.022959398\n",
      "Validation Loss:  0.02453048\n",
      "Epoch:  1691\n",
      "Training Loss:  0.022708714\n",
      "Validation Loss:  0.020837948\n",
      "Epoch:  1692\n",
      "Training Loss:  0.021416344\n",
      "Validation Loss:  0.018031536\n",
      "Epoch:  1693\n",
      "Training Loss:  0.022684302\n",
      "Validation Loss:  0.018389406\n",
      "Epoch:  1694\n",
      "Training Loss:  0.021833984\n",
      "Validation Loss:  0.017959157\n",
      "Epoch:  1695\n",
      "Training Loss:  0.02169451\n",
      "Validation Loss:  0.021720009\n",
      "Epoch:  1696\n",
      "Training Loss:  0.021973025\n",
      "Validation Loss:  0.017739924\n",
      "Epoch:  1697\n",
      "Training Loss:  0.021741763\n",
      "Validation Loss:  0.018041296\n",
      "Epoch:  1698\n",
      "Training Loss:  0.022033287\n",
      "Validation Loss:  0.016670158\n",
      "Epoch:  1699\n",
      "Training Loss:  0.021995028\n",
      "Validation Loss:  0.018752642\n",
      "Epoch:  1700\n",
      "Training Loss:  0.020812541\n",
      "Validation Loss:  0.018186552\n",
      "Epoch:  1701\n",
      "Training Loss:  0.020747863\n",
      "Validation Loss:  0.017387684\n",
      "Epoch:  1702\n",
      "Training Loss:  0.022936292\n",
      "Validation Loss:  0.018487321\n",
      "Epoch:  1703\n",
      "Training Loss:  0.020565884\n",
      "Validation Loss:  0.023811115\n",
      "Epoch:  1704\n",
      "Training Loss:  0.021617139\n",
      "Validation Loss:  0.026693486\n",
      "Epoch:  1705\n",
      "Training Loss:  0.02167813\n",
      "Validation Loss:  0.019887026\n",
      "Epoch:  1706\n",
      "Training Loss:  0.021160202\n",
      "Validation Loss:  0.019531915\n",
      "Epoch:  1707\n",
      "Training Loss:  0.021014733\n",
      "Validation Loss:  0.018190471\n",
      "Epoch:  1708\n",
      "Training Loss:  0.022559274\n",
      "Validation Loss:  0.017841203\n",
      "Epoch:  1709\n",
      "Training Loss:  0.021273492\n",
      "Validation Loss:  0.01778735\n",
      "Epoch:  1710\n",
      "Training Loss:  0.021879228\n",
      "Validation Loss:  0.01645607\n",
      "Epoch:  1711\n",
      "Training Loss:  0.022749849\n",
      "Validation Loss:  0.018920515\n",
      "Epoch:  1712\n",
      "Training Loss:  0.02113526\n",
      "Validation Loss:  0.019849023\n",
      "Epoch:  1713\n",
      "Training Loss:  0.021752836\n",
      "Validation Loss:  0.019300384\n",
      "Epoch:  1714\n",
      "Training Loss:  0.021902429\n",
      "Validation Loss:  0.020358741\n",
      "Epoch:  1715\n",
      "Training Loss:  0.021880096\n",
      "Validation Loss:  0.024096789\n",
      "Epoch:  1716\n",
      "Training Loss:  0.020655772\n",
      "Validation Loss:  0.018307352\n",
      "Epoch:  1717\n",
      "Training Loss:  0.022002298\n",
      "Validation Loss:  0.02086158\n",
      "Epoch:  1718\n",
      "Training Loss:  0.022638416\n",
      "Validation Loss:  0.017539198\n",
      "Epoch:  1719\n",
      "Training Loss:  0.021261884\n",
      "Validation Loss:  0.021002302\n",
      "Epoch:  1720\n",
      "Training Loss:  0.021064753\n",
      "Validation Loss:  0.019475238\n",
      "Epoch:  1721\n",
      "Training Loss:  0.020871501\n",
      "Validation Loss:  0.020846635\n",
      "Epoch:  1722\n",
      "Training Loss:  0.021401688\n",
      "Validation Loss:  0.01808159\n",
      "Epoch:  1723\n",
      "Training Loss:  0.02017024\n",
      "Validation Loss:  0.019033687\n",
      "Epoch:  1724\n",
      "Training Loss:  0.020888455\n",
      "Validation Loss:  0.020391418\n",
      "Epoch:  1725\n",
      "Training Loss:  0.021565516\n",
      "Validation Loss:  0.017717524\n",
      "Epoch:  1726\n",
      "Training Loss:  0.021431513\n",
      "Validation Loss:  0.018106649\n",
      "Epoch:  1727\n",
      "Training Loss:  0.021867374\n",
      "Validation Loss:  0.01831085\n",
      "Epoch:  1728\n",
      "Training Loss:  0.02078074\n",
      "Validation Loss:  0.017371858\n",
      "Epoch:  1729\n",
      "Training Loss:  0.02134953\n",
      "Validation Loss:  0.017827718\n",
      "Epoch:  1730\n",
      "Training Loss:  0.021161063\n",
      "Validation Loss:  0.017134355\n",
      "Epoch:  1731\n",
      "Training Loss:  0.022233276\n",
      "Validation Loss:  0.017154468\n",
      "Epoch:  1732\n",
      "Training Loss:  0.021476937\n",
      "Validation Loss:  0.0172597\n",
      "Epoch:  1733\n",
      "Training Loss:  0.02123762\n",
      "Validation Loss:  0.016718796\n",
      "Epoch:  1734\n",
      "Training Loss:  0.02060409\n",
      "Validation Loss:  0.022299806\n",
      "Epoch:  1735\n",
      "Training Loss:  0.021000648\n",
      "Validation Loss:  0.018431883\n",
      "Epoch:  1736\n",
      "Training Loss:  0.020939773\n",
      "Validation Loss:  0.018766979\n",
      "Epoch:  1737\n",
      "Training Loss:  0.020977566\n",
      "Validation Loss:  0.016963625\n",
      "Epoch:  1738\n",
      "Training Loss:  0.02151016\n",
      "Validation Loss:  0.017551286\n",
      "Epoch:  1739\n",
      "Training Loss:  0.021020712\n",
      "Validation Loss:  0.01941667\n",
      "Epoch:  1740\n",
      "Training Loss:  0.022211464\n",
      "Validation Loss:  0.018348662\n",
      "Epoch:  1741\n",
      "Training Loss:  0.02025547\n",
      "Validation Loss:  0.0185813\n",
      "Epoch:  1742\n",
      "Training Loss:  0.020589184\n",
      "Validation Loss:  0.017755343\n",
      "Epoch:  1743\n",
      "Training Loss:  0.019713469\n",
      "Validation Loss:  0.01806772\n",
      "Epoch:  1744\n",
      "Training Loss:  0.021052469\n",
      "Validation Loss:  0.018564543\n",
      "Epoch:  1745\n",
      "Training Loss:  0.020330474\n",
      "Validation Loss:  0.01797124\n",
      "Epoch:  1746\n",
      "Training Loss:  0.020031732\n",
      "Validation Loss:  0.024419168\n",
      "Epoch:  1747\n",
      "Training Loss:  0.02122161\n",
      "Validation Loss:  0.023920959\n",
      "Epoch:  1748\n",
      "Training Loss:  0.020201389\n",
      "Validation Loss:  0.016562114\n",
      "Epoch:  1749\n",
      "Training Loss:  0.020530622\n",
      "Validation Loss:  0.018042963\n",
      "Epoch:  1750\n",
      "Training Loss:  0.020405347\n",
      "Validation Loss:  0.016875729\n",
      "Epoch:  1751\n",
      "Training Loss:  0.020393541\n",
      "Validation Loss:  0.021499574\n",
      "Epoch:  1752\n",
      "Training Loss:  0.020627314\n",
      "Validation Loss:  0.01585267\n",
      "Epoch:  1753\n",
      "Training Loss:  0.021124851\n",
      "Validation Loss:  0.016718091\n",
      "Epoch:  1754\n",
      "Training Loss:  0.020938892\n",
      "Validation Loss:  0.020046378\n",
      "Epoch:  1755\n",
      "Training Loss:  0.021218855\n",
      "Validation Loss:  0.024775699\n",
      "Epoch:  1756\n",
      "Training Loss:  0.019566325\n",
      "Validation Loss:  0.017737838\n",
      "Epoch:  1757\n",
      "Training Loss:  0.021986451\n",
      "Validation Loss:  0.01757297\n",
      "Epoch:  1758\n",
      "Training Loss:  0.020264909\n",
      "Validation Loss:  0.017847322\n",
      "Epoch:  1759\n",
      "Training Loss:  0.020766903\n",
      "Validation Loss:  0.022764103\n",
      "Epoch:  1760\n",
      "Training Loss:  0.020518735\n",
      "Validation Loss:  0.01705078\n",
      "Epoch:  1761\n",
      "Training Loss:  0.020059107\n",
      "Validation Loss:  0.018634664\n",
      "Epoch:  1762\n",
      "Training Loss:  0.020193208\n",
      "Validation Loss:  0.018511942\n",
      "Epoch:  1763\n",
      "Training Loss:  0.020430647\n",
      "Validation Loss:  0.017979667\n",
      "Epoch:  1764\n",
      "Training Loss:  0.02049968\n",
      "Validation Loss:  0.02333194\n",
      "Epoch:  1765\n",
      "Training Loss:  0.020229576\n",
      "Validation Loss:  0.018033037\n",
      "Epoch:  1766\n",
      "Training Loss:  0.020321967\n",
      "Validation Loss:  0.024096906\n",
      "Epoch:  1767\n",
      "Training Loss:  0.020403791\n",
      "Validation Loss:  0.017153898\n",
      "Epoch:  1768\n",
      "Training Loss:  0.020876925\n",
      "Validation Loss:  0.018481368\n",
      "Epoch:  1769\n",
      "Training Loss:  0.020213269\n",
      "Validation Loss:  0.019697033\n",
      "Epoch:  1770\n",
      "Training Loss:  0.020274237\n",
      "Validation Loss:  0.016834764\n",
      "Epoch:  1771\n",
      "Training Loss:  0.020514017\n",
      "Validation Loss:  0.018093029\n",
      "Epoch:  1772\n",
      "Training Loss:  0.019705163\n",
      "Validation Loss:  0.017459856\n",
      "Epoch:  1773\n",
      "Training Loss:  0.021089677\n",
      "Validation Loss:  0.017813507\n",
      "Epoch:  1774\n",
      "Training Loss:  0.020057408\n",
      "Validation Loss:  0.017945273\n",
      "Epoch:  1775\n",
      "Training Loss:  0.019894738\n",
      "Validation Loss:  0.016925586\n",
      "Epoch:  1776\n",
      "Training Loss:  0.021249888\n",
      "Validation Loss:  0.01797597\n",
      "Epoch:  1777\n",
      "Training Loss:  0.02055726\n",
      "Validation Loss:  0.01570207\n",
      "Epoch:  1778\n",
      "Training Loss:  0.020489242\n",
      "Validation Loss:  0.016330445\n",
      "Epoch:  1779\n",
      "Training Loss:  0.021273263\n",
      "Validation Loss:  0.017674437\n",
      "Epoch:  1780\n",
      "Training Loss:  0.019686557\n",
      "Validation Loss:  0.019663064\n",
      "Epoch:  1781\n",
      "Training Loss:  0.021077078\n",
      "Validation Loss:  0.02404914\n",
      "Epoch:  1782\n",
      "Training Loss:  0.019502696\n",
      "Validation Loss:  0.016537035\n",
      "Epoch:  1783\n",
      "Training Loss:  0.020852065\n",
      "Validation Loss:  0.017194102\n",
      "Epoch:  1784\n",
      "Training Loss:  0.020417487\n",
      "Validation Loss:  0.024444655\n",
      "Epoch:  1785\n",
      "Training Loss:  0.02162722\n",
      "Validation Loss:  0.015030686\n",
      "Epoch:  1786\n",
      "Training Loss:  0.019785155\n",
      "Validation Loss:  0.017738098\n",
      "Epoch:  1787\n",
      "Training Loss:  0.020949444\n",
      "Validation Loss:  0.017047787\n",
      "Epoch:  1788\n",
      "Training Loss:  0.019325813\n",
      "Validation Loss:  0.019206876\n",
      "Epoch:  1789\n",
      "Training Loss:  0.020219585\n",
      "Validation Loss:  0.015939467\n",
      "Epoch:  1790\n",
      "Training Loss:  0.019330641\n",
      "Validation Loss:  0.015939938\n",
      "Epoch:  1791\n",
      "Training Loss:  0.021469608\n",
      "Validation Loss:  0.018671593\n",
      "Epoch:  1792\n",
      "Training Loss:  0.02066149\n",
      "Validation Loss:  0.01773442\n",
      "Epoch:  1793\n",
      "Training Loss:  0.019455299\n",
      "Validation Loss:  0.018396324\n",
      "Epoch:  1794\n",
      "Training Loss:  0.020198222\n",
      "Validation Loss:  0.017199822\n",
      "Epoch:  1795\n",
      "Training Loss:  0.020660853\n",
      "Validation Loss:  0.023449063\n",
      "Epoch:  1796\n",
      "Training Loss:  0.019660423\n",
      "Validation Loss:  0.016132949\n",
      "Epoch:  1797\n",
      "Training Loss:  0.019427894\n",
      "Validation Loss:  0.01652364\n",
      "Epoch:  1798\n",
      "Training Loss:  0.019367859\n",
      "Validation Loss:  0.017922612\n",
      "Epoch:  1799\n",
      "Training Loss:  0.019867295\n",
      "Validation Loss:  0.01595132\n",
      "Epoch:  1800\n",
      "Training Loss:  0.0207319\n",
      "Validation Loss:  0.018850023\n",
      "Epoch:  1801\n",
      "Training Loss:  0.019353583\n",
      "Validation Loss:  0.01891919\n",
      "Epoch:  1802\n",
      "Training Loss:  0.01954258\n",
      "Validation Loss:  0.018439123\n",
      "Epoch:  1803\n",
      "Training Loss:  0.020012755\n",
      "Validation Loss:  0.017495813\n",
      "Epoch:  1804\n",
      "Training Loss:  0.019957826\n",
      "Validation Loss:  0.01933852\n",
      "Epoch:  1805\n",
      "Training Loss:  0.020395108\n",
      "Validation Loss:  0.01679459\n",
      "Epoch:  1806\n",
      "Training Loss:  0.020066056\n",
      "Validation Loss:  0.014832318\n",
      "Epoch:  1807\n",
      "Training Loss:  0.01977488\n",
      "Validation Loss:  0.016422996\n",
      "Epoch:  1808\n",
      "Training Loss:  0.020372568\n",
      "Validation Loss:  0.027417243\n",
      "Epoch:  1809\n",
      "Training Loss:  0.019647945\n",
      "Validation Loss:  0.01711772\n",
      "Epoch:  1810\n",
      "Training Loss:  0.02039729\n",
      "Validation Loss:  0.014675179\n",
      "Epoch:  1811\n",
      "Training Loss:  0.019813215\n",
      "Validation Loss:  0.017248524\n",
      "Epoch:  1812\n",
      "Training Loss:  0.020982593\n",
      "Validation Loss:  0.01700598\n",
      "Epoch:  1813\n",
      "Training Loss:  0.020806357\n",
      "Validation Loss:  0.017700711\n",
      "Epoch:  1814\n",
      "Training Loss:  0.019141415\n",
      "Validation Loss:  0.016089253\n",
      "Epoch:  1815\n",
      "Training Loss:  0.020680273\n",
      "Validation Loss:  0.017853092\n",
      "Epoch:  1816\n",
      "Training Loss:  0.019215433\n",
      "Validation Loss:  0.017448144\n",
      "Epoch:  1817\n",
      "Training Loss:  0.02113593\n",
      "Validation Loss:  0.016412662\n",
      "Epoch:  1818\n",
      "Training Loss:  0.019748025\n",
      "Validation Loss:  0.018315509\n",
      "Epoch:  1819\n",
      "Training Loss:  0.018991506\n",
      "Validation Loss:  0.018407078\n",
      "Epoch:  1820\n",
      "Training Loss:  0.018747885\n",
      "Validation Loss:  0.020881996\n",
      "Epoch:  1821\n",
      "Training Loss:  0.020400736\n",
      "Validation Loss:  0.01622126\n",
      "Epoch:  1822\n",
      "Training Loss:  0.020325543\n",
      "Validation Loss:  0.023858383\n",
      "Epoch:  1823\n",
      "Training Loss:  0.02026903\n",
      "Validation Loss:  0.018258853\n",
      "Epoch:  1824\n",
      "Training Loss:  0.019864013\n",
      "Validation Loss:  0.022885786\n",
      "Epoch:  1825\n",
      "Training Loss:  0.019414995\n",
      "Validation Loss:  0.017352384\n",
      "Epoch:  1826\n",
      "Training Loss:  0.019802388\n",
      "Validation Loss:  0.017794153\n",
      "Epoch:  1827\n",
      "Training Loss:  0.020214774\n",
      "Validation Loss:  0.017008202\n",
      "Epoch:  1828\n",
      "Training Loss:  0.019378634\n",
      "Validation Loss:  0.017156204\n",
      "Epoch:  1829\n",
      "Training Loss:  0.019171877\n",
      "Validation Loss:  0.015540549\n",
      "Epoch:  1830\n",
      "Training Loss:  0.020225093\n",
      "Validation Loss:  0.01745916\n",
      "Epoch:  1831\n",
      "Training Loss:  0.021132594\n",
      "Validation Loss:  0.01572357\n",
      "Epoch:  1832\n",
      "Training Loss:  0.019370364\n",
      "Validation Loss:  0.016528156\n",
      "Epoch:  1833\n",
      "Training Loss:  0.019566393\n",
      "Validation Loss:  0.01541203\n",
      "Epoch:  1834\n",
      "Training Loss:  0.019380039\n",
      "Validation Loss:  0.017660534\n",
      "Epoch:  1835\n",
      "Training Loss:  0.020030387\n",
      "Validation Loss:  0.015171361\n",
      "Epoch:  1836\n",
      "Training Loss:  0.01953435\n",
      "Validation Loss:  0.017352432\n",
      "Epoch:  1837\n",
      "Training Loss:  0.020134164\n",
      "Validation Loss:  0.016544145\n",
      "Epoch:  1838\n",
      "Training Loss:  0.018506845\n",
      "Validation Loss:  0.016081743\n",
      "Epoch:  1839\n",
      "Training Loss:  0.019501725\n",
      "Validation Loss:  0.015976803\n",
      "Epoch:  1840\n",
      "Training Loss:  0.018683782\n",
      "Validation Loss:  0.016983153\n",
      "Epoch:  1841\n",
      "Training Loss:  0.019421855\n",
      "Validation Loss:  0.014795025\n",
      "Epoch:  1842\n",
      "Training Loss:  0.019584341\n",
      "Validation Loss:  0.017137973\n",
      "Epoch:  1843\n",
      "Training Loss:  0.019652879\n",
      "Validation Loss:  0.016408298\n",
      "Epoch:  1844\n",
      "Training Loss:  0.019032907\n",
      "Validation Loss:  0.015950188\n",
      "Epoch:  1845\n",
      "Training Loss:  0.01965069\n",
      "Validation Loss:  0.017675593\n",
      "Epoch:  1846\n",
      "Training Loss:  0.020710826\n",
      "Validation Loss:  0.01563905\n",
      "Epoch:  1847\n",
      "Training Loss:  0.01873684\n",
      "Validation Loss:  0.014374993\n",
      "Epoch:  1848\n",
      "Training Loss:  0.019287942\n",
      "Validation Loss:  0.014085036\n",
      "Epoch:  1849\n",
      "Training Loss:  0.019797225\n",
      "Validation Loss:  0.016483538\n",
      "Epoch:  1850\n",
      "Training Loss:  0.019187003\n",
      "Validation Loss:  0.017058289\n",
      "Epoch:  1851\n",
      "Training Loss:  0.018666228\n",
      "Validation Loss:  0.0206817\n",
      "Epoch:  1852\n",
      "Training Loss:  0.020390883\n",
      "Validation Loss:  0.016008621\n",
      "Epoch:  1853\n",
      "Training Loss:  0.019551484\n",
      "Validation Loss:  0.016800627\n",
      "Epoch:  1854\n",
      "Training Loss:  0.02094573\n",
      "Validation Loss:  0.016453156\n",
      "Epoch:  1855\n",
      "Training Loss:  0.01879872\n",
      "Validation Loss:  0.015711104\n",
      "Epoch:  1856\n",
      "Training Loss:  0.018778326\n",
      "Validation Loss:  0.016235115\n",
      "Epoch:  1857\n",
      "Training Loss:  0.020133864\n",
      "Validation Loss:  0.015539468\n",
      "Epoch:  1858\n",
      "Training Loss:  0.019711737\n",
      "Validation Loss:  0.019510241\n",
      "Epoch:  1859\n",
      "Training Loss:  0.018637655\n",
      "Validation Loss:  0.01817179\n",
      "Epoch:  1860\n",
      "Training Loss:  0.018411376\n",
      "Validation Loss:  0.018606486\n",
      "Epoch:  1861\n",
      "Training Loss:  0.01910104\n",
      "Validation Loss:  0.014497769\n",
      "Epoch:  1862\n",
      "Training Loss:  0.018799074\n",
      "Validation Loss:  0.018082561\n",
      "Epoch:  1863\n",
      "Training Loss:  0.019310595\n",
      "Validation Loss:  0.019884778\n",
      "Epoch:  1864\n",
      "Training Loss:  0.019887147\n",
      "Validation Loss:  0.016682576\n",
      "Epoch:  1865\n",
      "Training Loss:  0.018586075\n",
      "Validation Loss:  0.014325297\n",
      "Epoch:  1866\n",
      "Training Loss:  0.019769156\n",
      "Validation Loss:  0.018541938\n",
      "Epoch:  1867\n",
      "Training Loss:  0.018948719\n",
      "Validation Loss:  0.020368723\n",
      "Epoch:  1868\n",
      "Training Loss:  0.01962734\n",
      "Validation Loss:  0.017699385\n",
      "Epoch:  1869\n",
      "Training Loss:  0.020139871\n",
      "Validation Loss:  0.01810407\n",
      "Epoch:  1870\n",
      "Training Loss:  0.019447027\n",
      "Validation Loss:  0.015765928\n",
      "Epoch:  1871\n",
      "Training Loss:  0.019389763\n",
      "Validation Loss:  0.016437516\n",
      "Epoch:  1872\n",
      "Training Loss:  0.019612653\n",
      "Validation Loss:  0.017199557\n",
      "Epoch:  1873\n",
      "Training Loss:  0.01935984\n",
      "Validation Loss:  0.021359151\n",
      "Epoch:  1874\n",
      "Training Loss:  0.020250779\n",
      "Validation Loss:  0.01693459\n",
      "Epoch:  1875\n",
      "Training Loss:  0.018556643\n",
      "Validation Loss:  0.01876905\n",
      "Epoch:  1876\n",
      "Training Loss:  0.019414054\n",
      "Validation Loss:  0.015308379\n",
      "Epoch:  1877\n",
      "Training Loss:  0.018986184\n",
      "Validation Loss:  0.016592208\n",
      "Epoch:  1878\n",
      "Training Loss:  0.020578625\n",
      "Validation Loss:  0.016291542\n",
      "Epoch:  1879\n",
      "Training Loss:  0.01880229\n",
      "Validation Loss:  0.018538754\n",
      "Epoch:  1880\n",
      "Training Loss:  0.019267797\n",
      "Validation Loss:  0.015006072\n",
      "Epoch:  1881\n",
      "Training Loss:  0.020008117\n",
      "Validation Loss:  0.023345789\n",
      "Epoch:  1882\n",
      "Training Loss:  0.018987853\n",
      "Validation Loss:  0.018126626\n",
      "Epoch:  1883\n",
      "Training Loss:  0.018626178\n",
      "Validation Loss:  0.016895575\n",
      "Epoch:  1884\n",
      "Training Loss:  0.018797906\n",
      "Validation Loss:  0.015138035\n",
      "Epoch:  1885\n",
      "Training Loss:  0.01957539\n",
      "Validation Loss:  0.017064022\n",
      "Epoch:  1886\n",
      "Training Loss:  0.020094668\n",
      "Validation Loss:  0.02385746\n",
      "Epoch:  1887\n",
      "Training Loss:  0.019215995\n",
      "Validation Loss:  0.015506874\n",
      "Epoch:  1888\n",
      "Training Loss:  0.019709919\n",
      "Validation Loss:  0.016221523\n",
      "Epoch:  1889\n",
      "Training Loss:  0.018254546\n",
      "Validation Loss:  0.015374466\n",
      "Epoch:  1890\n",
      "Training Loss:  0.019033894\n",
      "Validation Loss:  0.015576952\n",
      "Epoch:  1891\n",
      "Training Loss:  0.018689489\n",
      "Validation Loss:  0.01780892\n",
      "Epoch:  1892\n",
      "Training Loss:  0.019205568\n",
      "Validation Loss:  0.01524597\n",
      "Epoch:  1893\n",
      "Training Loss:  0.017696956\n",
      "Validation Loss:  0.018364623\n",
      "Epoch:  1894\n",
      "Training Loss:  0.017765686\n",
      "Validation Loss:  0.015906485\n",
      "Epoch:  1895\n",
      "Training Loss:  0.01923847\n",
      "Validation Loss:  0.015795937\n",
      "Epoch:  1896\n",
      "Training Loss:  0.019794563\n",
      "Validation Loss:  0.016989427\n",
      "Epoch:  1897\n",
      "Training Loss:  0.018975254\n",
      "Validation Loss:  0.016912492\n",
      "Epoch:  1898\n",
      "Training Loss:  0.018457433\n",
      "Validation Loss:  0.015958058\n",
      "Epoch:  1899\n",
      "Training Loss:  0.018164746\n",
      "Validation Loss:  0.015126974\n",
      "Epoch:  1900\n",
      "Training Loss:  0.020471495\n",
      "Validation Loss:  0.015735595\n",
      "Epoch:  1901\n",
      "Training Loss:  0.018229602\n",
      "Validation Loss:  0.017247621\n",
      "Epoch:  1902\n",
      "Training Loss:  0.018356951\n",
      "Validation Loss:  0.020881921\n",
      "Epoch:  1903\n",
      "Training Loss:  0.01842856\n",
      "Validation Loss:  0.01638502\n",
      "Epoch:  1904\n",
      "Training Loss:  0.018270662\n",
      "Validation Loss:  0.017120404\n",
      "Epoch:  1905\n",
      "Training Loss:  0.018530328\n",
      "Validation Loss:  0.015375975\n",
      "Epoch:  1906\n",
      "Training Loss:  0.018625462\n",
      "Validation Loss:  0.015068449\n",
      "Epoch:  1907\n",
      "Training Loss:  0.018488316\n",
      "Validation Loss:  0.014173347\n",
      "Epoch:  1908\n",
      "Training Loss:  0.02077248\n",
      "Validation Loss:  0.015897999\n",
      "Epoch:  1909\n",
      "Training Loss:  0.018249013\n",
      "Validation Loss:  0.015566494\n",
      "Epoch:  1910\n",
      "Training Loss:  0.020735206\n",
      "Validation Loss:  0.014699803\n",
      "Epoch:  1911\n",
      "Training Loss:  0.018364023\n",
      "Validation Loss:  0.016930623\n",
      "Epoch:  1912\n",
      "Training Loss:  0.019443756\n",
      "Validation Loss:  0.016496928\n",
      "Epoch:  1913\n",
      "Training Loss:  0.018282859\n",
      "Validation Loss:  0.013820847\n",
      "Epoch:  1914\n",
      "Training Loss:  0.019574625\n",
      "Validation Loss:  0.020136511\n",
      "Epoch:  1915\n",
      "Training Loss:  0.01995502\n",
      "Validation Loss:  0.014903388\n",
      "Epoch:  1916\n",
      "Training Loss:  0.018340463\n",
      "Validation Loss:  0.019141844\n",
      "Epoch:  1917\n",
      "Training Loss:  0.019145746\n",
      "Validation Loss:  0.017985798\n",
      "Epoch:  1918\n",
      "Training Loss:  0.019211868\n",
      "Validation Loss:  0.015504652\n",
      "Epoch:  1919\n",
      "Training Loss:  0.018615311\n",
      "Validation Loss:  0.022715079\n",
      "Epoch:  1920\n",
      "Training Loss:  0.020145334\n",
      "Validation Loss:  0.014495741\n",
      "Epoch:  1921\n",
      "Training Loss:  0.018562894\n",
      "Validation Loss:  0.018591382\n",
      "Epoch:  1922\n",
      "Training Loss:  0.018925767\n",
      "Validation Loss:  0.016970145\n",
      "Epoch:  1923\n",
      "Training Loss:  0.018946262\n",
      "Validation Loss:  0.017051015\n",
      "Epoch:  1924\n",
      "Training Loss:  0.01816524\n",
      "Validation Loss:  0.014343879\n",
      "Epoch:  1925\n",
      "Training Loss:  0.018220464\n",
      "Validation Loss:  0.0136807775\n",
      "Epoch:  1926\n",
      "Training Loss:  0.01869835\n",
      "Validation Loss:  0.015160222\n",
      "Epoch:  1927\n",
      "Training Loss:  0.019560687\n",
      "Validation Loss:  0.0153606655\n",
      "Epoch:  1928\n",
      "Training Loss:  0.018607264\n",
      "Validation Loss:  0.01536115\n",
      "Epoch:  1929\n",
      "Training Loss:  0.018052466\n",
      "Validation Loss:  0.018369116\n",
      "Epoch:  1930\n",
      "Training Loss:  0.019022426\n",
      "Validation Loss:  0.013584554\n",
      "Epoch:  1931\n",
      "Training Loss:  0.017845219\n",
      "Validation Loss:  0.016636973\n",
      "Epoch:  1932\n",
      "Training Loss:  0.018335016\n",
      "Validation Loss:  0.01632396\n",
      "Epoch:  1933\n",
      "Training Loss:  0.018880911\n",
      "Validation Loss:  0.029362023\n",
      "Epoch:  1934\n",
      "Training Loss:  0.018187478\n",
      "Validation Loss:  0.021928415\n",
      "Epoch:  1935\n",
      "Training Loss:  0.018234896\n",
      "Validation Loss:  0.015487548\n",
      "Epoch:  1936\n",
      "Training Loss:  0.018759213\n",
      "Validation Loss:  0.014743105\n",
      "Epoch:  1937\n",
      "Training Loss:  0.018721767\n",
      "Validation Loss:  0.01461465\n",
      "Epoch:  1938\n",
      "Training Loss:  0.01784412\n",
      "Validation Loss:  0.014388022\n",
      "Epoch:  1939\n",
      "Training Loss:  0.018425867\n",
      "Validation Loss:  0.026568333\n",
      "Epoch:  1940\n",
      "Training Loss:  0.018423432\n",
      "Validation Loss:  0.015745234\n",
      "Epoch:  1941\n",
      "Training Loss:  0.017822132\n",
      "Validation Loss:  0.014867947\n",
      "Epoch:  1942\n",
      "Training Loss:  0.019031918\n",
      "Validation Loss:  0.020584015\n",
      "Epoch:  1943\n",
      "Training Loss:  0.018623754\n",
      "Validation Loss:  0.019869594\n",
      "Epoch:  1944\n",
      "Training Loss:  0.018699469\n",
      "Validation Loss:  0.02323938\n",
      "Epoch:  1945\n",
      "Training Loss:  0.017769778\n",
      "Validation Loss:  0.01711185\n",
      "Epoch:  1946\n",
      "Training Loss:  0.01917491\n",
      "Validation Loss:  0.013724096\n",
      "Epoch:  1947\n",
      "Training Loss:  0.018458255\n",
      "Validation Loss:  0.014673618\n",
      "Epoch:  1948\n",
      "Training Loss:  0.017480848\n",
      "Validation Loss:  0.015200363\n",
      "Epoch:  1949\n",
      "Training Loss:  0.01842711\n",
      "Validation Loss:  0.015562589\n",
      "Epoch:  1950\n",
      "Training Loss:  0.018109512\n",
      "Validation Loss:  0.014492702\n",
      "Epoch:  1951\n",
      "Training Loss:  0.017884076\n",
      "Validation Loss:  0.018219998\n",
      "Epoch:  1952\n",
      "Training Loss:  0.01692148\n",
      "Validation Loss:  0.015156283\n",
      "Epoch:  1953\n",
      "Training Loss:  0.018453036\n",
      "Validation Loss:  0.015958345\n",
      "Epoch:  1954\n",
      "Training Loss:  0.018350875\n",
      "Validation Loss:  0.015156895\n",
      "Epoch:  1955\n",
      "Training Loss:  0.017326314\n",
      "Validation Loss:  0.015667656\n",
      "Epoch:  1956\n",
      "Training Loss:  0.018848976\n",
      "Validation Loss:  0.015464253\n",
      "Epoch:  1957\n",
      "Training Loss:  0.01832069\n",
      "Validation Loss:  0.021105513\n",
      "Epoch:  1958\n",
      "Training Loss:  0.018500298\n",
      "Validation Loss:  0.015493398\n",
      "Epoch:  1959\n",
      "Training Loss:  0.018322272\n",
      "Validation Loss:  0.01620354\n",
      "Epoch:  1960\n",
      "Training Loss:  0.01744067\n",
      "Validation Loss:  0.022476831\n",
      "Epoch:  1961\n",
      "Training Loss:  0.018037697\n",
      "Validation Loss:  0.017702116\n",
      "Epoch:  1962\n",
      "Training Loss:  0.01972584\n",
      "Validation Loss:  0.017826978\n",
      "Epoch:  1963\n",
      "Training Loss:  0.01805947\n",
      "Validation Loss:  0.015297151\n",
      "Epoch:  1964\n",
      "Training Loss:  0.016942214\n",
      "Validation Loss:  0.014740472\n",
      "Epoch:  1965\n",
      "Training Loss:  0.018862298\n",
      "Validation Loss:  0.02233106\n",
      "Epoch:  1966\n",
      "Training Loss:  0.017605532\n",
      "Validation Loss:  0.013209495\n",
      "Epoch:  1967\n",
      "Training Loss:  0.018023407\n",
      "Validation Loss:  0.014684267\n",
      "Epoch:  1968\n",
      "Training Loss:  0.017222604\n",
      "Validation Loss:  0.01878847\n",
      "Epoch:  1969\n",
      "Training Loss:  0.018330108\n",
      "Validation Loss:  0.014619526\n",
      "Epoch:  1970\n",
      "Training Loss:  0.017569393\n",
      "Validation Loss:  0.017350048\n",
      "Epoch:  1971\n",
      "Training Loss:  0.017266858\n",
      "Validation Loss:  0.018620744\n",
      "Epoch:  1972\n",
      "Training Loss:  0.017891366\n",
      "Validation Loss:  0.016030168\n",
      "Epoch:  1973\n",
      "Training Loss:  0.017691309\n",
      "Validation Loss:  0.022416567\n",
      "Epoch:  1974\n",
      "Training Loss:  0.01797996\n",
      "Validation Loss:  0.015593067\n",
      "Epoch:  1975\n",
      "Training Loss:  0.018188478\n",
      "Validation Loss:  0.014812823\n",
      "Epoch:  1976\n",
      "Training Loss:  0.01705275\n",
      "Validation Loss:  0.014422567\n",
      "Epoch:  1977\n",
      "Training Loss:  0.018202798\n",
      "Validation Loss:  0.017771233\n",
      "Epoch:  1978\n",
      "Training Loss:  0.017443063\n",
      "Validation Loss:  0.01541869\n",
      "Epoch:  1979\n",
      "Training Loss:  0.017491365\n",
      "Validation Loss:  0.016685313\n",
      "Epoch:  1980\n",
      "Training Loss:  0.01961233\n",
      "Validation Loss:  0.014651469\n",
      "Epoch:  1981\n",
      "Training Loss:  0.017365204\n",
      "Validation Loss:  0.017648\n",
      "Epoch:  1982\n",
      "Training Loss:  0.017272454\n",
      "Validation Loss:  0.015639083\n",
      "Epoch:  1983\n",
      "Training Loss:  0.018189905\n",
      "Validation Loss:  0.017106889\n",
      "Epoch:  1984\n",
      "Training Loss:  0.017192686\n",
      "Validation Loss:  0.014891067\n",
      "Epoch:  1985\n",
      "Training Loss:  0.017973578\n",
      "Validation Loss:  0.022973984\n",
      "Epoch:  1986\n",
      "Training Loss:  0.018254861\n",
      "Validation Loss:  0.014731913\n",
      "Epoch:  1987\n",
      "Training Loss:  0.01819046\n",
      "Validation Loss:  0.019761218\n",
      "Epoch:  1988\n",
      "Training Loss:  0.017249113\n",
      "Validation Loss:  0.014036923\n",
      "Epoch:  1989\n",
      "Training Loss:  0.017544532\n",
      "Validation Loss:  0.015089338\n",
      "Epoch:  1990\n",
      "Training Loss:  0.019392941\n",
      "Validation Loss:  0.015744114\n",
      "Epoch:  1991\n",
      "Training Loss:  0.017479256\n",
      "Validation Loss:  0.020105083\n",
      "Epoch:  1992\n",
      "Training Loss:  0.017971894\n",
      "Validation Loss:  0.012586397\n",
      "Epoch:  1993\n",
      "Training Loss:  0.018883392\n",
      "Validation Loss:  0.015126421\n",
      "Epoch:  1994\n",
      "Training Loss:  0.01722154\n",
      "Validation Loss:  0.014990463\n",
      "Epoch:  1995\n",
      "Training Loss:  0.01761621\n",
      "Validation Loss:  0.021757416\n",
      "Epoch:  1996\n",
      "Training Loss:  0.017921787\n",
      "Validation Loss:  0.015293543\n",
      "Epoch:  1997\n",
      "Training Loss:  0.019023357\n",
      "Validation Loss:  0.015137971\n",
      "Epoch:  1998\n",
      "Training Loss:  0.01845193\n",
      "Validation Loss:  0.014210726\n",
      "Epoch:  1999\n",
      "Training Loss:  0.017510803\n",
      "Validation Loss:  0.013049703\n"
     ]
    }
   ],
   "source": [
    "# Now let's do the training!\n",
    "\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "mymodel = myMultiLayerPerceptron(77,1) # creating a model instance with input dimension 1\n",
    "\n",
    "best_model = mymodel\n",
    "max_val_acc = 0\n",
    "\n",
    "# Three hyper parameters for training\n",
    "lr = 0.000001\n",
    "batch_size = 32\n",
    "N_epochs = 2000\n",
    "loss_fun = nn.MSELoss()\n",
    "\n",
    "# Create dataloaders for training and validation\n",
    "train_dataloader = DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
    "validate_dataloader = DataLoader(validate_set,batch_size = batch_size,shuffle = True)\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.Adam(mymodel.parameters(), lr = lr) # this line creates a optimizer, and we tell optimizer we are optimizing the parameters in mymodel\n",
    "\n",
    "training_losses = [] # training losses of each epoch\n",
    "validate_losses = [] # validation losses of each epoch\n",
    "training_losses_all = [] # training losses of each SGD iteration\n",
    "train_acc_list = [] # training accuracy of each epoch\n",
    "\n",
    "gd_steps = 0\n",
    "N_batches = len(train_dataloader)\n",
    "\n",
    "for epoch in range(N_epochs):\n",
    "    print(\"Epoch: \", epoch)\n",
    "    batch_loss = []\n",
    "    train_acc = []\n",
    "    for batch_id, (x_batch, y_batch) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # pass input data to get the prediction outputs by the current model\n",
    "        prediction = mymodel(x_batch)\n",
    "\n",
    "        # compare prediction and the actual output and compute the loss\n",
    "        loss = loss_fun(prediction, y_batch)\n",
    "        batch_loss.append(loss.detach().numpy())\n",
    "        training_losses_all.append(loss.detach().numpy())\n",
    "        \n",
    "        # compute the gradient\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "    # calculate the training accuracy\n",
    "    pred = mymodel(x_train)\n",
    "    pred = pred.detach().numpy()\n",
    "    pred = np.round(pred)\n",
    "    train_acc = np.mean(pred == y_train.numpy())\n",
    "    train_acc_list.append(train_acc)\n",
    "\n",
    "    # Calculate Validation Loss\n",
    "    validate_batch_loss = []\n",
    "    validate_acc = []\n",
    "    for batch_id, (x_batch, y_batch) in enumerate(validate_dataloader):\n",
    "        # pass input data to get the prediction outputs by the current model\n",
    "        prediction = mymodel(x_batch)\n",
    "        # compare prediction and the actual output and compute the loss\n",
    "        loss = loss_fun(prediction, y_batch)\n",
    "        validate_batch_loss.append(loss.detach().numpy())\n",
    "        \n",
    "\n",
    "        pred = mymodel(x_batch)\n",
    "        pred = pred.detach().numpy()\n",
    "        pred = np.argmax(pred, axis=1)\n",
    "\n",
    "\n",
    "    cur_val_loss=np.mean(np.array(validate_batch_loss))\n",
    "    cur_epoch_loss = np.mean(np.array(batch_loss))\n",
    "\n",
    "    validate_losses.append(cur_val_loss)\n",
    "    training_losses.append(cur_epoch_loss)\n",
    "\n",
    "    print(\"Training Loss: \", cur_epoch_loss)\n",
    "    print(\"Validation Loss: \", cur_val_loss)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))  \n",
    "plt.plot(training_losses_all)  \n",
    "\n",
    "plt.title('train loss per SGD iteration')\n",
    "plt.xlabel('batch iteration')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))  \n",
    "plt.plot(training_losses)  \n",
    "plt.plot(validate_losses)\n",
    "plt.title('train and validate loss across different epochs')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE loss')\n",
    "plt.legend(['train loss', 'validate loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "60e129e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_acc_list)\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a44fab48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy:  0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "## calculate baseline accuracy\n",
    "total = c2_data.count()\n",
    "attack = c2_data.filter(col(\"outcome\")==1).count()\n",
    "normal = c2_data.filter(col(\"outcome\")==0).count()\n",
    "\n",
    "base_acc = normal/total\n",
    "print(\"Baseline accuracy: \", base_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7652f972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9836956521739131\n"
     ]
    }
   ],
   "source": [
    "## calculate train accuracy\n",
    "pred = mymodel(x_train)\n",
    "pred = pred.detach().numpy()\n",
    "pred = np.round(pred)\n",
    "train_acc = np.mean(pred == y_train.numpy())\n",
    "print(\"Train accuracy: \", train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "509d7f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.9948717948717949\n"
     ]
    }
   ],
   "source": [
    "## calculate test accuracy\n",
    "test_pred = mymodel(x_test)\n",
    "test_pred = test_pred.detach().numpy()\n",
    "test_pred = test_pred > 0.5\n",
    "test_pred = test_pred.astype(int)\n",
    "\n",
    "test_acc = np.sum(test_pred == y_test.numpy())/len(y_test)\n",
    "print(\"Test accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3ecfc313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[192   0]\n",
      " [  1   2]]\n",
      "F1 Score:  0.8\n"
     ]
    }
   ],
   "source": [
    "## calculate TP, TN, FP, FN and F1 score and AUC and ROC and PR curve for the test set and plot all of them\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, test_pred)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(conf_matrix)\n",
    "\n",
    "f1 = f1_score(y_test, test_pred)\n",
    "print(\"F1 Score: \", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toolchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
